{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-2\n",
    "- **Problem-2**\n",
    "- **ID=160204008**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem #2**\n",
    "\n",
    "*   Apply **Neural Network / Deep Neural Network** for the **Ekush** dataset and build a binary classification model that can predict  **male/female** from Bengali handwritten digits with different hyperparameter settings.  \n",
    "\n",
    "### *** Approach ***\n",
    "- Our input size is determined by the size of the image **(height x width) = (28X28)**. Hence the size of our input is **784 (28 x 28)**.\n",
    "\n",
    " - When we pass an image to our model, it will try to predict if it's written by **Male or Female**. That is a total of 2 classes, hence we have an output size of 2.\n",
    "\n",
    " - Determining the **hidden layer size** is one of the crutial part. This can be any **real number**. A large number of hidden nodes denotes a **bigger model with more parameters**. \n",
    "\n",
    "- The bigger model isn't **always the better model**. On the otner hand, bigger model requires **more training samples** to learn and converge to a good model. \n",
    "\n",
    "- Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve good results.\n",
    "\n",
    "- Moreover, too small of a hidden size would mean there would be **insufficient model capacity to predict competently**. Too small of a capacity denotes a **smaller brain capacity** so no matter how many training samples you provide, it has a maximum capacity boundary in terms of its **predictive power**.\n",
    "\n",
    "- Hence it is important to find the right hidden size for the specifed problem.\n",
    "\n",
    "**Problem Portion Dataset Link:** https://shahariarrabby.github.io/ekush/#download\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processin and CSV file making was done on Laptop using Jupyter NoteBook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Image Processing*\n",
    "Ekush dataset has two image folders Male and Female in both this folders folder 110 to 119 consist of digit images. I copied all the male digit images in a maleAll folder and all the female digit images in femaleALL folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--------------------------------------\n",
      "1--------------------------------------\n",
      "2--------------------------------------\n",
      "3--------------------------------------\n",
      "4--------------------------------------\n",
      "5--------------------------------------\n",
      "6--------------------------------------\n",
      "7--------------------------------------\n",
      "8--------------------------------------\n",
      "9--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Female Renaming images\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "path_folder='E:/CSE/softConputing/Ekush/female'\n",
    "\n",
    "src = path_folder+\"/110\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='0_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('0--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/111\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='1_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "    \n",
    "print('1--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/112\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='2_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('2--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/113\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='3_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('3--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/114\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='4_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('4--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/115\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='5_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('5--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/116\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='6_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('6--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/117\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='7_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('7--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/118\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='8_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('8--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/119\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='9_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('9--------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--------------------------------------\n",
      "1--------------------------------------\n",
      "2--------------------------------------\n",
      "3--------------------------------------\n",
      "4--------------------------------------\n",
      "5--------------------------------------\n",
      "6--------------------------------------\n",
      "7--------------------------------------\n",
      "8--------------------------------------\n",
      "9--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Female digit images of folder 110 to 119 coppied to femaleALL folder\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "path_folder='E:/CSE/softConputing/Ekush/female'\n",
    "\n",
    "src = path_folder+\"/110\"\n",
    "path = 'E:/CSE/softConputing/Ekush/femaleAllRaw'\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('0--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/111\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('1--------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "src = path_folder+\"/112\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('2--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/113\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('3--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/114\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('4--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/115\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('5--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/116\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('6--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/117\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('7--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/118\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('8--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/119\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('9--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing all female digit images\n",
    "from PIL import Image\n",
    "src = 'E:/CSE/softConputing/Ekush/femaleAllRaw'\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    image = Image.open(src+\"/\"+dir_name)\n",
    "    new_image = image.resize((28, 28))\n",
    "    new_image.save('E:/CSE/softConputing/Ekush/femaleAll'+\"/\"+dir_name)\n",
    "    #print(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Male Renaming images\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "path_folder='E:/CSE/softConputing/Ekush/male'\n",
    "\n",
    "src = path_folder+\"/110\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='0_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('0--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/111\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='1_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "    \n",
    "print('1--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/112\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='2_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('2--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/113\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='3_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('3--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/114\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='4_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('4--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/115\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='5_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('5--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/116\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='6_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('6--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/117\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='7_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('7--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/118\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='8_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('8--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/119\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    #print(dir_name)\n",
    "    a='9_'+dir_name\n",
    "    os.rename(src+ \"/\" +dir_name, src+ \"/\" +a)\n",
    "print('9--------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--------------------------------------\n",
      "1--------------------------------------\n",
      "2--------------------------------------\n",
      "3--------------------------------------\n",
      "4--------------------------------------\n",
      "5--------------------------------------\n",
      "6--------------------------------------\n",
      "7--------------------------------------\n",
      "8--------------------------------------\n",
      "9--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Male digit images of folder 110 to 119 coppied to femaleALL folder\n",
    "\n",
    "import shutil\n",
    "path_folder='E:/CSE/softConputing/Ekush/male'\n",
    "\n",
    "src = path_folder+\"/110\"\n",
    "path = 'E:/CSE/softConputing/Ekush/maleAllRaw'\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('0--------------------------------------')\n",
    "\n",
    "\n",
    "src = path_folder+\"/111\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('1--------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "src = path_folder+\"/112\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('2--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/113\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('3--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/114\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('4--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/115\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('5--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/116\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('6--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/117\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('7--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/118\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('8--------------------------------------')\n",
    "\n",
    "src = path_folder+\"/119\"\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    file_name = os.path.join(src, dir_name)\n",
    "    if os.path.isfile(file_name):\n",
    "        shutil.copy(file_name, path)\n",
    "print('9--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing all male digit images\n",
    "from PIL import Image\n",
    "src = 'E:/CSE/softConputing/Ekush/maleAllRaw'\n",
    "dir_folders = os.listdir(src)\n",
    "for dir_name in dir_folders:\n",
    "    image = Image.open(src+\"/\"+dir_name)\n",
    "    new_image = image.resize((28, 28))\n",
    "    new_image.save('E:/CSE/softConputing/Ekush/maleAll'+\"/\"+dir_name)\n",
    "    #print(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female',\n",
       " 'femaleAll',\n",
       " 'femaleAllRaw',\n",
       " 'femaleDigits.csv',\n",
       " 'male',\n",
       " 'maleAll',\n",
       " 'maleAllRaw',\n",
       " 'maleDigits.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'E:/CSE/softConputing/Ekush/'\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWO seperate CSV file for male and Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV For Female\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "src = 'E:/CSE/softConputing/Ekush/femaleAll'\n",
    "a = os.listdir(src)\n",
    "print(len(a))\n",
    "\n",
    "import pandas\n",
    "\n",
    "l=[]\n",
    "for i in range(len(a)):\n",
    "    l.append(1)\n",
    "df = pandas.DataFrame(data={\"imageid\": a, \"label\": l})\n",
    "df.to_csv(\"E:/CSE/softConputing/Ekush/femaleDigits.csv\", sep=',',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV for Male\n",
    "\n",
    "src = 'E:/CSE/softConputing/Ekush/maleAll'\n",
    "a = os.listdir(src)\n",
    "print(len(a))\n",
    "\n",
    "import pandas\n",
    "\n",
    "l=[]\n",
    "for i in range(len(a)):\n",
    "    l.append(0)\n",
    "df = pandas.DataFrame(data={\"imageid\": a, \"label\": l})\n",
    "df.to_csv(\"E:/CSE/softConputing/Ekush/maleDigits.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done Image Processing and making CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAFAUlEQVR4nKVWS2gTXRQ+d+68MokEqTZFRezLZxvQjaJd2IVdKG6k4kZQLCgFN0UXIiKK4MKFoCu3LtxYH6EbFa0SUYlSgg9c+Cg1RY1t00eaZO7Mnblz/sXxD8KvLv6c1XDm3m++79zvnDtMCGHbNvwbUkrTNKGxYIj4+fPn0dHRdevW9fT06LrueZ5hGJzz/48qpbx69SoAbNq06datW0II13WxsdAMw2hubtZ1vVAoKKVs22aMCSEaka//+PGjXC4jYrVapZRt21EUNQKqtbS0pNPpVatW2bbtuq7v+4jIGGuIaRAEnHNN02Kx2JcvXyzLagTuZyDi7OxsR0cHAGzevJlK0ehBKaWUUjMzM5xzRKRqhmGIiL9lAABBENABTE9PZzKZ69evSyl93weAhYUFAACl1Nzc3MGDBwGgu7u7VqsholIqiqL/UqCkEAIRgyA4fvz46tWrm5qa1q5de+7cuWfPntFeQETf969cucIY6+zsfPPmza/7fwsahqHneXfv3l25ciUAOI4DAIyxPXv2zMzMuK6rIaJpmlJKxlipVHr69Onfz6BWq3HOR0dHT5069e3bN855PB6nymSz2Xv37um6rimlACCRSJimOT8/X6lUqMp/AiVeHz9+/PDhg2EYSqlSqQQAS5YsqVarN2/erFQqmq7rANDT09Pc3AwAbW1tYRj+pfEZY/Pz8+Pj447j0F7TNB3HqVQqAPDy5cvXr19rtLS9vX3FihUAUK1W/0KTDrZUKmWzWdd1hRDd3d3JZNJ1XdM0LcsSQjx+/FgjKywuLjqOwxjL5XJSyjAM/wQaRVFLS8vXr181Tevq6jp9+vSOHTssy2KM+b5frVZzuZxGLZRKpfr6+gzDePTo0eTkJGMsCAJCqRuWLGwYRrFYTCaTURQdPnw4Fovl83nf97u6uvr6+hKJxKdPnzSlVK1W8zxv69at8Xi8WCy+ffuWc26aJrUAInqeBwCaptFkiMfjTU1NsVjs4cOHJ0+eLBQKy5cvP3bsWGtrqxBidnYWEFFKSe7bsmULAAwODnqeVzc5vQqCgB4oc+LECfoMiUin0+Pj40NDQyRFk1IahkFjZcOGDQAwMjIyPDwMALZtSykBgHOu63oURZxzKveuXbsSiYTjOIlEIp1OP3jwoK2tTdd1zrllWUAUiNrw8PDGjRsBoLe3d3JyknpuamqK2JEgRKTMtWvXtm/ffunSpWKx6Hme67r9/f0AsG3bNqB1BC2lPHPmDGMsHo8fPXq0UChQa1J3kisQ0XVdunLCMCyVSoRw//79VCoFAIcOHQJELJfLxBQR8/n83r17SfLQ0NDExARtJrgwDKenpxGR5k49crnczp07ye+ZTObnQCGlNExv3LiRTCapeQYGBt69e1epVH4VRGSJ+8LCwoULF1KpFOk7e/aslBLq6+oP379/f/HiRWtrKwDout7R0TE4OJjP58fGxuqCEHFxcTGTyezbt48YWJZ1+fLlubk5pRSrd7pSqt7ytVrt+fPnFy9ezGazlEkmk5Zl7d+/f+nSpQAgpSwUCq9evZqYmCAbnT9/vr+/v7OzE+hnot45URQxxsh9Usr379+PjIw8efJkbGxMCEFvqdwAQN5as2ZNb2/v+vXrjxw5smzZMgAQQjDSUr8+6ca3LIugoyiampq6ffv2nTt3yuUyfRsRNU3TNK29vf3AgQO7d++uX5dSSinlP6LvMpDubIMWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28 at 0x2390D005388>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "data_dir = 'E:/CSE/softConputing/Ekush/maleAll'\n",
    "name = os.listdir(data_dir)[5000]\n",
    "Image.open(data_dir+\"/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28 at 0x2391312B748>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "data_dir = 'E:/CSE/softConputing/Ekush/femaleAll'\n",
    "name = os.listdir(data_dir)[5000]\n",
    "Image.open(data_dir+\"/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15620\n"
     ]
    }
   ],
   "source": [
    "src = 'E:/CSE/softConputing/Ekush/femaleAll'\n",
    "a = os.listdir(src)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imageid', 'label'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalF = pd.read_csv('E:/CSE/softConputing/Ekush/femaleDigits.csv')\n",
    "totalF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1_14_BOG_1_317.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1_22_Farid_3_318.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_1_B.BARIA_11_1_319.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_1_B.BARIA_11_1_320.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_1_B.BARIA_11_1_321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_1_B.BARIA_11_1_322.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_1_B.BARIA_11_1_323.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_1_B.BARIA_11_1_324.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_1_B.BARIA_12_1_325.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_1_B.BARIA_12_1_87.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    imageid  label\n",
       "0      0_1_14_BOG_1_317.jpg      1\n",
       "1    0_1_22_Farid_3_318.jpg      1\n",
       "2  0_1_B.BARIA_11_1_319.jpg      1\n",
       "3  0_1_B.BARIA_11_1_320.jpg      1\n",
       "4  0_1_B.BARIA_11_1_321.jpg      1\n",
       "5  0_1_B.BARIA_11_1_322.jpg      1\n",
       "6  0_1_B.BARIA_11_1_323.jpg      1\n",
       "7  0_1_B.BARIA_11_1_324.jpg      1\n",
       "8  0_1_B.BARIA_12_1_325.jpg      1\n",
       "9   0_1_B.BARIA_12_1_87.jpg      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalF.iloc[:10, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15068\n"
     ]
    }
   ],
   "source": [
    "src = 'E:/CSE/softConputing/Ekush/maleAll'\n",
    "a = os.listdir(src)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['imageid', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalM = pd.read_csv('E:/CSE/softConputing/Ekush/maleDigits.csv')\n",
    "totalM.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0_18_kis_2_361.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_0_B.BARIA_14_1_362.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_0_B.BARIA_17_2_363.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_0_B.BARIA_20_3_1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_0_B.BARIA_20_3_364.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0_0_B.BARIA_21_3_2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0_0_B.BARIA_22_3_3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_0_B.BARIA_22_3_4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0_0_B.BARI_10_1_365.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_0_B.BARI_11_1_366.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    imageid  label\n",
       "0      0_0_18_kis_2_361.jpg      0\n",
       "1  0_0_B.BARIA_14_1_362.jpg      0\n",
       "2  0_0_B.BARIA_17_2_363.jpg      0\n",
       "3    0_0_B.BARIA_20_3_1.jpg      0\n",
       "4  0_0_B.BARIA_20_3_364.jpg      0\n",
       "5    0_0_B.BARIA_21_3_2.jpg      0\n",
       "6    0_0_B.BARIA_22_3_3.jpg      0\n",
       "7    0_0_B.BARIA_22_3_4.jpg      0\n",
       "8   0_0_B.BARI_10_1_365.jpg      0\n",
       "9   0_0_B.BARI_11_1_366.jpg      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalM.iloc[:10, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'E:/CSE/softConputing/Ekush/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRawTrainingSamples(csv_filename):\n",
    "    df = pd.read_csv(PATH + csv_filename)\n",
    "    print(csv_filename)\n",
    "    print(df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maleDigits.csv\n",
      "Index(['imageid', 'label'], dtype='object')\n",
      "femaleDigits.csv\n",
      "Index(['imageid', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "m_csv = showRawTrainingSamples('maleDigits.csv')\n",
    "f_csv = showRawTrainingSamples('femaleDigits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropColumns(csv_file):\n",
    "    #csv_file = csv_file[['filename', 'digit']]\n",
    "    print(csv_file)\n",
    "    print(csv_file.iloc[:2, :])   #First 5 Rows of the CSV File\n",
    "    print(\"=============================\")\n",
    "    return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        imageid  label\n",
      "0          0_0_18_kis_2_361.jpg      0\n",
      "1      0_0_B.BARIA_14_1_362.jpg      0\n",
      "2      0_0_B.BARIA_17_2_363.jpg      0\n",
      "3        0_0_B.BARIA_20_3_1.jpg      0\n",
      "4      0_0_B.BARIA_20_3_364.jpg      0\n",
      "...                         ...    ...\n",
      "15063     9_0_THAK_20_3_345.jpg      0\n",
      "15064     9_0_THAK_20_3_346.jpg      0\n",
      "15065     9_0_THAK_21_3_347.jpg      0\n",
      "15066     9_0_THAK_21_3_348.jpg      0\n",
      "15067     9_0_THAK_22_3_349.jpg      0\n",
      "\n",
      "[15068 rows x 2 columns]\n",
      "                    imageid  label\n",
      "0      0_0_18_kis_2_361.jpg      0\n",
      "1  0_0_B.BARIA_14_1_362.jpg      0\n",
      "=============================\n",
      "                        imageid  label\n",
      "0          0_1_14_BOG_1_317.jpg      1\n",
      "1        0_1_22_Farid_3_318.jpg      1\n",
      "2      0_1_B.BARIA_11_1_319.jpg      1\n",
      "3      0_1_B.BARIA_11_1_320.jpg      1\n",
      "4      0_1_B.BARIA_11_1_321.jpg      1\n",
      "...                         ...    ...\n",
      "15615      9_1_TAN_1_1_1577.jpg      1\n",
      "15616       9_1_THAK_13_316.jpg      1\n",
      "15617    9_1_Tha_21_3_00032.jpg      1\n",
      "15618    9_1_Tha_22_3_00033.jpg      1\n",
      "15619    9_1_Tha_22_3_00035.jpg      1\n",
      "\n",
      "[15620 rows x 2 columns]\n",
      "                  imageid  label\n",
      "0    0_1_14_BOG_1_317.jpg      1\n",
      "1  0_1_22_Farid_3_318.jpg      1\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "m_csv = dropColumns(m_csv)\n",
    "f_csv = dropColumns(f_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30688\n"
     ]
    }
   ],
   "source": [
    "# concating male and felame CSV\n",
    "total_csv = [m_csv, f_csv]\n",
    "\n",
    "merged_csv = pd.concat(total_csv)\n",
    "print(len(merged_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Making train folder\n",
    "TRAIN_PATH = 'E:/CSE/softConputing/Ekush/train'\n",
    "os.mkdir(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'E:/CSE/softConputing/Ekush/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(folder_name):\n",
    "    src = PATH + folder_name + '/'\n",
    "    dir_folders = os.listdir(src)\n",
    "    for dir_name in dir_folders:\n",
    "        file_name = os.path.join(src, dir_name)\n",
    "        if os.path.isfile(file_name):\n",
    "            shutil.copy(file_name, TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M Done\n",
      "F Done\n"
     ]
    }
   ],
   "source": [
    "processImages('maleAll')\n",
    "print('M Done')\n",
    "processImages('femaleAll')\n",
    "print('F Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None):\n",
    "        self.data = df\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        \n",
    "        path = self.root + \"/\" + item[0]\n",
    "        image = Image.open(path).convert('L')\n",
    "        label = item[1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Samples:  30688\n"
     ]
    }
   ],
   "source": [
    "#Normalizing Dataset\n",
    "mean = [0.5,]\n",
    "std = [0.5, ]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data  = Dataset(merged_csv, TRAIN_PATH, train_transform)\n",
    "test_data = Dataset(merged_csv, TRAIN_PATH, test_transform)\n",
    "\n",
    "print(\"Trainig Samples: \",len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23912c81548>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Displaying a Ekush Image\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "show_img = train_data[5000][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x239135da508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVI0lEQVR4nO3dfYzV1ZkH8O/DOwKiw0xHFEqlwWR9Rb2lqIgC0giaoIlda6KBpIGaVqVqmrWub9HUEN3SEMUmoAbadDXVgtgqWkOKrhq1A7IIa1ywjjKFwFAo74g4z/4xl82szu/7TO/vvq3n+0nIDPOdc+/h3nnmDvP8zjnm7hCRr75etZ6AiFSHil0kESp2kUSo2EUSoWIXSUSfat5ZY2Ojjxo1KjM3Mzq+o6MjM+vVK9/3ragrwebG5gXkn1uEzT16TCt539H95xmbV/ScRfedd26Ves5aW1uxc+fObm8gV7Gb2eUAFgDoDeBxd5/HPn/UqFF48803M/P+/fvT+9u/f39mNnjwYDr2888/p/lnn31G8wEDBpQ0LwAYOHAgzXv37k3zyJEjRzKzPn34U5z3G9Gnn35Kc/acHj58mI7t27cvzaPHjRXUoUOHct13lEfYc9avX7+Sb7dQKGRmJT/TZtYbwEIA0wCcDuA6Mzu91NsTkcrK8219HIDN7v4Xdz8C4GkAM8ozLREptzzFfgqALV3+3lb82P9hZnPMrMXMWtrb23PcnYjkkafYu/slwJf+k+Tui9y94O6FpqamHHcnInnkKfY2ACO7/H0EgK35piMilZKn2P8MYIyZnWpm/QB8D8Dz5ZmWiJRbya03dz9qZjcBeBmdrbcn3X0jG2NmtBXT1tZG73PEiBElzLTT7t27ad7Y2FjybUdtv8iWLVtoHv2ug7XXopbihx9+SPONG+lTiq1b+Q9zrC05adIkOvaCCy6gefT1MmXKlMzsuOOOo2PztmqjtiB7zo4ePUrHspYlu34gV5/d3V8E8GKe2xCR6tDlsiKJULGLJELFLpIIFbtIIlTsIolQsYskoqrr2Ts6OnDw4MHMPE8fPVobnaePDgCbN2/OzFatWkXHvvrqqzRfv349zT/44AOas97qoEGD6Ng8PV0gftzZdRVPP/00Hdvc3Ezz6PqDr3/965nZ9ddfT8f+5Cc/ofnxxx9P8wh73KNlyewxZWvh9coukggVu0giVOwiiVCxiyRCxS6SCBW7SCKq2nozs1y7crJlhVEL6KOPPqL54sWLab569erMbNOmTXTsvn37aB4tt4xaMVF7jDnttNNofsIJJ9A82l2Wtf6ixyVqOUZfS62trZnZggUL6Ng1a9bQfOrUqTSfO3cuzVnrLdpKmv271XoTERW7SCpU7CKJULGLJELFLpIIFbtIIlTsIomoqz57dBoq27L50UcfpWPvuecemkc93zx90Wg55XnnnUdzdsw1wLc9bmhooGPPPvtsmkdLg6MeP1vSPHToUDp25cqVNGd9dABYsmRJZhb10aP73rBhA83PP/98mk+cODEzi65dYM83u95Er+wiiVCxiyRCxS6SCBW7SCJU7CKJULGLJELFLpKIqvbZI9H65Ntuuy0zi7Yl3rNnD82jI3YvuuiizOzhhx+mY8eNG5frviOs1x1tFZ33uOkBAwbkypkrr7yy5LEA3+751ltvpWP37t1L8+iY7fnz59P8wgsvzMzYVtEAv3aB9dlzFbuZtQLYB+BzAEfdvZDn9kSkcsrxyj7J3XeW4XZEpIL0f3aRROQtdgfwRzNbY2ZzuvsEM5tjZi1m1hId1yMilZO32C9y9/MATAPwIzP70tX97r7I3QvuXmhqasp5dyJSqlzF7u5bi293AFgOgP/aWURqpuRiN7NBZjbk2PsAvgOAr/sTkZrJ89v4ZgDLi2u5+wD4d3d/iQ3o6Oiga9bXrVtH75CtT969ezcdG/nhD39I80ceeSQz27VrFx3bqxf/nsqOXO4J1peN+tzRfR85coTmbC9/gPd9o2OPDx06RPPocb322mszs40bN9KxDz30EM2j/fT/8Ic/0JydUzB79mw6lp0zwB6Tkovd3f8C4JxSx4tIdan1JpIIFbtIIlTsIolQsYskQsUukoiqLnHt1asXXVJ50kkn0fHRscxMtF0za9MAfJvraLvmaJlpdCRz9O9mWwtH7akor+QS1ki05Dl63Ji77rqL5q+99hrN33rrrZLvG+Bbm48ZM4aOveyyy0q6T72yiyRCxS6SCBW7SCJU7CKJULGLJELFLpIIFbtIIupqK+loqeiBAwcys379+tGxUT5hwgSa55GnHwzER0Lnvf16xbZMBuIlsgxbJgoAd955J81nzJhB8+jrbefO7D1aFy5cSMeOHz8+M2NLlvXKLpIIFbtIIlTsIolQsYskQsUukggVu0giVOwiiahqgzbaSrq5uZmOZ9sW5137HG2JzHrd0Xr1Sq75rnfssYmek+jo4mgbbLZWPzom++STT6b5OefwjZWjbdHZ/b/77rt0bEtLS2bGrkXRK7tIIlTsIolQsYskQsUukggVu0giVOwiiVCxiySiqn12M6M956jPPmvWrMyMHecMAMOGDaP54cOHaT5kyJDM7Ku6nrwc2J72efvs7LYBftx0tN781FNPpfkVV1xB86jPztbTf/zxx3TsCy+8kJnt2bMnMwtf2c3sSTPbYWYbunyswcxeMbNNxbcnRrcjIrXVkx/jlwC4/AsfuwPAKncfA2BV8e8iUsfCYnf31wB8cb+oGQCWFt9fCuCqMs9LRMqs1F/QNbv7NgAovv1a1iea2RwzazGzFrbvlohUVsV/G+/ui9y94O6FxsbGSt+diGQotdi3m9lwACi+3VG+KYlIJZRa7M8DmFl8fyaAFeWZjohUStggNrOnAFwKoNHM2gDcC2AegN+a2fcBfALgu+WYTHRW+O23356ZLVu2jI7du3cvzaO10aynG62NTlklH5votqM9CpiGhgaaT58+neaPPvoozdl1HdE1AGzNOvs6Dovd3a/LiKZEY0WkfuhyWZFEqNhFEqFiF0mEil0kESp2kUTU1drMqOVw5plnZmb3338/HRttzzt06FCasy2wBw8eTMemjC1jdfdctx0dZc1ac9H239Hy27Fjx9J88uTJNF++fDnNmZUrV2ZmuZa4ishXg4pdJBEqdpFEqNhFEqFiF0mEil0kESp2kURUfSvpSm27PHfuXJpHW/tGWC+d9eCjsSmLet3REtaoz86+1vIsfwX4VtAAcMkll9Cc9dmjI75bW1tpnkWv7CKJULGLJELFLpIIFbtIIlTsIolQsYskQsUukoiq9tndnfZWo341O8J34MCBdGy0/ri9vZ3mTU1NmVl03LP67N2L+uTR1uJ5bj/aOyG6BiDaevy9996jOZvbp59+SseWSq/sIolQsYskQsUukggVu0giVOwiiVCxiyRCxS6SiLpazx7t3X7o0KGS7ztavxwd0cs0NjaWPPar7siRI5lZ3759c902O0Yb4H36qMcf7Wm/b98+mq9YsYLmrA6i9ezNzc2Z2ZYtWzKz8JXdzJ40sx1mtqHLx+4zs7+a2briH35YtYjUXE9+jF8C4PJuPv4Ldx9b/PNieaclIuUWFru7vwZgVxXmIiIVlOcXdDeZ2frij/knZn2Smc0xsxYza4muPxeRyim12H8J4JsAxgLYBuDnWZ/o7ovcveDuBbaYREQqq6Rid/ft7v65u3cAWAxgXHmnJSLlVlKxm9nwLn+9GsCGrM8VkfoQ9tnN7CkAlwJoNLM2APcCuNTMxgJwAK0AftCTO3N32u+O+q5sDXHUc432II/WTh88eDAzi+adZ3/znsjzmEbrtlmfHIj3T4/WjeeR57qLaI8B9nwDwNq1a2m+d+9emrPnLForf80112RmS5YsyczCrzJ3v66bDz8RjROR+qLLZUUSoWIXSYSKXSQRKnaRRKjYRRJR9SWurBUULUPNsyVz1KaJtqKOWkzMnj17Sh4LxO0v1jbMM28gfk6ifxtrI0Vzi9qp0ddDtDU5Ey23XrRoEc2jVi9bFr1z5046duLEiZnZs88+m5nplV0kESp2kUSo2EUSoWIXSYSKXSQRKnaRRKjYRRJR1T57JOrp5tl6OOqjR0s9n3vuucxs9erVdOzKlStpHi1pjJaJVvL436hfHD1u7HGfNWsWHRs9LlOnTqV5oVDIzKIlqO+++y7NX3/9dZpH13Ww/JxzzqFjL7zwwsyMXXugV3aRRKjYRRKhYhdJhIpdJBEqdpFEqNhFEqFiF0lEVfvs7k77stH65sOHD2dm0TG3f//732m+fPlymj/44IOZ2ebNm+nYqFcdrduupGgL7SFDhtA86iezXvnPfvYzOjY6Fvnuu++m+Y033piZ3XLLLXRs9Jxu376d5tG1EWyPgp/+9Kd0LFtrz77W9MoukggVu0giVOwiiVCxiyRCxS6SCBW7SCJU7CKJqPq+8VFfl2E9W3enYxcsWEDz+fPn05ytfz7hhBPo2OjI5t27d9M8wq5PaGhooGPPOOMMmo8ePbqkOR3DriF45pln6NimpiaaR/urL1y4MDNbtmwZHbtt2zaa9+/fn+bRPgJXXHFFZjZjxgw6tlRh5ZnZSDP7k5m9b2YbzWxu8eMNZvaKmW0qvj2xIjMUkbLoycvsUQC3u/s/ARgP4EdmdjqAOwCscvcxAFYV/y4idSosdnff5u5ri+/vA/A+gFMAzACwtPhpSwFcValJikh+/9B/oM3sGwDOBfA2gGZ33wZ0fkMA8LWMMXPMrMXMWtrb2/PNVkRK1uNiN7PBAH4H4Mfuznfr68LdF7l7wd0L0S9cRKRyelTsZtYXnYX+G3c/9mvM7WY2vJgPB7CjMlMUkXIIW2/W2Td6AsD77t61P/U8gJkA5hXfrujJHbI2VLR1MNtK+o033qBjoyN2o62F2RLaaClmtIT19NNPp/kNN9xA8ylTpmRmo0aNomPZ0cFAvAQ2j3nz5tF8/fr1NL/33ntp/uqrr2Zm0fPdpw8vjai1Fj2ud9yR/fvsqFXLtlxnLeie9NkvAnADgPfMbF3xY3eis8h/a2bfB/AJgO/24LZEpEbCYnf31wFkfavJfkkRkbqiy2VFEqFiF0mEil0kESp2kUSo2EUSUfUjm1kfMOqzs22oH3vsMTp269atNI+2/mU52+IaiOc2fvx4mp999tk0Z9sHR8dgHzx4kOZ5HpdItDT429/+Ns2nTZtG87fffjszO3DgAB2bdwvtBx54gOYTJkzIzNg20wC/9oH16PXKLpIIFbtIIlTsIolQsYskQsUukggVu0giVOwiiah6n532AYO106xn/OKLL5Y8JyDubbJ85syZdGy0Hn3w4ME0j7DHhe0B0JM8uvYhsn///swsesyj7b/vv/9+mrN/26BBg+jYaI+C2bNn05wdFw3wPv3AgQPpWHa9CbuORa/sIolQsYskQsUukggVu0giVOwiiVCxiyRCxS6SiKr22Ts6Ouja76i/yPbyfvnll+nYqVOn0jzqq7JeeEtLCx374IMP0jxazz558mSas7lFR1lHPvnkE5rv2MHPBlm8eHFm9tJLL9GxeY+yZvv1R+v4R44cSfObb765pDkdE32tM6wOtJ5dRFTsIqlQsYskQsUukggVu0giVOwiiVCxiySiJ+ezjwTwKwAnAegAsMjdF5jZfQBmA2gvfuqd7k4Xlffq1Yv2F6P914877rjMLNpj/KabbqL5448/TvP29vbMbOPGjXRslEd7r1988cU0/9a3vpWZReeIv/POOzRfu3YtzaO5sz5/dEZ6JOqFX3LJJZnZ6NGj6djofPWzzjqL5vWoJxfVHAVwu7uvNbMhANaY2SvF7Bfu/m+Vm56IlEtPzmffBmBb8f19ZvY+gFMqPTERKa9/6P/sZvYNAOcCOHauzk1mtt7MnjSzEzPGzDGzFjNrYT8Ki0hl9bjYzWwwgN8B+LG77wXwSwDfBDAWna/8P+9unLsvcveCuxeamprKMGURKUWPit3M+qKz0H/j7ssAwN23u/vn7t4BYDGAcZWbpojkFRa7dS6jeQLA++4+v8vHh3f5tKsBbCj/9ESkXCxaAmlmEwD8B4D30Nl6A4A7AVyHzh/hHUArgB8Uf5mXqVAoOFsO+re//Y3OZdiwYTRnon/nihUraM6W0K5evZqO3b59O82jpZxsSSPAt3vOu8Q1Gj9gwACajxgxIjOL2luTJk2i+fTp02nOjkWORG3g6N9dK4VCAS0tLd2uc+3Jb+NfB9Dd4HwbtYtIVekKOpFEqNhFEqFiF0mEil0kESp2kUSo2EUSUfUjm5k8ffS2tjaaDx8+nOZRz/aqq67KzLZu3UrHRlsm79q1i+Zr1qyh+e9///vMLOrRX3311TQ/99xzaX788ceXfPvREd29e/emebQdM7v+gB17DMRLd/8/9uH1yi6SCBW7SCJU7CKJULGLJELFLpIIFbtIIlTsIokI17OX9c7M2gF83OVDjQB2Vm0C/5h6nVu9zgvQ3EpVzrmNcvdu93+rarF/6c7NWty9ULMJEPU6t3qdF6C5lapac9OP8SKJULGLJKLWxb6oxvfP1Ovc6nVegOZWqqrMrab/ZxeR6qn1K7uIVImKXSQRNSl2M7vczD4ws81mdkct5pDFzFrN7D0zW2dm2ZvcV2cuT5rZDjPb0OVjDWb2ipltKr7t9oy9Gs3tPjP7a/GxW2dmfJOAys1tpJn9yczeN7ONZja3+PGaPnZkXlV53Kr+f3Yz6w3gvwFMBdAG4M8ArnP3/6rqRDKYWSuAgrvX/AIMM5sIYD+AX7n7mcWPPQRgl7vPK36jPNHd/6VO5nYfgP21Psa7eFrR8K7HjAO4CsAs1PCxI/P6Z1ThcavFK/s4AJvd/S/ufgTA0wBm1GAedc/dXwPwxW1sZgBYWnx/KTq/WKouY251wd23ufva4vv7ABw7Zrymjx2ZV1XUothPAbCly9/bUF/nvTuAP5rZGjObU+vJdKP52DFbxbdfq/F8vig8xruavnDMeN08dqUcf55XLYq9u6Ok6qn/d5G7nwdgGoAfFX9clZ7p0THe1dLNMeN1odTjz/OqRbG3ARjZ5e8jAPAdG6vI3bcW3+4AsBz1dxT19mMn6Bbf7qjxfP5XPR3j3d0x46iDx66Wx5/Xotj/DGCMmZ1qZv0AfA/A8zWYx5eY2aDiL05gZoMAfAf1dxT18wBmFt+fCYAfP1tF9XKMd9Yx46jxY1fz48/dvep/AExH52/kPwTwr7WYQ8a8RgP4z+KfjbWeG4Cn0Plj3Wfo/Ino+wCGAVgFYFPxbUMdze3X6Dzaez06C2t4jeY2AZ3/NVwPYF3xz/RaP3ZkXlV53HS5rEgidAWdSCJU7CKJULGLJELFLpIIFbtIIlTsIolQsYsk4n8A6NM8DY2lChkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Displaying another ekush Image with label\n",
    "\n",
    "print(\"Label:\")\n",
    "print(train_data[2][1])\n",
    "\n",
    "show_img = train_data[2000][0].numpy().reshape(28, 28)\n",
    "plt.imshow(show_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "(1, 28, 28)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# One Image Size\n",
    "print(train_data[0][0].size())\n",
    "print(train_data[0][0].numpy().shape)\n",
    "# First Image Label\n",
    "print(train_data[59][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-1:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 100, Layer=2, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 100\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        ###self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        ###self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        ###out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        ###out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_out): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6466644406318665. Accuracy: 63.26597131681878\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.5699825286865234. Accuracy: 62.25554106910039\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.6033549308776855. Accuracy: 60.95176010430248\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.46783164143562317. Accuracy: 61.408083441981745\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.5231016278266907. Accuracy: 61.08213820078227\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.3803236782550812. Accuracy: 59.97392438070404\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.33501487970352173. Accuracy: 61.016949152542374\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.29279202222824097. Accuracy: 59.680573663624514\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination1.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-2:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 100, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 100\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=100, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6700134873390198. Accuracy: 61.04954367666232\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6108580231666565. Accuracy: 62.190352020860495\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5247443914413452. Accuracy: 61.08213820078227\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.4944919943809509. Accuracy: 60.33246414602347\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.43107855319976807. Accuracy: 61.11473272490222\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.3726526200771332. Accuracy: 60.33246414602347\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.28857576847076416. Accuracy: 60.234680573663624\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.2978760898113251. Accuracy: 59.51760104302477\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-3:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 150, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 150\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=150, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=150, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.5931234359741211. Accuracy: 60.72359843546284\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6014130711555481. Accuracy: 61.73402868318122\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5391729474067688. Accuracy: 61.3754889178618\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.436341792345047. Accuracy: 60.5606258148631\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.4568038582801819. Accuracy: 61.11473272490222\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.39042720198631287. Accuracy: 59.32203389830509\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.2727600932121277. Accuracy: 58.60495436766623\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.2748830020427704. Accuracy: 59.41981747066493\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination3.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-4:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6119794249534607. Accuracy: 59.8109517601043\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.5742093920707703. Accuracy: 61.17992177314211\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5696818232536316. Accuracy: 60.46284224250326\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.4082745313644409. Accuracy: 61.73402868318122\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.3982463777065277. Accuracy: 61.17992177314211\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.2773303687572479. Accuracy: 60.821382007822685\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.25303176045417786. Accuracy: 59.84354628422425\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.19630208611488342. Accuracy: 60.234680573663624\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination4.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-5:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=SELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.SELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.SELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.SELU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): SELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): SELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): SELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6808386445045471. Accuracy: 60.658409387222946\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6340527534484863. Accuracy: 63.005215123859195\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.6265541911125183. Accuracy: 61.83181225554107\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.5520623922348022. Accuracy: 61.473272490221646\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.540344774723053. Accuracy: 61.04954367666232\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.5025638341903687. Accuracy: 58.3767926988266\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.439458429813385. Accuracy: 58.93089960886571\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.36621078848838806. Accuracy: 57.98565840938722\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination5.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-6:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=RReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.RReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.RReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.RReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6574615240097046. Accuracy: 61.73402868318122\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6288185119628906. Accuracy: 62.54889178617992\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.6098566651344299. Accuracy: 62.222946544980445\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.566916823387146. Accuracy: 60.95176010430248\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.5785497426986694. Accuracy: 60.33246414602347\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.4859604239463806. Accuracy: 62.15775749674055\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.4512924253940582. Accuracy: 61.86440677966102\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.34036263823509216. Accuracy: 60.49543676662321\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination6.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-7:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=Sigmoid, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.Sigmoid()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.Sigmoid()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.Sigmoid()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): Sigmoid()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): Sigmoid()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): Sigmoid()\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6430050134658813. Accuracy: 60.267275097783575\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6395496726036072. Accuracy: 62.48370273794003\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5720251798629761. Accuracy: 63.46153846153846\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.5299933552742004. Accuracy: 61.76662320730117\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.49344882369041443. Accuracy: 61.08213820078227\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.3312402665615082. Accuracy: 60.75619295958279\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.2854247987270355. Accuracy: 61.3102998696219\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.19341878592967987. Accuracy: 60.43024771838331\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination7.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-8:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=GELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.GELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.GELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.GELU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): GELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): GELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): GELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6185833811759949. Accuracy: 61.73402868318122\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6002343893051147. Accuracy: 61.17992177314211\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5852234363555908. Accuracy: 61.21251629726206\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.41584208607673645. Accuracy: 61.08213820078227\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.36505958437919617. Accuracy: 60.202086049543674\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.30104655027389526. Accuracy: 61.636245110821385\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.1895689219236374. Accuracy: 61.994784876140805\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.1508558839559555. Accuracy: 61.70143415906128\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination8.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-9:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=RReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.RReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.RReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.RReLU()\n",
    "        \n",
    "        ### 4th hidden layer: 100 --> 100\n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        self.relu_4 = nn.RReLU()\n",
    "\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "         ### 4th hidden layer\n",
    "        out  = self.linear_4(out)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        out = self.relu_4(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_4): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6428923606872559. Accuracy: 60.59322033898305\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.6178381443023682. Accuracy: 62.41851368970013\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.64544677734375. Accuracy: 61.86440677966102\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.5416417121887207. Accuracy: 61.53846153846154\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.5808335542678833. Accuracy: 62.05997392438071\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.41756656765937805. Accuracy: 60.071707953063886\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.4976995885372162. Accuracy: 62.64667535853977\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.46871358156204224. Accuracy: 62.51629726205997\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination9.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-10:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 250, Layer=4, activations=RReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 250\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.RReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.RReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.RReLU()\n",
    "        \n",
    "        ### 4th hidden layer: 100 --> 100\n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        self.relu_4 = nn.RReLU()\n",
    "\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "         ### 4th hidden layer\n",
    "        out  = self.linear_4(out)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        out = self.relu_4(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=250, bias=True)\n",
       "  (relu_1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_2): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_2): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_3): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_3): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_4): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_4): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_out): Linear(in_features=250, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6583731174468994. Accuracy: 59.55019556714472\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.655173659324646. Accuracy: 59.61538461538461\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5829250812530518. Accuracy: 60.72359843546284\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.6130525469779968. Accuracy: 62.35332464146023\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.5475453734397888. Accuracy: 61.04954367666232\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.43134403228759766. Accuracy: 59.55019556714472\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.5224820375442505. Accuracy: 59.58279009126467\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.3538530766963959. Accuracy: 60.43024771838331\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination10.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-11:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 250, Layer=4, activations=GELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 2\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:139\n",
      "Test dataloader:16\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.GELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.GELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.GELU()\n",
    "        \n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_4 = nn.GELU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_4(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_4(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): GELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): GELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): GELU()\n",
       "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_4): GELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Iteration: 500. Loss: 0.6140651106834412. Accuracy: 61.3102998696219\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Iteration: 1000. Loss: 0.5220586657524109. Accuracy: 61.92959582790091\n",
      "8\n",
      "9\n",
      "10\n",
      "Iteration: 1500. Loss: 0.5599929690361023. Accuracy: 61.08213820078227\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Iteration: 2000. Loss: 0.45066502690315247. Accuracy: 60.5606258148631\n",
      "15\n",
      "16\n",
      "17\n",
      "Iteration: 2500. Loss: 0.33738404512405396. Accuracy: 60.98435462842242\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "Iteration: 3000. Loss: 0.26570093631744385. Accuracy: 61.53846153846154\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Iteration: 3500. Loss: 0.22036413848400116. Accuracy: 60.625814863102995\n",
      "26\n",
      "27\n",
      "28\n",
      "Iteration: 4000. Loss: 0.20406502485275269. Accuracy: 60.49543676662321\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/Ekush/ass-2/model/combination11.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Best Model\n",
    "Best Model: Combination-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model Loaded\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('E:/CSE/softConputing/Ekush/ass-2/model/combination9.pkl'))\n",
    "    print('Trained Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deZgdRfm27zqZLKBEA4jBGNxYDARUkAgKP0UFERAUZYm7LG4ooogg6gWoCCoggoiCsgq4IPKJiggoKhDZXZAlIItEA4KAJEDIJNPfHzN3d5863TPnzEwmnKSe68o1mTN9qqvfqq563rfeJWRZRkJCQkJC96KxvDuQkJCQkDAypIU8ISEhocuRFvKEhISELkdayBMSEhK6HGkhT0hISOhypIU8ISEhocsxooU8hLB9COH2EMKdIYRDRqtT3Ywkk2okubQiyaQVSSbDQxiuH3kIYRwwF9gWmAdcB8zOsuyW0etedyHJpBpJLq1IMmlFksnwMRJGPgu4M8uyu7IsWwz8ENhldLrVtUgyqUaSSyuSTFqRZDJM9Izgu9OA+0q/zwNeNdgXQgiD0v8QAgAjiTZtNPr3pr6+vmG1Odj18d/qrg0hPJhl2XMYhkyGIwO/Iyr6M2ib7T5XO/eu6wOwqPT/QeUSQshCCC39idv2c8d86dKlQ/Z3kHvW9XtZom2ZwPDnSll+Xjtu3DigkNloPX9VOyNoe9gyEe3M6VgWg9yr8nvOv/HjxwPQ29sLwOLFi4e8d7xeDfL3hwbWlEqMZCGveoNbehpC+CDwwXYanDBhAlAIdMmSJbZR3GBAGD6gUBDPfOYzAXjssccAmDhxIgCLFi1qur5OuHXXV/3N3x2w0mDcW/paWzKxP4O0CUBPT+uQ+V0nlv1TRn7uBGv3uZ566qn+BxiQUfnejo1jFr8wfreEhdHv8QvYJJPx48fnMrA/wn764qy66qoAPProo/k19tV+1sHr4uuH+l6p38UDdb5QDSqTgfZb5op9dXyVU13flFP52tVWWw0oZBbPgaEW3zrCFC9mVW3X9bPmfkPKpNFo5P3w/rZjP/y8alxdM/73v/81PZtt+DOeh89+9rObPn/+858PwL/+9S8A7rnnHqAYr6r3b5VVVgGK9yXuX2k9u5dBMJKFfB4wvfT784F/xxdlWXYKcAoUu6cvv512EHzQePGqmkxVEwaKBXzzzTcH4NWvfjUAb3jDG4BiIq+99toA3H///QCcf/75APzsZz9rudeznvUsoBhoEU/MSZMm0dvbW97Zh5RJo9HIJkyYkA9k3WQXgy0wymLq1KkAPPDAA02fT5kyBYBHHnkEgNVXXx2AHXbYAYA11lij6e+XXHJJUztOKoDHH38cKCagY6rcp02bBsDvfvc7ent7eeSRRyaUutoil3ieLF68mGc84xkAvOUtb8nbAnje854HwF133QVUL2S+PDHjjDe1uoXbF8zxqFvQfO6yLDrAoDIZuG8ul56enmzy5Mn5+MSINyX7XO6Xc9n35I1vfCMAb3/724HWd9I5Ei/ctvnXv/4VKMbmb3/7W0u/bNMFT9krY+dSBdp+fxynuvejbrOD1vfaBXnLLbcE4M1vfjMAG2ywAVCsPc997nObrred//znPwAsXNi/T1900UUAnHvuufk9/v3v/sdasGBB071t03fOcRoKI7GRXwesF0J4UQhhArAn8PMRtNf1KDGDCUkmBQYWlklprrQgyaQCSSadY9heKwAhhB2A44FxwGlZlh05xPVNjNydeag+lFV6GVb8HdnmW9/6VgCOOeYYoGAUMWQ1kyZNAgp2cPrppwPw1a9+Nb823j1lik888URd/58C/kWbMimrhsJdXwYZM6UqJihjjnf5WbNmAQWjUEvZeeedgUI7kbU6LmeffTYAn/rUp4Bm5hKbgnbbbTegkPtaa60FwBe/+EUADjvssDvpV5OHnCvOk9e97nUA/PrXvwbgllv6nRfmz58PwDe/+U0Arr/++ibZQLOZpYxYrrFJ4Mknn2ySQWzKUsa2X2VuGsruWULbMhlot0l7U/aTJ08G4MEHH2y6fvr0foX5RS96Uf7Z61//egBmz54NwPrrrz9oB53jmq+EDFg5PvTQQwD84Q9/AOCHP/xhfu3ll18OtM5LTRMVY3UHHa4pdW1pQnI87Xd5Xdhss80AeOc73wnAa1/7WqBZblC8546zc2bu3LlAwabVemJttfz8hx9+OABnnnkmAA8//DAw6Ny5IcuyV1bJAEZmWiHLsl8BvxpJGysobh5M6Csp/pdk0oIkkwpkWTb47pLQghEx8o5vNrB71u06dSfO5cMar9HmpR3rgAMOAGD33XcHCuauDc+DB9vaaaedmu7l9TKMv/zlL/nfZH6ydSEjkpWVbH2D7p5lhBCynp6e2nOB4YyPLOTzn/88AB/+8IeBQpOIWb5sRcatjV37nEzlqquuyu8hs/Gn8vSsQdkos7322qsjmZSfQ3anLV94vnH11VcDcM011+R/+81vftN0jcyyXZtjbM+tY9flA7Bh2Mjblgm0vj8yvfhcZZtttgFgv/32AwrNBgom6nukXHxOD+q8TpbpdcK5JGLHBBk6FO/PySefDLSyZrXi0nlEtStUBerWFDUn303vuf322wPwuc99Lm9jiy22AFq1tH/84x8AnHfeeUCh8Xgv2bTvqO+Nz7P33nsDxZpU1t7UIFx33vve9wLNmgwU2tZjjz026FxJIfoJCQkJXY4xZ+Rlt0F3T3cq2c0gp9g5Pv3pTwOw//77A4U98NprrwXgyCP7TWvar2677TYAnvOcfldM2Yy7pe3495hxQLEzv+td7wKKnTj2BqFDRh5CaGHJFdcBrWy6jHXWWQeA4447Dihs4MpXxi0zOuWUU4DifEDmrizEBz/Y7+l16qmnttxTeR100EFNP4UseYsttuhIJo1GI++38j722GOBwl4bu4OVPZgcC+9/3XXXAYW9/d57+7259DCIWWEd1BK0d1bN53bbYpiMPG7f32V1aqczZsxoaSO2r8c28Msuu8x7AYW9OHahK2vJUGg6MuGyXPyb76bnKHpFlZ6PLMs6YuQ9PT3ZaqutVnsm4vmP78See+4JFGchVc/2mc98Bmid77Hni9qKMrUPvk/eY9111wWK9w0KLclr1GAOOaQ/K4FrjfJcuHBhYuQJCQkJKzJGdNg5HFTZGocKWNFPE+C73/0uUNhLZabubGeddRYAP/95s9eSDCI+2f/GN74BwA033AAUp8naGcv92mWX/mhh7Wtf/vKXgYL9xYE07SLLshaGHXtXiKq2tfEpm0022aTp929/+9sA3HHHHUAhK7USmYYMT2Yh+9x6660B+MEPfpDf0zaUiV4Q4r77+oN+9XzpFH19fXm/tLNrL/zoRz/a1D/938uePHrNaBPVF32fffYBCkZu3MCf/vQnAObMmdPUVszC9A2WsbbhmTKqaDQa+Thpk9UWrubks1f5VssWfQ9uvfVWAGbOnAkUDDxm3M5xtU/nofNAm68oezjJKvVZV5NVW7777rubPu8ES5cu5dFHH81ZtVqpjPeTn/xk0/PZr3JMhNrV0UcfDcBpp50G1PueqwHp6x1/rtydQ3feeScAe+yxR36tGsK73/3upn7bhz//+c9AMT5DITHyhISEhC7HmDPyKtR5Bsg03/GOd+SfycQ9XdfeduONNwIFs3aHjv1+hbun0P/VCDdZLRR+11/5yleAwo7lifNRRx0FDMtrIe+rrMl+x+H2wud56Utfmn/m7i5j3XXXXYGCbWrvj0ON4/7GJ/72Yc011wTgJS95SX6tY+Oze41eItr4ynbBTmG/PTP5zne+A8BNN90EFIzJSM9XvOIV+XeNJ/CZtRer3cmANtxwQ6Bgavqqq1FoM3ZeyeRL3gT5PWWxbdjGh4VGo8Gqq66aawVGK++7775AwcSVSzzHAf74xz8CxXsjI/y///u/putiW7qsNT6f8Dpt7XH+GyjmURxNqiZx/PHHAzBv3ryhhRAhhMDEiRPzuevZmecF8VmXUZbleakP99///vema+t80P3pu6pMYo8ox0FmXrYGfPaznwWK9+Y1r3kNUMxLNYkvfelLQDEf65AYeUJCQkKXY8y9Vsrss/Q5ULAnfVjdlfSHhoIxuYtrP7XNOq+COo+CdjwM7I/MV79qd2B309tvv92vdOxHHvvhxomGZBYf+tCHgEIrALjiiiuAQk7aHmO51uWnkVnIEozGFFdeeSVQsDkoPElkEDKzr3/960Bx9iDboUOZlH+vG6PYjq39FwqbrVF22sg33nhjoMifYdsl74Cm343qVaO78MILgSKnyE9/+tOW/quptWE/H5bXiizua1/7GgAf+MAHmu7nnFfLOOecc/I2ZHg+j948alvK0LgLn+973/seUHjEvO997wMK+Xlvz6bUYADe//73N91D6Klh/3/xi18AnfmRNxqNbPz48bmnlfNP/Pe//wWK8x37Xz5PEc6jujiXeB7GWkmcbKsu+Vy5rRe+8IVAEaPhO+o69p73vMf+J6+VhISEhBUZaSFPSEhI6HKM6WFno9Fg0qRJufoqVHNUQVTbDz30UKAI2gDYa6+9gCJ8NjbTlB39oVXdjNXzuuTv5XBaTREepJh8ygM/k0pp9ugUS5YsaTILlPureUnVUbVd0wUU6uRQKQ5ik0r8edXhGBTmiK222ir/LE7vqtlJl0dNKnVufJ0gTuAf5572uctjb/9MsGXKW9vyMDsOkV5vvfWavm+SKQ9UHXvhgR0UB+7OWw9p7aeqdjz/O4V90rVSKB/NJpoTjjjiiPwazRkeiOvCqAw1vfzoRz8CClOm42wQz3bbbQcUiaW8t267fh+KdAmaCZxnHhIedthhQP9ho04M7aKnp4c11lgjP0CNoYugB+VVOdzjxGjOL8fLORI7B9Q5N2gGjce57PLo33xeD3p1YvCemliGQmLkCQkJCV2OMWXkfX19LFy4MHeTkmm725t4SearS1OZfZoEK2beoq70WF1FExEf+paZvrunu7gHOptuuilQMCTTxRqK3A4ajQarrLJKzt7sl+HyHmj5ue5+/iwjfqa6sH6fNS5tJQuNE4jFQUnlNnQzNJw5diGTdY2EkdelO1ZmcaktaK1g5O/2w8M4P5exy7LUkHQ99YDb4CgDYxxzKA697Y8pBTx0NKgmPljtBI1Gg3/+859NfY/D7D2EP+GEE4DmBFbCfvu8HmYa5Kac4qIqupfqfhlXhvJ6DxmhcIP9yEc+0tQHmbAMdvLkyXn77aK3t5f58+fnYfDxYbXuprqN+v6XNeDY1beOgYtYk421zrpxrfrcQ3nb8Kda1YEHHggUaTXqkBh5QkJCQpdjuQQEaT/VVqad7sQTTwQKe6TMt7wb1THxuFZfjHZrMFYhLpl1xhlnAEV4+qte1V8fVjerThh5X18fTzzxRN5/A1fcid31DVj6/ve/X9uWNr24fJkMI04OJDsx+Y8JhmLIbgzxh8IGqn0+DoZwbOvGazAY5CFDitl8fJ7hc5TdxeqCnmL2pNxLbpJAwfadg5YyMx2AKQl0nYPCvu48kPUadn3xxRcDw7eRKxfdXD0nctwcZ59FFl0++1CmBgSZYtZximWtjGWOH/vYx5radC7FqV/L75v90pXT91tNolykok6jroNBUieddBJQyDpOKWAwn2dOg81L35O40EpdHdM6bdM56PfK42CQo2czsWum8o4LetQhMfKEhISELsdyYeRx2TJPrXWOv/nmm4HiBD0ujgoFs4oLTbQb4BRfN1TV8PI1ekL8/ve/BwpGbsKhTpFlWW4nlPG4Qxuaa+k5AzWqECfrkUnLLn027YP2WzmXvVKgYHaOl/ZTKBLgx8w29kAajiaUZRmLFi1qsUUOVT2+HBYeM3HZUNyfWEuJbZae49ie8veMwjJzUHiw6EEhIzfJl2xVRj2clA59fX0523T+mSAqnruG8MfFCqDw2nnBC14AFMw1DkzTC8Wi2vG5iXLStm36aDUYKFIHeJ6itinbNLXC7Nmzcw2hXfT19bFo0aL8HM1zCrVltR89ZgymKheW8FzH9SguFu0ciT3g4gIfah7OJc/OTIPg+wbF+61moHbiu6rWcsEFF7Qlh8TIExISErocyzVplmHTFneQaWh/NZVjFdr1gmi3EK4MpIqZ13m4yEJMBxD7gncC++cOLSvQG8T0qqLqXrGdM/b2kG1q39VeGNvn/J6MSbagn3T5HrEtOvaMGQliO+xQ7L58z3jc68qixZ47dcnV1A5s188vvfTS/FrLAxpqLouVoZvIKw4j7wTluag3iP7ksuyXv/zlQJG+Qs8bKORhcjgLg8Q++XXxF3GsgXPCswTTAZehVuP8jAuoq3Hfddddw9JSyvNC27NxDc5x++3cLyfF037uO6ZXUF1f4rXH98Q0wjvuuCNQjEPZf1x4pqTmYvyFcjeFRLtzJTHyhISEhC7HmDLyEALjx4/PdzSjNN3RtCHGRY7L/sF1xSditMvE2ylyHP8tto252w83jW2j0ch3aEvWaZczWtQE80aqlYtDy3Q22mgjoIgGsw1ttWo+ZVsdFIzG5FivfGV/bh7HRW+DMpuNkyWJ0WDiIQSqkqvp3aRNWJ9lx0HNyDagSFsa+1LrqVOOGoaCPXnvOHWpiFOZltsy0teCHkbGfvzjHweKRFV6sbSLLMua5phpV7U5axf2p3ZWvWigmLuObezxo+3bcYw1L+VpCT3t3vrhi3JSKn3OjbuI4xIct3vuuWdY75Al4vw/FLEoenuZUG6zzTYDmhm5ZwgmQjMJnVqGqYyFCcO0u+vD7nmDsvTetifTh8IDzHdOOD5qNlXng1VIjDwhISGhyzHmNvIQQm47Mk+D0D87Zk9l1lMXleguH/t+Lgu448a5TMpeE+0ihMCECRNyhqe9TsarffMnP/kJUDBFy0dBIa8tt9wSKGQRR/wJWcC5554LwG9/+1ugYAznn38+UBTxsL2yXT72For9+GM7aKcIIbT4+prfQy8bU+iKsn927BeulhcXHa7rn+Mhc9d2LmP0+cu5MDzjUb6f+MQnAPjlL38JFBqEY9wpI4/767iYAlVvLzUBtQu9RqCw33pe4jxTHo6jv5u62PMqx8TzIcfZduLcRVCcFahJOU7OJxn71KlTW0rMtYNx48a1nM3YH2VsjhjzOKkdQcHO1ZzMd6I9PY42VZ6Op3PKlL++V7/61a+A6hTZceFw4fPLxOPiKnVIjDwhISGhyzGmjDzLMhYvXpzbYN0B9ct293dXb3c3gqE9Gtz946x9dRiMXcvIbUuWVpWTZCjoM+399Es2L4UsW48HPUzKTFDfWVmU7FG5am+T1WujVQZxLpa4PJYsoTwOMjPlGrPnOMl+J3CeyOq0t8qcYibuPcreAf5fe7GsWKauXdZndQxlizKmuMCuRUZsRxZe7qf9kZl775133hlo1UTbRZyXxz47Pp6zyOZk3TJ1gKuvvhoo5m58lqT26/N7Lz+vKxIes84qW3dcSlA5KePrr78+n8OdYMmSJS0xB/F8dJ5anL0cIe069La3vQ0ozhSMa3HM4/dFqJXo1+/5QSyDsrbh3+JiFfF32o3DSIw8ISEhocsx5jbyLMtadjQzk8lG3fnaYeLtIt6hh2L7ZW8Md3P75e4pK5aJyXaGg9j7Q5n4syo6T+g7K8s0x7HfLXtzQKvPvPeWeciYZJs+57Rp0/I24myBQz1Pp2g0Gi2Z6sxAKOJ7V9kdjVWwuLD2/7gkoIhzU8eIbe9lv+q4pJfylSE7T4YqpFuHvr6+yvladx4U+8RDK3OOxynO0xN/Hmtg8b2ryvLFZQudX8rHfg5HoxXxmVmcU8f++t6XfcHNqKpHi89gmz675wTKLD6TMtvkF77wBaDwsTcuRr9/aD1zEfG61K4XT2LkCQkJCV2OMWfkjUajhQnKYGLfVnfEkeSyjlFl74XBK9nE/fC0Wtu0bQ3HC2E0IMtsF7LOuBqSzyl7Mf+G2HvvvfP/63NbxfpGA2VGrm+9Wf78XG8Cc/WU+2f+DtmfHi/KSlt4Xaa7OltwfJ5Q5ZEg29fvXU8Rc3THkbTdhDrN1ndDeWhfhtY8J74vMl/9rx999NEWZt0OynNFxAW5/bv39vwAimLj5sSJo1ktSi7jFr7/zi1zLan96aVj3Mbhhx+ef9eIbas4mcPH/hlx++CDDw7x9P1IjDwhISGhyzHmjLyvry9n3u58spw4R8iyQJw3pe40vsp3XVglxp3YyMfBcsOMBXy2Ol9cn6NOvvFzxrbecr7y0Ty/qEJ5PIyYtPajtklZ1o9//GOg2bde5i0jlx3NnDkTKDw5vI/XxbLRZ9jrYhu5PtBQeI1od5eJO9+99u677x702Z/OUHOV6eplEufsLkckemZT5xWlptLT09NxPvIY8fsce6lZMcgcLFDkSIlt9Nq0zYdiG65b1h3QO8kzppe97GVAkWHRLJRlTzMjTc1nb2yEXjUy8aozhyoMychDCNNDCL8LIdwaQvh7COETA5+vHkK4NIRwx8DPKUO1taLgySefZM6cOcycOZNNNtkkd2VaunSpQTUzVzaZtIGVUiaPP/44O+20E5tvvjkbbbRRnqZ1wCS13sr4/tx3331ss802zJgxg4022ig3LyxdulS305VOJiNFO4x8CXBglmU3hhBWA24IIVwKvB+4PMuyo0MIhwCHAAe3c9OYMcan/csSMeNyB493vDIz8Dva+HbffXe23XZbDj74YBYsWMC6665LlmXMnTvXr9wMXE4HMhkNxGcPdYh9vGVZcRX2+AyjHDkZV7Zv43S9Y5nIYPQzlmWrCTmP9M8uV24/++yzgaL2qcxae3vZtzp+NihkGediETLSuDISFDbSAw88kIceeoi11lqLTTfdlPnz57P11ltz8cUXaxNdkGXZep2+P8sTcd7/djxmjGeQJff09HDsscey6aabsmDBAtZZZx3uv/9+7r//fkII9PX1tS2TEALjxo1r8YOvy8K52267AUU+nPK1PoteRdbL1atFxGdMnpmprelPLpM3p7s1XAHWX399oDhL8F4bbrghAIccckj+fO1gSEaeZdn8LMtuHPj/AuBWYBqwC3DmwGVnAm9t644rAKZMmcKLX/xioH+xmTp1atWh30olkzax0slkzTXXzJNFrbbaamywwQY8+eSTmuOsULxSyWXttdduksnqq6/OwoULm4LAWMlkMlJ0ZCMPIbwQeAVwDfDcLMvmQ/9iH0JYa5CvNsGdL87LEFe8jqvNjAbiNmMmXmWT8jvu5v6cO3cu8+bN44477sj7bia2TmUyGqiqXTkYZBaxfE877TSgyIIY+8tDwYZjP+zBMNx5IswAaX/tzwEHHAA0V0+yKvxBBx3U1EbZFx5a88/X5TF3Xsjc9d4oez/suuuuQJFDWqamP/4ee+zBlVdeWfb86B2495jPleEirqjkPLCWqZ5E5ejbDTbYAChkWfYMuvfee3nggQeYNGlSk8fKcGUSv8/eU6ZrrpWqZ5KM7bvvvkBzhlEoNPI4F1RcG9U+KBuZuRWDgLyikVGkeqmYtVEt5pRTTql/2BLa9loJITwT+ClwQJZlrfpk/fc+GEK4PoRw/dBXdxcef/xx9t9/f2bOnNlRsp8VWSbDxYouk4ULF3Lttdfm4eDtYkWWy8KFC5k9ezazZs1qIglDoSyTsTDHdgNCO4IIIYwHfgFckmXZcQOf3Q68bmDnXBu4IsuyDYZoJ2s0GnmObbO06fVhvcpyBBQMLx/5IH0AOrPHm4PhzDPPzNvo7e1lk002Yfr06S3Ve4AbgLfQpkza7kgN4tzgsbdJXIswRlz/VDZ1ww03AAUjL/u0Gk1qzuU2MGKZOA+OOOIIoMguqFeIlXmgsDHqBeACqp1dJqRWqMdBXNnde8oWlZUVdvR4KN9D/3uZ9+mnn85JJ53E3Llz6enpKbPGv2ZZ9rJO3p/B/r48MVgchu+PB73Tp0+nt7eXHXfcke222y7X/PTuWLp0aehUJnH2xdhmvu222wLFHCm//9qudVrwrKsuj5Bt6unk39UU66KGy/ZuYwzsl7JRw7N/apsnnHDCDVmWvbJODu14rQTg+8CtLuID+DnwvoH/vw/4f0O1taIgyzL2228/pkyZkrsaVWClkkmbWOlkkmUZZ511FlOnTq0K/19j4OdKJZcsy9h7772ZMWNGkxvg+PHjywvsSiWTkaIdG/lrgPcAfwsh6Ch9KHA08OMQwt7AP4Hdlk0Xn36YM2cO5513HquvvnqeUTDCTOB/rEQyaQMrpUzmzJnDNddcw7Rp06rOeiaHEO5gJXt/rrrqKs4++2w23nhjNttsMxYuXMg+++zDxIkTeeqpp1gZZTJSDLmQZ1l2JVDnA/OGTm/Y19eXu/Po2mVJKguOxqaV4RRsqEPschergqrFurhBEbqryjR37lxOPPHEvEBABW7Osqxj2QwXQwYLDMgvTpal2SBeYDycs+DEm970JqA5Tawh8AZFDNUHOpCJ6VrjwhgGIRnerCuhJex22mmnvI0ZM2YAhZukz6r67jMZxKXrmM9h0JEqsAdVhmHbfpll64povz24mjx5MgsWLKgy580dTF1+OiIuouLc0ZShaaAcEGSCtXKqhd7e3lx2rgOnnnoqixYt4qmnnlqv037FJeniIuYGi91yyy1AERgGxVhqUomLpMQFxmM3XeHzaFKJ15jy+PuOXXjhhUDhQrvVVlsBRUETE8XF6QFipBD9hISEhC7HmIfoQ1GaypBr3fk0/Hto5A45mu6HImb57p6GcpfZtj7jHkj4Uxchmbq7f3w4sqxRp13UBQjF5djqwoAtXaV2Ui71ZtCL4fHKYjQQp2uNEykZ4m65Lq/1EB2KxFR1B1UeesoGZUa6J26//fZN3/cwVMg4b7/99vwzi/Wazli3s9ijSbfEdgvrPp0QOxvEB3uy1LL2ppbr3+LSg/PmzQP6g7biQh5DodFosOqqq+Zuoa4VjrM/LXZ8wQUXAIU7IhTrzqWXXgoUB4wWty7fC4r3zLbV+uJ1Kr6ujLiot3PaQ3Tf2bhQeh0SI09ISEjocrTlfjhaaDQa2cSJE/NdSCd4d0kLDbsTHnxwf3RuOT1sXNIpdieMw/kK7ZIAAAYeSURBVM29Vxy6a5CCO7PBHNpby0zLNKmx7X4QDOoqVMbTwaWsziVT5mhRC1kqFHI95phjADjyyCObPq/QEkYskzrNY731+k2qFouGoizcnnvuCRQs0O/Kovwp65dVeb0s0uAQWdvll18OwG233ZbfcxgpfduWCTw95kod4verzEK19/oeGXATF3I+9NBDueSSS3j44YfbzpylTGI7tojnjIWVjz766Pwaz+biYDDdik1zq6utmmnsXhhrtrZXdRZlAXpt46YMiIPILNO4ww47jMz9MCEhISHh6Y0xL75ctsP6fx3y3bm1kRswVE424w4la3dXl1WaHMmf2vBk3jK0WbNmAcUuqg3N0+Ezzjgjv2dsK1vREJfiEtpwTUZlGDbA5ptvDhR2as8ztD07LnVMaTio8zhy7M4777z82nPPPRcobN/6K5vA6PjjjwdaEyLJDrW5qvnJtrXh+ntZi4mLT7ThydN1iBOuxectohx8pszi9L0yW4tR77bbbnlh8E5R54Hl584VNahyIJdh+zJv7fuuEWpfBhN5fjaQ6TRn8M55x9+zJdecsl3elB56+cRapukojjrqqKEfnsTIExISEroey8VrRch6ZE2G6mvrNOHRiSeemH/HFJMm1tJnV2atT7rs3t1Rm6dMwWTwMkh3XRMvVbGpwcKQuxnxs8a2Qr0xyonxZS16h5x88slA4X993HH9QcCO03AQy7suBbFjWpVy9qKLLgIKO7qM3PQDjr/P6r3qmOdgsH/LsjDK8kZdQra4BF4ZfhYXobAt3/vLLrusMi1wO6grdCJDj4sal+eKCaz00rIghKzdNjwjMl5Bn/TYA861SNY9WEFvNTvno+dR55xzDtC+B1xi5AkJCQldjuXCyOOCrTIvowS1ecrmyt4S+lkaJSbc2dzBLB+lDVTbur692uuM6NPGV8U4tL+vaExcxMxWdqUslNG3vvWt/DvGAhiJpg169uzZQJFcv1x+rVPYj7pyfPZPO3zZXztOTercsj+Ot236UzYVI048FhfWgFamuTLBd8SxqNJglIsaoO+onkBnnHFGx+cKIQQmTZpU68UWj6/zolxuTpauzdt4BFnxLrvsAhQM26RyFoXwXmoT3stzI60IN910U35P17YrrrgCaE7BDJ3PocTIExISErocY+pHHkJ4EHgceGioa7sEa1L9LC/Isuw57TSwAsoEquWSZDICmcAKKZckk1YMa00Z04UcYCAZfFclCqrDaD3LiiQTGJ3nSTJZtu08HZBk0orhPksyrSQkJCR0OdJCnpCQkNDlWB4LeXvVRLsDo/UsK5JMYHSeJ8lk2bbzdECSSSuG9SxjbiNPSEhISBhdJNNKQkJCQpdjzBbyEML2IYTbQwh3hhAOGav7jhZCCNNDCL8LIdwaQvh7COETA58fHkL4VwjhzwP/dhiqrajdrpVLkkkrkkyqsSzkkmRSQpZly/wfMA74B/BiYALwF2DDsbj3KD7D2sCmA/9fDZgLbAgcDnx6ZZRLkkmSyfKSS5JJ87+xYuSzgDuzLLsry7LFwA+BXcbo3qOCLMvmZ1l248D/FwC3AtNG2GxXyyXJpBVJJtVYBnJJMilhrBbyacB9pd/nMfLJvdwQQngh8ArgmoGPPhZC+GsI4bQQwpQOmlph5JJk0ookk2qMklySTEoYq4W8qnRTV7rLhBCeCfwUOCDLsseAk4GXAC8H5gPHDvL1luYqPus6uSSZtCLJpBqjKJckkxLGaiGfB5TTFT4f+PcY3XvUEEIYT7/Az8my7AKALMseyLJsaZZlfcCp9Kt87aLr5ZJk0ookk2qMslySTEoYq4X8OmC9EMKLQggTgD2Bn4/RvUcFoT8/5veBW7MsO670+dqly94G3NxBs10tlySTViSZVGMZyCXJpIQxyUeeZdmSEMLHgEvoP20+LcuybiuE+RrgPcDfQgh/HvjsUGB2COHl9Kt19wAfarfBFUAuSSatSDKpxqjKJcmkGSmyMyEhIaHLkSI7ExISErocaSFPSEhI6HKkhTwhISGhy5EW8oSEhIQuR1rIExISErocaSFPSEhI6HKkhTwhISGhy5EW8oSEhIQux/8HQQFMXzz6vOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in test_loader:\n",
    "    break\n",
    "    \n",
    "fig, ax = plt.subplots(1, 5)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(images[i].view(28, 28), cmap=matplotlib.cm.binary)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.forward(images[:5].view(-1, 28*28).to(device))\n",
    "predictions = torch.argmax(predictions, dim=1)\n",
    "print('Predicted labels', predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies obtained for different Hyperparameters\n",
    "\n",
    "- for all combinations iteration=5000, learning rate=0.001, Optimizer=Adam, batch size=200, epoch=32 and Loss function=CrossEntropyLoss    \n",
    "Other hyperpatameters are shown in the table below along with Accuracy and Loss \n",
    "\n",
    "Combination|hidden layer| num_hidden | Activations  | Accuracy | Loss |\n",
    "-----------|------------|------------|--------------|----------|------|\n",
    "    1      |      2     |     100    |     ReLU     |59.680    |0.292 |\n",
    "    2      |      3     |     100    |     ReLU     |59.517    |0.297 |\n",
    "    3      |      3     |     150    |     ReLU     |59.419    |0.274 |\n",
    "    4      |      3     |     200    |     ReLU     |60.234    |0.196 |\n",
    "    5      |      3     |     200    |     SELU     |57.985    |0.366 |\n",
    "    6      |      3     |     200    |     RReLU    |60.495    |0.340 |\n",
    "    7      |      3     |     200    |    Sigmoid   |60.430    |0.193 |\n",
    "    8      |      3     |     200    |     GELU     |61.701    |0.150 |\n",
    "    9      |      4     |     200    |     RReLU    |***62.516***    |0.468 |\n",
    "    10     |      4     |     250    |     RReLU    |60.430    |0.353 |\n",
    "    11     |      4     |     250    |     GELU     |60.495    |0.204 |\n",
    "   \n",
    " \n",
    "  \n",
    "\n",
    "- **How hyperparameters were chosen**\n",
    "    - Firstly, layer size 2 and 3 were take along with 3 different num_hidden 100, 150 and 200. It was seen that 3 layered model with 200 num_ hidden performed best.\n",
    "    - Secondly, for the three layerd model and 200 num_hidden 4 diffenent activations SELU, RReLU, Sigmoid, GELU were tested. It could be seen that RReLU and GELU performed better than others.\n",
    "    - Thirdly, hidden layer size was increased from 3 to 4 for model with activation RReLU and GELU, num_hidden 200 and it could be seen that this model with RReLU activation gave highest accuracy.\n",
    "    - Finally, for the model in combination 9 num_hidden were incresed to 250 but the accuracy of this model was less than that of model 9.\n",
    "\n",
    "### *** Combination-9 performed the best ***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
