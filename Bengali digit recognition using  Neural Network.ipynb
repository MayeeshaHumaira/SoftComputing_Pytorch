{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-2\n",
    "- **Problem-1**\n",
    "- **ID=160204008**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem #1**\n",
    "\n",
    "*   Apply **Neural Network / Deep Neural Network** for the **NumtaDB** dataset and build a multiclass classification model that can recognize `[0-9]` Bengali handwritten digits with different hyperparameter settings.  \n",
    "\n",
    "\n",
    "### *** Approach ***\n",
    "- Our input size is determined by the size of the image **(height x width) = (28X28)**. Hence the size of our input is **784 (28 x 28)**.\n",
    "\n",
    " - When we pass an image to our model, it will try to predict if it's **0, 1, 2, 3, 4, 5, 6, 7, 8, or 9**. That is a total of 10 classes, hence we have an output size of 10.\n",
    "\n",
    " - Determining the **hidden layer size** is one of the crutial part. This can be any **real number**. A large number of hidden nodes denotes a **bigger model with more parameters**. \n",
    "\n",
    "- The bigger model isn't **always the better model**. On the otner hand, bigger model requires **more training samples** to learn and converge to a good model. \n",
    "\n",
    "- Hence, it is wise to pick the model size for the problem at hand. Because it is a simple problem of recognizing digits, we typically would not need a big model to achieve good results.\n",
    "\n",
    "- Moreover, too small of a hidden size would mean there would be **insufficient model capacity to predict competently**. Too small of a capacity denotes a **smaller brain capacity** so no matter how many training samples you provide, it has a maximum capacity boundary in terms of its **predictive power**.\n",
    "\n",
    "- Hence it is important to find the right hidden size for the specifed problem.\n",
    "\n",
    "\n",
    "**Snapshot from NumtaDB**\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://drive.google.com/uc?id=1LvkNwV1My2RniR_JsbasBET1fa97eMQu\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "\n",
    "### **NumtaDB: Bengali Handwritten Digits**\n",
    "\n",
    "**Dataset Link:** https://www.kaggle.com/BengaliAI/numta/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['archive.zip',\n",
       " 'model',\n",
       " 'model2',\n",
       " 'model3',\n",
       " 'testing-a',\n",
       " 'testing-all-corrected',\n",
       " 'testing-auga',\n",
       " 'testing-augc',\n",
       " 'testing-b',\n",
       " 'testing-c',\n",
       " 'testing-d',\n",
       " 'testing-e',\n",
       " 'testing-f',\n",
       " 'train',\n",
       " 'training-a',\n",
       " 'training-a.csv',\n",
       " 'training-a.csv.zip',\n",
       " 'training-b',\n",
       " 'training-b.csv',\n",
       " 'training-c',\n",
       " 'training-c.csv',\n",
       " 'training-d',\n",
       " 'training-d.csv',\n",
       " 'training-e',\n",
       " 'training-e.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'C:/Users/Mayeesha/Desktop/sc/NumtaDB/'\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAIAAACyr5FlAACjgElEQVR4nEz9WbOk15EkCKqqHfcbK3aABMEkc63qya7ulpEWmb8w/3xe5ql7OquyiskdBIgdCMRyr/tnqvNgx8FOJinCYCDCr3/fOWamm/GPv/2cUJ3FgAFJIKADxJEVBKKA7qMNhpLSNsGSSMuJT0EkiAEB0C2b+w9C8eQgaLJDEtVJUQzSSAWFtNHdxSOCQ5RAgJQXr05pCTkZMUH6DIt6iIgOkSbQghgGDqtkEUc7TYNgJEbog6W2sYTSiSrA7gMqUEvxVfY1bIgVqnnAPEWogyIg2yZUcKh0WGnEJgK0SJdRqmv5aMMgTRp9KiCrrFox4oggiOCOjeiAUQDlTo7DqahOQCOJzXgeDimXT61whQwAB2myCqESEmEbIYuQGVLKKQAYInLTAUTMH0y3SXAJJmPyr3/5NkGJiLstQ/RFomkfFRIIEwKRAQorSJgSkdgH0M5C6DAVRQySZkCmcX4sxTbbshEHSSLiECk6YJtgasFZqnnAAYgAvpJxnUQX6UNHEPaKZfbpdF65drMXq8k4FSAhcZSEFAgHRhNHDFiuUDmZgEKYCSGHEaoRuOcjoUQiV4ndSgSFhHgiIcQIOgeN2AnBFQLVlGisKwmYRMSA57YqBnINA7KjbtZqOkTmkxgULXSTIhfn65NNdqQAoopIIy2LgYEGIxRCdjxPnExYDE1WEZCPMEglKwDSLHap4LItBEEcnoRVNDvdfdgxTWmB6mUdUkjHgUUxrGsIww4XfSABVQIRqOuSVh/XdDfJWqecAurypmtJiWSdFbPDBZEnUA6MIAEA5XFwsckKKZIJVPONXRquVFJEwFgHCsbRlkRYdEIAKtgJaEDaX5KCGDmicnFJSbpzxGCY0uECO1fN9SeAVipBq2kqYABWgHQT6WJyVKuMJub8mqBbZYvH+UQuJEbTR2F1fBxHxRUEFFNADqgKQBS0YZglrdMiKDZAE1iEViCGToKAWRXXfB0V2HbiRGYCFyAJgWXQcwEBkcN0lKYIzWUEiTEQkKIb67g85HoKbBhWGMOrDdxBKcOUATQNsogqZBcdUEn5mna7Ya5UH1XN8wpI2FGQxA+JHJrXkJVaYqpitpoRsAALB6F5vD6FnnsRKJDq1WSEChglAJsWETsGGNtB4sZVFsQkuHQIoIollSjTpEX5iAJDSBighBAxiAUBMGw2OkVglRiEHYCSBWsdB8RmRykoLAdkGHnuVF6DKyOSUJxGehWlU5lxUgyAwzmaJBGCAAFKLOJIH7YCKCk2iwTSMKFFmAEgM50DMFJTQYoB6fk+GTmACqAAKyFiVrFINAKS+6qmIYXodbgKCUlIJaiiwtFZERogRYEwaaCQQAuaOy4AgkLVOp0sKNCJYQLQ5IkCVmjbSCfLbcWVgLGTzlXU1XqY9xUpogjAiDyPKKEcgXaHdHZf5Dlr0co1pAIEu7+gIuOQHBTBAIchkHFQaB/zfSgxCIWMUQTJ2B0AAkFWKHTYgN1MU2ytlEWoTiKQTDkAvGhc2V7LRgrTU4hBIc5UFfd0QT5gFSThEEFI0KkWSaD7enEcKGYUBjCmqEQh4hgmnMRTQFBLHYSlEG14OoMQoSi0wKhMBFHmdUCRKZKQ7QARudbpVFQixQ6sQrEauLbFOCRYRa25s2ATy4QXkaCBCkWCBAMrRmQyaoAsGYolBj5giYxICzgcRGHCA2EQ15WCrzDoNDwvM0WizFCdfe+BVKVa0QJDAGEBUqigJcVrlSsMkcSxDTRVARMRYAICCY5g0RBQqA6vTMQi5/cwRKPaCggYV7MOzLE5gylHMNhpEbVq+YxMk3PQjuOSeWFRimPHESxeuJZPABdJBAc7IRvGSg4WRDtJI06QBkEAkRQDQLEkQI6oKhAIEhERgLQJHO7uY0m0dxUPgzkkR64xPJcWCRALVsQQqWY3mqmwqNgpsiAAR5KmADM8LkiOUAFoM0nJVcWU29Pd0bQTHKsQsD1VrUopHG5YUAEiEnYkSIhUTE9/GCeNAAxYAFmokNNhIYdiqQ7RqgI5Pyqc2CGtYjiPnxAYJwyEAliZ6zthQPCkqkYaTBxakrQA5urIh3MbARiJEpvnbl8u5kFVqEbIVILSkbabRKLMDGMT4mkJAuYxQ4KCuOU8APGR2MgBJqVMx+6DpDkdfsJEopBGOxFKPM3FSXdDHdgAJAIEEykQGfLk7OJFMUwhjttMw0BECQUDWESQnJiQdtlGAala4JGC7XiGh8QucIpid4yu4so5AIsLFV8cYCY6AKB8hU4AyXlCB/Omw1ahzmt+VtZpCnACdkOqO+2SbyJCJLLsBuAQJOC2nTBpuVO8gpUocciIhXSAxExFIrGKRhi2g/0KznAKsMOju9Iki0Lsq0O26+CaS1RiKSwYpVTrqNNBLRaZIIFbreMiUJCDpEPyvGYihOAOQRaMvtAKyUOHpt0QQQsRqJrWwOwiCrsXCRju12534KETIEDSPhBGMMC58hK1mMUZOkFg5isomPEY1KlIGvMHOuHKcY25FqJlwjKvXCDpPuAoNdXXYK8BHpYfclehGCAlU/ARXBtSGJrgckXEAtgY9INVPuFYhCqoNthBWaUTkJ6rAnU1F4OQCyUmK3PQOmJS8hTKmUOTox1fAxFLUKnLGMyk4uKALUQqNgajgVHoxGEyjVpBRTFBkFJIg0SdmJYKawYlEp6qHSqiV+3GCKAo0UqZcjqHi+u8irKRoOBGxQ4a8dRLmGcqZ8DCraGilSOpTlqSoJl0AQjphKw1Tx9xOkzIPbqQ4tQTzldFuxt2CEzNcOY3ggFaAnAO5uLFAQbm57/70gOEiBCFBKmWDcoiM9Nx0LjWESQ5iVkrTNwCAllJXECiXJnYsukzTz3vO1GBphtJ1LmCtaLyAkkFMzTPIMbQ3SJEBrs1OQgURMWcxiyKZBwMOrr1ENMU2AirhCoCCDYU4UFQIoFUyMBzvBCR2k+MyUzXnKeCJtb0ToI73QYMrnKCJkqlaKpgnGzMbYpsAlKqYq62YRJIJQQ6mAawZANxbKZpZA55hKKoAGYQLceESlPAo0QG7Lh9rlhANG/B3I8zXdJpMrdGiySTwKFVFk4JGwg5jcZCUO5mIS6HQsSGw9Tl6IJNkQMtHITIIsVWK0kGOKFP5xxNIyzCCeLiKRBgwWUS6DRCMteTKcDVIEMfPo4wlKCSCEaUky4SZzWiXmzDpGac0dQhAyqi5ml2GrEgeykGI/YU2wAlkjKJPdCHpqzEiCmrCtPfk5ozie42WKGvUNrpIGQW1DpitSmCTtLiLloOpS5WQSFaZSN9JZ3MXy5DZISmCfIAFM7bTCZGmwcOdFzR9CctQqeSZdu4DUoJIzZJ7x7r1mpx/5ZaZJcFM7HnwM57aayfYMdFUAYPm8syWQ5sHMkqLAwmmmstMjHNtDyXLOOjU+RcyPtIApeOdKqoHVsAK2oklVqOqzva/aepY4mo1Q67gYTL0RTBhUZBLk5D7FBCcGjBJhoJa245kc04Ei0cmB4GZBVjBHQfgzrvy5aGSaIG6qJSAClosFsHPK4MUvSSoZmE2wQSK5nRtBNNO9SmEiqEAUrpWmUpoTuZQVZI0L4qWSsgEiaL1OJcPimIoEBGRrICpgaGCGYGjZiSGjSYWCGsADEgMRL2xWDuWzJIGiKJjbMnA92iGaBJCGwVWHVA16PQ05DWIYsHGzxiXO2CIiMEpcHBOF+mWd2efnuaVJqg0HKlwIK4ApIeGOZwQKM4gMcRHBCAquPgNFwCVZVa6AgAmiTMK3NF2FziolQtO5UUOjXlmSDtUJnjDYQBwnDRjUDdSUOwzk5xpa7IurZqECUYhgCRMY40gACOjJOqCUYnyGpyTl2cwJGKhBRUPDhjoq7T1A2lw0yHFEbAGQIJzSTLgRqK1SQoUol7cPjBmMhioWnBcQCHfUUZZOZhI4pZCEDumWTw4UHV0jZgQ/MrHCRMU16ajZnxBxKIlZwpl1YPBAFIoKpV3cZumhllDhkg2RSc6aAVFWeGKcJIrO5mV60iUoaoqw8ZVygbDOsegmvxRDUbaAyN0UCbQRNCLopDGPPv61HTVLID3VAfl6jbg+rohmnRyCDqtKG1lKiHiCA17XG4InpaGnrwhYRwaVUK2EU7hLhC93SLNaDmnh06M/4knJm4SA6OuhhSYKEEkt70CyQPBoiYB+CkwIPgETSasaCNIc4IKsUGhvRL3AFKwmaRwnI4JNLhoYxmUAeUEmI1E6CjaWJhGqGkU98dZQqAyjxN27SSxaWSpsQBWBwS4UC41MMBxm3ABLEMiCJEzFEDO4gvElAB+ogunq4x3ViiFsLAoFE6sVaQHMiqYC5Bg03sViphEA29QYIzqiUtcpdwIGFbmtaQgDwllhQDbcaRKFTY0MWEJTF9JcASSdCuIJwOEiRP2v0GnMAOgx7AOsUbLMbBIwaunTofEknHyKKoGD2PpxuYvjotJcfwW3OCw+5gBR5sKuCQ42gboB3yWIGCaQZBItS8uw2Gw7OCNtKgCBihgWlARYCmY+MAUdw32LBVqAhJlBQ9A3mSVcJcByFjqy1AQu+zLIY/nWJeBGVqqQd45eCREI8FQgr5E89xsNabg08qgrOpNKSP5Lig3Atz3VeqqkjjyPRykCKIho2EmZEv6X1W503wBlADJZy/JFCqZ8yl6bYRYJ32u1ZzctE4AAqqmZeKqIpjH40emg4z2PZRqEheac7DIwCiJe6KS+MGYrrd3RkSW2h04opqnUh2HFKAImCThe3bVTDg5lyUCm7tykZ3NLcWmcMBw8GeQgdzK6kAx2CyqbwkQUjS0YgB5g2EyXaqyILJ7sbVc1BArvT1csg0lwS2Z5isUw6UsEiS4bLJGAmdMJ09JNMhU8rBSwAcgNaStNCx1Bzk0CyiEtNeBkpu8L6x4JVUmyHNYoYjYAQFFRFpWEIvbubaJmbgrzkc02qkjMBWIger5oJnBoQIQx4uTSOC6eA2oy8HPA50kum2KOLGvZCiHB+Bhr4k0B2RtTaSJFsgiaOMgnyCqARIUbZ0IO0cqDtjJdn1uONY1CqS1U4jFBSCM9FAKHIItrmBRSD2QN8ZfnzjyOlhUioJu2dGBxHCg8XESBBDCefiNDqbKK0h08TVEcKQSoQpXkrYeeAFhUDsyhT0JO4QHVxUj8UT0gZo6bQ2sJI4ILHuuJDGGTYOowGiClVoJIDNtYiQ3jSeODx76MRGQdNiDwEjgjytMtWYGwU9VXjdpnrT8MEmw1CkagovMOwE0KmEZGVNXXbHbnAG/ETTjzIhSUpEVIghC4bjY9N7MWxTW/USKCUCJ5moOA3SYA7hGitAnRnKV2DwGu7HGvQR8aCySErDJNGbnPfwsj6Ig1U6naaV7EwxHZw3UWasxPwo4byCmZ8+U7O0W9Kp6WGOPc6hmErRVPjnP31zTshu27sROh8MfE2nSEcZ0VNx9B0NG1RUBIJuYXEtM4wIAzazDyqmpBwjNUAIri7AUTkHdD3rZK/DGSHGvpKGPC8AQwvYAjrhMBMElICO4qx55nMfekNbM39YjEF5D9+ialOwPmbgA4ZzqeLc9JXRBQWdtSFLpJHIUmqaC8EJBksyHDhMc98yYHrgLrAievAVgENvEZlrHk2NfqV6Gm632JTA1QRybP4nWzECtpeCu2oUEaKZIIyGknQsZNovYPgm3OAVb/bae7YxwoOjD6v5UKRJVK0zjnklvBEYCjiD0SlqZE5ecvh0gEtWCSlRnjPhIg0uHI0zIrN3MyIlqfjaYkwO/5BcGUXEdS3Fp6OTXGcqdVSbYTeHBiqQQLFWDE7RGzy/SC0wTuHIJl3Ek25SR9tbz7K1ZyBbU2c1CChv/w8YMa9ozDhMhnAcGxUJDKE5bImZK+Fck8CNDE9dqpA+5MNWi1xzV+K0QqJRrlLcW4MiY4VmN2GeCCCpjuIOr/gb1JoKBaBmThScDOaCYWJAhVQnscCBmYcKCGpuEnrTgCGnRzGxEUJqsLjBBqPrwU//8GUfW7MhekR7pSHQ6QQrUXIkvQcUC+sk9qYL1CFyrBQTSJTFNnwkSZ0tiEN26gg9/yAhVfFUiXI9gpAFspjwsNAOggVUOBOSKrZ9wDeKXsRaBE+2c1ViwFEoLA0pLyOx580JMNKiObrZNO400DMAGIwABUOJRVPahp6Y8Y+mMBKZBtq1+cFgNAbhUKUlrC1NywhNnNpdCAlJlFJJzGNeVSHq2LwOiWyDrMVBo1GCSoGOTnyELKpGJRTShDxT7AhTHXt6jrCYIZY5XOMIamxQOkGBr7k2vAUSAPiXP3w1pPh8s8NOzABAkfK88Az27WJz/7dMDXDI+EBmmFtapBI4MMMSA7Wb07Zt/tjO/KQq8Ua/IGmPjBCxDDItNxKr1hTO+UpJBJUW2lGgsgwe2lqqRVAR6Y0oTHFVPIpeVjtoD2g/4y98TCvIVGaGQdORRxVieijird5RVtEH6jIvLSKuut3/Yphcw3YYC6Y0Q7MJpGbSllC0PMAJAXXQOVodpSi5CE1JmcZi+gdy2uihPwFP4ShWrZ/YWPxEviGGpoHaGrkBMYkobOCw0/MxblPImvHIPCwPQOTA82eEq+hAoQSyzIO0eZAUGqwj8nFgxCOM5BG8DqhGYtCWUS8Nu4vrGnkmmFzY5PzGdE8r7vme9ktu0g0faTcVIUXLTHIAPhgC8hIo7cHesYF1hD9hWXAG5sGA0ZwZdNDqwSeNk6ZXFktDZxPcUjJn4JMalZMjmMHyjN1ac10Do9ffA++JLjpNRBkSXTwhXL0bIwNJZroGHe2GbsMdBGjRBDBfDE4cOXTNK+js6rO1we0ruKUI8zOKt8KJuUn2VzAtqHPQIVV1WkgcIxa9oAQBtKQUo5FuTgHjyJWQpE2yEnMQ8mkRQDJVoUDUoDNGJ+ShmZoi3JSVACIYdWydqB1ccRQT8DoXgDTkLuFFs0YmCiJQeTil/T0IWrhT4Tpic+wzNLcqr9Hgi5q3YGYPDm7ZMGDpb9pmhNQq7KfojRODMTuZ6dFO54a82DCKpirQoKbz/GGC1qjGVgWnuHNJJ6pBuo9hljsxcKoqVqMwU+S8YRkMbXO48+8QahCeS29DLqqtXxi5fnfSc6UnM+RwuB2MBAbYXwrSU7moTf8T1TTKwDIQC07xqASupKgODljdSXpcAgKu1jF8T5sbJahSrT1wJW4EsRpwPMJJ9hbSh0CrMKLg4+hBcdkQI2VYMJ8G3TS5MQJKsbRfva1dZRbELI7GoYZ7HGXi4EAh7bmW5gh6AA2GAzzCzlaokUmRbnnOG4gkl0YyIDbNCNFo+jvpdFEYbDzch0geYFIhLgeHOFtoJObgpkOKeij/sDTUHY10wFC+sfPATwwZlX0xDo3GQwlS0Ymq6ZQH2o2BI/R+JnOhBaw5BpkHEeCIR5cg0yHMGiJXYgHiZ3/4YuiJwUXULLAXEqDhLaHcpM4gIoDTW8q+MVyKHbdD6UTR7Vw9utaB2wfJ3vekk6HLBMP7dt/K0GU6mhoAmhqccubDODzIIYnEBno0tNo3EwQKbMTpXaFH7wR4ziFrzcDHRtrDyW3ZQ3gz6WCr2gOZUrSYqAWQFakZbrZuK5H2i5EIruL8rftFnpY0hNFHjHgJW5Ke6gvyqs3GE+pEUbsh5KGEUShzm2Zqnongahh07eF+g+45bM+kFW9FnsXMe2kP9AIM+gEGI4yGEGrqORZGN3x4WLP9ARjHOACNOEWZFi9hDiCsMpcX4OTYeJdknsAzFQIxwoW7PdFWINiEi65pflVG5eQM2xaKKXoo2lgH2o4cojP1s1M0tuQF7uhwbjIEj9aU++CmR7tzo47tIS8xv/faq6pKGo5h+IoBWt0mFUWVkoY95/4K7Zr2f/p+JXPeZ/q46ZkqqsiKCs2RZ3IsAEBtsWADSONwt18d+eH1suu9d+8enZcQoYsdJFA6wq1g50YYAFTPSIlrumEBFW3d5eYTMkImKG2wgdi8NUQ33eMwWAi5y/WG9H2saMWWqMoeLIgko3iSQ6TDY3xYMYlTMnAiT+EeJRRwTTvgoGjSFuFiO+kSsHatQVgYZQ7CYUKDPhBgabNn4P4pBEBBpCgA03uiGj3JYLej4DwCD7s4rcWINQvKKLLAkV+0ro0gTA9u4p9a9FprOGgMEDx4rxlVWEoTHjD5yMCToyobkhBAbWQ9OB5MRSexlMa159fHP4k21CngtJbqec6iHp20YrjtPtKjCZiJMZ0k3GzMDJAwyCR2A2nSM3PVcFxTTNTD5JVHwSlpEOC5HgkpwVZlY3OBStzopSoIM3xzjuKoZBqHMYeapaUAbNXhpCWkVkK09jSDeS37mEaNxbtTAF5dBM/xYJjTz1KujIrTWjYIn+Z/1qKCNvcTHR50UD4JLdXIR7FLMEZ8MeKxaThHImn3bUImBTqEInKdMBxPiJ5Ky3GK9GCKGUFhYOjIKcyJdjynZiTg07sNdjssnICK3bkyJnhSIQtX4prMww1m7iBcxdNdlU6E1tHlPh7UyBAwYVCpRWWAZjJ1MNYRCL1VJdNtrxXNJTPML0D6dsgGLr6NceIQSaMhG24iQWAQM6DZOY50APDrP39pj3+O29uBGFmYcip3RKwCnW4ToumVPSnPXzJXKziOYQCsLG1BgW/4kLnFBzPTLwCUV4mb+3BouLstUqwtGB7sWAlGObQ1Lj3gIQJuAmKkdDP9jbZqK8IHu84YXYFcO91gEdpEGrYmo2YQ4p4PM538vNVkoTi3SRLEDeQYQpzZijzE2LUVQ1RuERoHNjBpFzI1nsPFJYdGdzDzh4bMG5/hjPoc7I83knXQ+6GcplvHPEAAggY3Rajchh2ZzjDcM1xlgFGwtgc8+z8yLezXf/iyhQ4czqAZJOWtysV2GYQjug9xTmHf446jFOeN+OnN80YqcJM2By1xnEghzFVN8SFMYUG6vdJxmweqaiMu29Y29WN/Jo4XxakgdHtKKxOam1ka9xi2tD+ReeOvd/+gkFUjtZube1Ty+RshPxUPiHEa3wtGo8WZNAuBKlZuWMO89Zp5kvAmvlCxEEjNSs8rNKzXUOtDl2mKZ4EUwk4OSPFCz/S24bq5LBV34sFsplEYFIOFiE5MRMXRaWG7ibB1ckPYBJJuKvYhXITboeIXf/xqs5C5TR7Tlg5eemt4pzeIvMQxBykENS8RCfTGWTOKA4sI2UfMpIpIpQGFVYScyB4G4wYrdGJV6dGJmEwDILb7SDLGu/GCYVNK7nS3M17UGVFnzKUwzSvh0T0M4ZJkrErzaZljiO+Nd2EeIWq0mDMAxOiarpxpY7+vijTeooGGAfZ4BrxPVbJndANHMKz6kBzoPZVTPAF0j5duC1WwB/DAOQwc+2IkMeoN7HOyn9oMsh7pOgYadTKqgP1UxW02zB53hnCi9yQ+H3gGkXlX1mgmayQKo2OGMJ43jQ51ILypsSY5gh9E6K7jiiELDGCBkYdQ4lapgNfQF1QSDQR2TQeCT8MKYOwWzprgANxHuZIZQd9+diUMFDckdI4OYYFVtaeOXTtvwgVTgEyNC6+EISm1fx1jr+G8zhtjjsZLNPgOMzK7IOpwym72QFC0MBMWD0q4yV2AKXQcVam37iQMJE/LVIRYQTGa2jDcHrfMA70hU5aayzGM8dJsHoAcyIgchAXiOKWmvlJz/seIyVFpaCc9jL53JKNIHySlGsWC0S7C5GqHg92ANg1O5Z6eZWMbcxHMqMYAUTe6jT40TZamg0iwOwv3VHcrApUisaHBMUhzOF2SHmNwmbkhTgaDNGeM0BAKAwVyPG1oABCLXDUCP6Sj/annvRqDxlSZzRpsXBuosYxNzsqmcQlkXGrGnmTITh9IjoyEfWkkknEfaPQWBoFH0ZhhZhpgTjHz4KZpbtMSHRaD0UhmuD5u9j/1N73XnO6hYuc7Gsw26LlHamnLUTA34QCg0CQGMAGpccTrJ4B9v3ThKHabRAScCCndbOcCJ1mZVIaBgkZrHOZ6M95wqOohN2MQB3anXIMPa8sRsVupnVUTx7kadNUJWkTojg/YQlEnyEYP77hNHMCgRcCIvbjhmtx45dL2FHtkWm6GbsbDq8ztJkBbdWpj/mDiJ3jdYxXo3ucnAKiBDaO+nYmh5kdZmSCWSqvGlbHv40m9mdgGzBxW8ycSRbO2cgK4SYiwsI05u7KD+7Wd+2kugGQ6hm1qdPY4RPTQa3OTH7sBq3E0GbuK9MQRCDUSbHB0RXusG05gvylb1ZFcOzqS4Bhqu7EEcybj+WemqRqH1UZbhYDT+gzAv4aHSE2TwZ67XEB5IHRG4sJJCKBYffVIhs4lgzikeDwg2mgdsLUCmbs8ty+PWPNttn2gOT6En2ahGX4wl8bofMZE6o0BDnp44z6c3nEU5BCF88aEc6vuRmNefgIoY8VRQUNsecPrMwmKcgqM4slAsUa4xIHiN86EbanRDbSbb3q0TYJxHOh2NroznivUpLsgGW/0QHoZ/Jo5Rm3M26Q6SoSbk7yFm5ma2RVv8MxplQcYnblcCtDInKVBeFdQ2S0VCf5NFUJw34VzMZIAKxiPpGkEMy9OA8Fq+JjPWqAQgx6lFjzeFldBEMzVaBJY013f1F1xe8DyJOlmR7VwkgE2ZRgpZpclMlia1KHhNMzNR29TvJObFSFT+aXSbhnnEM1Ux9wuCwx27+ENtyVzlfcV1nBGjgHGG0RXQO9pZ2qicYEne4PhoOcDFSdO2tPfhCpgfBPpOEZ55P3ASQDYc+V2sCdcR6OvJRDIezDcmI8Y7feaabi7yuS4cMaMnUHJKd2wb3g/8BlPyWgR/Oz3X2G7RUNg9FqcLI5bg5Qh5Of+KGiysIayoymOK2zKIxO5waG06chmUadTcWYH2lQOCqFojbaLgMJDGe5hY8RRbo7HtQEvkpKyL/MxVvDwZLjd2GnsmuM5EjCQgkpbBDM63em/fwLPOdckiZ8YbewpqEeRtd+faVmaNFI375BB3+R6tuD5BD0QA0ophnDP33e71Q9m3JZrGkSkObjCxL4dkyg2VR0bPb6hXjOC/DSh3bT3BhIcvdkNbo2CWFsUtL9u52ZJ2abu7eQMONZDucDyVpbPZ8hWVPA2W3FTocUpstTc5jW6dFwo5BYdiGDUIJvfU4G7v6RDlwAOjRgBLIqI6YZpnEHrRHjPn4aZiJSQno/iXdgT9TFk63ziTc3eWPgRqGQLRpi5A3NrtMcDMkdmcBBYNVJcZoztHTcdruLk7tlM3G4FJg5BJkIXxlrCgGUgnTRFUoHaZWhm5w2FQwQWSfkGhQ5qlZvLsMLTiU67+zBDLHFhQKyRsd10k4OBEZzcmoknuYGiGS3rmu9sgMHts8fYBEeN0hwhyRjR+ekfvpADs7dkbhjsSEZPQN1gV5iGFRu/GM0sDOQgkRKa6Q2LcNzooU4gZTiZSAzVuP4Q+4hUo1J2Y6QBWkBp5JLZjxpgClBufGkj4y5kslHBDMa2j+RuLselDiBTl4c/ZUjdSDne+un8BIlujHCTdlOux0+ngVFkMNNHxjtisUacNrpTIE4RGvBf20XCgO4juIbF2tkoA1ly2OsRqxZTm/TdqPAx5orpzRH2Vsnz9qxv1zyQVHlXd2z63yP2QjBw8wyG4+coT1omQG5EIIPIrVvM4pZ7DMs+WDZ2sAxvv34DZvYjYSwLOVmT/TOBN9ngC4PqFnBsYp+20z2faVsRNAPqxvKUmW2P3cbv7jQ3bHWK6pzyHRETA8fuEDPNy3YJ7vCOMTSMOMJbZsndzQ5YuhtSJHvg3uT6eGOSQD1hcdmFS2Kj3DDIEZkCP4kjAlG+5XtEIztnCFhcC9z4zpasGymRgg7nIfufTBdjrN4w1jR6P0nbnODIWClwE63AmuDAsL31HZrXBgC7mZ4vJeBEtu5vTrDHr61519nOWrvoBPBPPa/HF1y3+aWH5YmJNaFIWwKwm+7Jr5zSuAnCaHTQRyGHf5JbUeLa4+YkKQy/hXE0JL5O2tdYinbXJWJqTyc+fGOdsPukJe5osQSmw/0zA38jFuYlQw246psbZIb+zEuw32Eg036ATPYlM6qHFKKQLPPW589hutUmovYoc3PtN2DPn5RUOiI8s+CWUXELgIWUbbsnsS7EsbtEyvP+TxbDvG2Nxo5HmyNrZsEUQ85w411YJipI2dEIY9LfB0cgWAY94RcjEBDXJA8Mzu5gOI3EHHU0RiTH44ajeyTCmQrO3hoRCk4n28aTVZjnMLL3fc2PspTBpNVO8Q9XAFSiMXZNbzi33NL4g7F9YUlLRO2eS4P95Sf5xsb7gzEi3sDzsW2M6jy9UazNGWDfhWB4jPGJvIkFpu8OQdSMJAlQRhGotMeXMBaAfcCnjk0m2/7xwRkRRWfiB/ZxDhG3L1frviGGE7BX2UOFBK09Rg0AtAU2ayCAXd42WI5G9m03CHgy75kE3abCEdkNxAdUwdOe0cqIsbcQaQ30mTktky/hLTCcEAaRLBXqdvuOoiAzPhVuP/rAA9PQ3Gznc+5XUZYnG2kaANxMbFvKj1sDjA0xdfb1KWCCQzdqMaKC3T9OqcX+V+s2nE63vyf+PYzgp9tkkwvskWr8347PcKniLpzcg10QcYpc3ZQhDW6Jw8zeu7mZ1nhety3tIDFq4dh9DYlBTkVBdI9gsK9Hg6WlWqXTHjH3W2pPJ9PTYQW22B5HEkjv2KkBvPZFP5oDTF5tRpA8dXrfiyRitkcuZ2/Eb5SGncKar23gLAyePSzO0bdvlmKzbkeptvoGGVstN4O85woMnrZJPNumF8Bjd+LY0kJ7WMRpmfdMtC33JG5OAB/bcoOYNSmHU9y5PYi9576BPaSt9Zl7ITPbzhnlYPJDfm7r5v7LNS/NyFJIkLuMzD8YcTJYZ0wYeyHnCiGk7W7eYoq5yH/6xmayvPmtt7QoySB68eBW16hUqhOWGqPXaMoXDHofbvMJhrybME7JosLNBXjgAQUZF77m0/YxL3Q8cUhza4/eY3shh6+Zr3VNM5sFTL+9e4JdCJvMCDPgCYMY9Zw2fBi7nZuXlCbSR8ZILw5vv9vwCFdB+5JxX9NNISmwSnNEZwjF7VT2JLjtAWJQ0hGmKLl1yXMnx0g2abTvpj3k5Ha7pkhOsAOz2yIGUK2B+IIe2t0QWVI0puSBWZP0KHwZBho7/H7+P02gyTAiyXKLcHOrEyslzM1pos0dHZV9nZE6cF7MCnhN074lDh5AOFZQMjXxD+NLG73k7q6SgCNSVikbDJquDE3tEq6jsdVrDGqyL2fQkCaGgUzdqNaViekhN0lyY78TbbNEw30LzR4OfXyWFDnEkakcVV44TWfY9NCQg7spZnYEmkc/yapouaddgagUvUNotMe/rd+ricbkWJhH6jiJkfMmq3b+RCaIZZJYfsLkMescgolcFUMMTzvOBZAWf1IIcEPb2vVuG1+3wAzy36ac2xE00nNjoho8TOA4DTFNgXUQLWbCCBdmINhqZkDMGTUjuI/s/EzGKUUlrVMNklEbl57KMWKnGcOmTpQAjj93OFCMsrBqR4wQNSGa0xftGz8EpDLmqPQu4V47NmRGQ+xCXoA4UJlIalm7wGOPltPzI3b6QBrndQBiT+C5ofBADvJELraLwRrjghZLLkzeO0HK29RA1WJSI4xbqSkzmNMhYJxn2oDHHmUHs96gVvYGEI5RbycEZh+XnpeDHmFDgmkca8sdDrnH1XZwhuVwuPKkcqBvQevTBwdzI97sL3QxULp5OfYUveKBq1FEDdZIcU2VmcilDHe+u6qFJRaWwnalpXQqYho4YkSahQggNlkxxWvkttwWB2pyTgaBCcksEAI0Ga7T6o2R4RIi2tCCSKP5+W+/QNVt5Nq+H82FYVCzFSH7/27KuQE44Y0UIbeLbVqfPQR7yNaCi56o2vkWAOz83E3kwEDPuFRYLN5CSxCgJxfDWaWtONjqpxE/TJQaNpQ17lDyluu3dTz46dUPQE95Hoe1IagWxyc8kcyNrYZAUkCBPdOngLXp620imsFiMjHAHPnJl1YcnU9r4EkLTNybaJh2hshGjidka+qltvZwVlSwN9C/oe4bIDmJE4D2ZJJNQjSmYmggvjI8ap4a2n2ORPzTJNkReqM0gyBXqIXajSajofvoPXtEg7ndel/DYQYNx23un/5LpHklRwa09tglTixXZK/jatBL2F77w7dhYH6vTjcdsXFsXPIYbMk9uN8xqqd9x8/MSiA+gE2LzIxOYH7Wxn7Zh4FwT90ZjHo7GMaCeFjc8GFC1h5ZNujpwYbn2XHGNIIxchxB3L1/dbKWReMgPZmTDlId7S7KB0KjtoqDGMIV7GwPI9k1332VkL5u+cKubBMRM6PIbIXZXaqRtCnWfMnwgOTeuLdGI5mwJ4GfnldR44OYLg6xgYqXSuN45AB30ykEkKdlzwFM36MuZnwoe8gAuKsqIa2+9Z2ErTbaHkL5RKPoKJPBJEXYXTgm+wQ7QStwbxvlFr4RqQmAzWSUjT0GRIbLn5i9eQF4Y3gUjltCnJzzad8UsBxyr5qYG0dbt70hiDHYlzCbTHqj+BOogtuYaHMI9ml7QWESfWPy8P5UG5LurW/ZoFeIo7E7TbL2nh9twgQ36mq2ZJCwSMysNhcfUsg4xXnbm8GwAgOGdCsDceQZRel5PeACgPSMwCogrNHijlQpdHmlMXDDuMf3lwanPejSBG2FAhbi0SZoSNNdJrNlmqHB7tDB0QmxQJnHdhBvxagoWoBO29KAHDGdcupWsgagAbh0uwsIZRrjTetTCZhtr8VGz6bRm7mYIy0b8UdhhcTYKfZvxyg+RvN7E3XsFgdIU7H2/0CNUWgzExAZlGVama6ODkZmOk2MFzNVIY2MB07W/L5iLYrc4H3hbx5k1vj5iQxNtZvnbFn6oL+cFVE3CioWi3OgWj0jRsjJSqTQHrFigFmlNAyJYlFgVeDgQA5AxIgTtwtuPyc4wLxsMxhg01eZgXK03DXD0C7n4ZYHbn4hk89p8joQW244U4DN+ABlgzZpCSxx3Aw2ZhkEwVHOz/VYAQOTzaHZtlbeMCW5wR0IsDuOGwfz0xe0245jTPgMb7sWJiqU84vTGSS9w8Hmzt4IIrfyC3tcDLdLJRmCaUgo9GxVc7YoiKsxwdVZxpYOEYYPJ8RE5AwarhrUukdUMgE23ADMwH7FgB2F1o6Km3CP7NVaDfEmxJgex0KPI8k3RhjYsYkHnEnanZtiaLmVvoqaK80aKQc8ZCXC3TLNaLgFlkzzxurP+asCoGE8fvJbkjwp0IAIYEYZNdDjjaBhFjkszqDBO3k5JMMG2qaMgpEcswxoCmyYrXualt+7TtA/6TqxJYGcuLKJK99VSDCJiRWnMN0iQEwuZLRBRDKMNoKITf8yaB/OVCoQxAEEZrxY3Er7G9+ijTTzKGiyj8wGZ/WFjzDGST2rb3JwJ6YjCXVVBSPMI5C4o0Nca3ShmFDFRD8Z8mZk2SlvublIIcbOcQz8HkllhThyI/W9x5+xh63m2tp8cwIWhiNkbUx4jtutpN0gpsnQGcyTVDLbhm4oMgPY22/NmrFx3vncFLGpPU1pVhRg251289V7kMnUQ0o2j9vOSGcMEtj0+3YpzvU3eonoRgNM5McOr6VMFSc8hARGXQWCGFqbifbaKgDju5k5eZT9RjdAZSXW9CBwDRU9sY0BFzg3wd+O9BjKhyHiZsRW1WRspHoPfbYHdBRhdPrwDW+bRVH2kUIyLqlNG/EmHxw32R58svvR3gsJHGCNrx3inDAPuV8AioHhFpLyWqzZ3zT81J64CazZWjYtwFw+wQBHxc6GLwcXHHVcSjcxFEipNBblmQz3cDP3hhTrgaZwp3kZhY0Qs/72Z4zEMZsYFEUFe7wfBmsO1b5ptoznlslJbsZgKsrcEWSmQ50Sh+5Zo7iR2MNOcg3aPthXBF5FnSIBS1uiUcwixXPQCXywEgip6cKIbmWEK/B160YC4tBEQdya2xjM0nG56bymchUQoApIMZ5QSaBMZRI7BzPIRq4wfgRip8GMzmG0yduvNH78pYB0VUa7BPI0sPagebMLSPLRi2huXfRW3/V0DnbhqOQWvAliEv6DWVAG1NgKuOmVEZOmhGy6FlLP4TY4syVlhMxp5dTD48rOrBEdJ3pE9ITiZ2s/ufFwcGFGJIbmpPDHjtaUwal/vJ3nhL35+jE+Igi3UT7e2yEP9Bs8/Nivfnz9+v44rpeHl9fjZa4/4HgpVZ3OPD3jYp3fOd29d/forfOj56dHz3G6Axa5ppcb38Hm4s3sOJCEs/koBnkFGpAEkTZntQeuh7Ydhhkqdnz5hMvd4yBqi6micTqKNXMZgWE1e6pdGmPszlwl2GYwNEqNWRfgpI8txSxSumIUu2NyWBpt/8rhG8A/XvkSaaAhh4dDW+5gyp6a4xbi1l4DGJRw1LU71KVAHkGi05mncdHP+oCbirZHVjZbDosUMh50jEAGG2AJcmTbDYUqQ4UwR+JjxlaHcmsrPGcu2jcDQW7a6EajAUi3u68Px/1X11ff3v/w+sfvX798+fX9i6+/++pyvb+8ufar6yyaS1HFM67fHpVn7Geld985ffh3b7/1y08evfvxo3f/7nz3Nk5najarmTCtA2hUR5ORC0GDvAsBCs3ZBzwUDmgBLhewAEJG7YivGxfAyijA6OWjtlSZO7k+ScFb21Rg7/iX3TDMVsUT5O7eNSSbEDnal0Q95vmSuAaQPxX/8oe/0reFMEhpk0Ej7+iRuwDJmMXBBS0OlHXjIRHLvlGrdZMVbrFEdyZdZZviuaGAyKM8nfUHUwj2/TBczlD5yQzWNrB2dPGMMh4J27DgQ/T8pL8Y2cpsVx20gUjQPi798Ory4+cvv/jymy/+8uLrr9588+bND/zxqotwrD58MEdyvcaWzkNtHaXWqVCl03mt0yPVo7c+ePpP//v/+rO/+893j56zCiCxtdHDPd2+m2GjN9DsHrccN2sIWtARqaCmr24k4l6MMsalAp0JgO0ReZPlGYgwJAIbhF0AxYkOIhMrZp3CE6dqjOoPQhqDbFSShZ1BNpDT0enOAhFlhyqCRxK4ZnMmcAqh4oi9TzetHUA2mAZjVLrGyEyGYhtx3yqfDzYWlsY5mK3AzMHCRDb+TQQ0rKl5YD6RNhw0kMa4nermFha5pmgPCzli/KGTuPGTweoQP+D60JcfH15+fv/VX7//4vVXP37145fffvvt5fvXdvsuXQ7RF/ab5CHVE1cPn89GLsf9dV1RxXVi3Z3uHj97/PjtN98cT37z78/eenq++1Xp6eiVItrbhcMh0nsnIAwpeFIPATcumEmHkxJ3GgdqcNhWSK4Cr8bBxmaUCE3ElXvkFQKb8L6gWLbZIDIib2FXVNfsycENxsp0KbVYgPoGVwPgBpfWhtSzNe/zflzNDSHv4XB2UM6uHGWna201ll0a7fDe8xtHTTVSYS2dJiIvHPQitYV8WsnQG0g77ARxUT1SvNFO1h4qbIaqmYiJEdjDSWN2IuLg4pZMTqsJOJd+8/LNd5++/PLz7778+puvv7n/4bsXP/QP14f7Cx6uub/0pbsDcNV6fD0/q3c/uHv65KzT+SG5v1yPN28efrjk++KPbPdr15s3zx/evH1986jf+v0fLlb9p/+N73z063V6Mkyb1v7B4hGjBUEOw76W37DPCXbWCrIQ73hTnaxMs0xwT11WpGNq+eiDBmM6eoyvDg9Iwmk35SxNAJGmMqfk8YqFkLywPE2RdlSjp6QEcO+bNuHKwg3/BZqgKE3YoUHshWhJeItMmmExmChYWvLSuO9i1xS9QTWk4sYUsZdfgbvNNDAZJceeJYZUrFEWMAa65+/VjhQdC3JI17Rho43b376N6OANgCZ85PryzXeff/fZnz7/w6fffPX9dz8+/Pj6yvuHay6v+vLmAccV13qSxx/dPXr+9KQnP//w8fs/e/7Os8en405VzcuPL77/7uuXr+9+8M/efPONvv2m/fIh/uahX3a/268f319eff/i7vHbp/Pbz98567x29zz2MnPrj8aG5yXiao5JYQzWO+SoRrpaBIjtETbg2O6wPFYsz0McTC7rhMB2sTmGFSHSXLJLIXLdJl/PWbtBa/OF2yITHVcjvWX4HPCYDtfmspmueeSzik4Ie3DdfXvsru7Yk6On7xBAHKZpZC0jGg5cWmLNsDQ88s598CgNo7G+jOZz5FAVayYNxVAmr/5qiFa005zj29jGPUjFNcETGeXy4YcfXn391xdf/v7LP/3l679+9/13r99crg/u15fL6zfXi+4e+B7fevTs7tl7jx4/e3p+dj6VTk8/fO+9j98tPr4/ruc7nPryw5v5BG/e+cU/vfV3//LiD3948+d/W9+90kPz9PBS7cvjhzt98emn73/08en89A5PuBTRWFrzc+NW5ESh5NPCJioGRElsaiUHeKArPVKCkT6Pk6MWN7Bkt0igggMHttuJtsbWn6QOeM6XNlhuA0prsCGjOW0qd6Q/ubrEI/GsWAwgSauT/R4SW54UsBoTPDC9KXcJ9Ymn5qYQ6JsQZAwFo7yone9rDFjbowIb6cWkgyxOkvU6ujHrvA14AGUGNZANCzUut71jZbaYBjXWLlBhK52axgTI4Vffvfn6i2//8sVf//yXz7/55vsfvnn16np/ufbD5Whf6pGffXL3yT9+8PRnp589f/b48dPrS7z4U99/f/f052+9/7On731wd370jhT1w4tXd/3k/bc/ri+++fAXP3vnnSdff/z+b9+6++y//Z/3X/6Vx+Vk3J34HHr52ec/fPz5Wx99vJ490XAcSq4dAKYr0VyroHTQZ1+V0Swoid2+FtnTgG1IsE01CRyLCHPASeTaUjs0+0AWcSLPG1NBy7O3+OafETnOMnbF7cHoARUBNVQjXhB5Jkf5pW0cWuu8tkzBk25BaOINoHhoYGzJ0YZbuEMhJuwZK6TSWbx4K56cdjBSv4POXvc5abpD9SWOWMoqx/RVcQCjbKip2b3CIW1nLQah24EYFINJ2g477pefvfjii+8++/zbv3zx7ZcvXt2//PHN/Vf3b168Po6jcUCnp8/e/+SX//gvv/inv3/+7nuPnjx+/PgM9BefvfP57z690/mj9z547923zuelpSO5PH/y4c8h4vh//F2RcL/zdPn6z69fvvjy9SteX6L9cPX9I3z7Wt98/+rDN6+e+L1jdv0MKRykKhj8P6FjFqqR6352zKhvKYdLVGbXcyiap3To7mPaNe6wmDQinqi7CU8eJi0DWSl128asSKlZngQ6WtkhWjMchoWJw7iu2VUwkITNxcNrzTPhwfFdjnoNxGxztuOtOSaItIiDx2aXR1/YHgeeo4laB6WsmsgibmvJ2mq0kObEmovGlb7OD7ehn1T3Fp3RBwZYo1Ts8eNgFhpigLrER44391//+2d/+MNf/vjdt9+9efXq1f2rl319/er++rIB1/n0nO99+OjDTz78+c8++Nl7H7/39tOn5+fPH93dnSC+9ezXP/+HXxb14el8XlhjYo6wCgIdZx3H5Xq53H/zp3de/fjJ06d85/mbb344so7c31/wmH5zf7y8x9tXrDNYKtYBcWI0R6U700RdmS0j2DleEriiLnCbAjcCEQUoNYyj9m6xuUM0Buwd5wx3On2Mb+VapzXWsuphq4ADIXy9Uq5akYBAkkqOjrYPljALtIefvkY6VibQlBt9yI7QmjZYMxWXQLuvAIF10rRMSY0G72ZqZi/3jOhActKI2VE1aId2zQQrMoTezLJ20rqH3J5uqG1O08vAHbcmk4w3JS8QH8erH7757W8+/d1vPvvq2x9fPVwe3ty/evXq5euHh74AUB4/Pp/ffufZLz/+2a8/+dmHP3/6/P233n70jHx8PpUY5oNzffTkjNEAHQdSHih5Ysg5N15dHu7/8ulnL64nPX4Hd2+9buf6OkFfjpz8wavvc/9jeExAdiPKImrY6i5UwLiziYot8kTYXb6IOXwOuW8STHcQnSbC1Lv5c+92AMSDr4NdYgQIovYGSdZpQJ0+RvLGrb9NVuaFpdiBDzDHzu7M+J6A5kyoXqiR0Ay5jQEjRz06gbLcfbdw0tqaEUD0qJebMUuePiyLnhggyB0Xlfi+6TEq7nLgXFVuDmnUQEe6zqBtJNYiS9kq7BlvSGGySwKSRV8vL7/58r//t9/+19989c2Ll/evHh7uX99f7h/g48lVV+QqXq/Hm9PlW33dkp8+fueTTx4/ef7o0VpbIkWO9obj0F5r4nmAsLjX05SX5Lc+4v/r//3uy5ePf/f7V5+9/frpB3717YNyXk/hx29evn7z4ns/XHz3WOtEgkcqk6lfM/MdRLVT7kyXBqTd7hhapzqICmlZtIgjeLi6DtQSwU4fk0GpNqpZqSxSmWx5rRJardBHMk0blP2EUYxXp8eaglmFHVXB60QjhrUZ5ckkXExjeswRpkOchQaEdx4fE9KbJ+kpVZPtU0CNqBm9KU2Pv4CCimh0wwdQUXWRMK6NtnM1FTEifYw9URDqBp0NKJzcJHDYRsfdOh+v77/79PPf/Nt//F+ff/XN6xf3r+4frm8ayPnu7szz+cX1u2sfy7xej35xfxwfPn7nAz567+68TtnxQdwQCrZKfPThhR4B7yCxQYASPqDffycvz+e/HP/w3f3p+zf3P1xel/DoTnfmRed73EE6wTwOLLtuXgEM+eUzYvIAeHRyxOjIg13El0bJiI+rE9YSVzlzMxDTTHq0TqwS4DSu6NmhskplzWITHMdW6IFcWSTmtaRsHplECMAVWKPj2FEiItjQUOfLEVdxoMqROozCJhMR5iGUAPQEfMQKhqhHC4KKO2JX2aKfYxSJGGW0yqiBLeYb51rLAHrHEo6qnvM+2qHRk9XLG8E4+jaNtOd6ef3qyz989t//7bf//pdvvn64Xi4vj8dd75+fX3R6s5p5pRyPwqbWk2fv3X3wTx//87/+67/++le/eOfRnVRICtoZD1sn2pnmLDcwcFv3GRqdAe7qydP1D79+dHd+/+H7D1999ZuGr32cdH149cXr7z+7vPr7y91dymyCKnbNmrBOHAXmIpF1usTVLJWqZFjdOLxlHEOnAug7nSagbUMBpWlY1ii5WL6O6hLJRqZ1YGtS20mJHLMipVXjgxoRjLV/wszW7CYqXoCExZMLK9iGYWZAb2IN9jj7w+RRGKa7YbNGPpzZbHCoMwA8Sz2y4BC1booBwNblGtZVdYjC3NSYDSVN9gB5cY25FIVSuJesAmBn2+5FAA8Pl2/+8Oc//OZ/fPbpl69+uL5+uL7Rk3c++ee3n58ern/57odvjje4O7/33tsfvPjx6To/+8W//s+/+od/+fWv3v/5u3dPb0nfM3ZvpBa7DcANXwB3kBc2qNRNCOea2qx+fHd+99nzE6uv1y49HA/XS31/5HXyVCJPo2SYtJZJVYviIrlAV46gpDqpqphcY16gmzqCCA64bbZ7sdAM4QNwoI52MN6OQmWCa3d4oDVCwTiqksjZEkALR1opncTDGDkrZo6ZDNyBvG12XNbSxNGht1Q4o4CZbmnYzcoY4SRhcrpUylZuVMOIO5UrTCxoIRo/zwQvqf34DNSSEaURHpztSaBmixHpVAZj2aJ8YUkD/YxzMof7FduXL/786X////3h95+9fPWmH47Xd2+99av/9OuP1vWH333/1afff/U9mqe3+PT5+89/+a9v//0//ad/+OST9549PdcJEzNAwKrj5tYdZ9G48ypS1ShJM+OeHShrlDHhDBEllHL3WKi7OqGPq+6eryfv68kTiWXsRZ+8tZi102O0lA6yTkiVicPHjF1Tpid9Z4K3VUmENV1ncMxNJ1Wqt0QlqhEnDJFOotqzYwRiuLa8LulLH7QqhZIldiHtlZJCqaVRR2h7wONeUiakBhy9PfZu+gB2TXhVzw0/zSRd88Z5a88hBkX0eMITd6etWDvaOIR9hJFY0PrpcBLziSyNIXEkmtMSEiPvc9o+nIeH+5dff/rpf/2vf/jDn3747uX9g3N+9t6vP/n4k8ev/vLf/vIfv/nu2/t7qB7VizdvHr67/E//+uG//udfffj2s0c1C35yADGhWurh7CaeZAs/xybhrcDZ7EYjDLs14VtCJXh49eb+y/tceLhT69xPzni6+EiqYi2fWFeMlZQTCzJyGB6QD9Qa1UsHV7NdFMsH++DEjZqaEKOqqNK+CerqVBrB87BZ8/JlZr0xDI2+tzbSCY//UdDaY8gBKiUDQ6KlurGdLTA32ihm5Xr1eAL3y8hg7MhCqbd8a2xaszdYtrHttOQebwLylFnDHmDNMokjweLRmf6pCAmzmHxupoz6mQAEY7mN6iarg/HakKwIOfrH717/7t9+87v/+NPXX/9wvZz06KPH73345PB3v/u/vvjjny8v79N6Uqe740y+tR79/L13P/rwyflJTYorqdG6skqTn6UtjN0yo7gxc/zftsJNz1PHLANCcu20Lw91//rZ/f3Cm/taedMn3R19eX30Q+MxfIpEOXuzZsyJBZlMljN7JDwwIHGpY7L6waNswcYdqdlhd1N2pkDEB5zZIt2HJzdGTKC02cQp00KatrHFg1rQscSxtpo9cTFBX03jKM5f7Vk2EVdrXSksDZQyWwM4ckS6pBK2nM6ekD0lu+bVbZwQzFQ8Cqc0mNIkF11vkTOdK5U4HYcWq3fPoR3SCIJegwHbW/mRQfJW0jmuL77746fff/31q1eN9fGv3vngX97lqe4uf/7mdOE3fXogJeeuHr310b+8/7/9z3/38UeLk2iJkRWO3hmZrC6U9n4gYXzhbUA94IZv3Ugw61vR3ZjJU3W8fXp41uvFk1Mfx3Mf63JcHo7rw5GL62xs7nzex5FLWmxIBc8AN5vb0m0mWkaVOmJPHz/x2Zbt0qIsJOm+umdb/Vkh7UnwGbpllkurTbsnRJljDh2etcdMMEOPYDAmVQuwQBVcQC+NJHNxnZLM9nZqMqSU0RyqPck4nJiw23YtOZj8N/0kN24tQtz+H+5IkQUAdQWrzpWtQOmcEZ3iSWNub6oOtGvEtm5So48H4Dzc3//10y9/8x/3X3z/6p744KNf//Pf/8Pf/fIsrOeP3/2Rv//k59//++/w7Z/6wPrwX379v/8///F/+cV7z88iZ0Mga/tZJBONUFwhEXOvsduykeGyiKGqU4AJg3aN57UuR7/65vWLP1ZdH+v6Gg/3/ej06NzPnlwfPe3T6dCIN0s7jaXRfRAP0umaMXiNsI2UyOiQmsdJ5DZEAATX9YCo82BQGdUhS1VL5I4RTG19sYY3ldbYFRJYYwIQQchi3Njbt2bjPMBVTLMwdmWQqp3753UHXYCotUTWYTRymnHOhOzs7alkYFA8Otq5EqUtGWaBS43gCDPWi8G5GEl02h4lmzmaJjVvkvMsgMExXrsilXiQ9+Q4jvtvvvnrf/y3Tz//rH2cHz99/v7f/eyd9986vuf9j+999K8fv/vOzz9494tf/uPvP/sKB//54w//0z++996zGRTnmxiNIBOSHHG1EPR20E3gBlYDtbUmk3DUBEZEklOStA8/QD/g6Rf97hXf+LpYZ7uPvnuUu3fS5+MBPgOTwn0F0FVcWENGyiv0ic5pyNd24Olxo72LFxP1R7GrToDT9ERDFwqn2vJIz77ETMDQjrqkjOJKbHoiKXv0/OMC3quxtmGCyeEE4V4sqlhjLLxmWbOOSprJTqhCsXC0y6Mdny/X2zgHFbs1BnZ4ZAGF6HqiurWGv7GuXiUXyQ7Di4Mc3KpKgiWIzIrccJllt9DeRi3PApvr/bdf/fV//Oa3n3777ffX9fjpk5/94uNfP3r6ztdff4Pv/ME/nt46r3fu+Ml7P/vV3/9c4PvnPFvkXtsKFY0Rnc2AAnEhLTBuKCyNqMLYgQZjq+Km2wtwXes4MS2okZfHi28v334HqB7V3eUCHj//8O2Pfv4hnz7pUxVTRx8th3DjsBZrUdDBNU0fe5aO4yReXIlF7J1/GIKRSOT2lTzN5qUhbdvXoHGUyFkvP6Yn7uWSQa7BCVWoJFtqhwkPIF03ti/cQQfS6MQZazYiJQdKqy2lzZr+qzRhjNdhVmcZ7OBiqNHileh1Sje3NrROotas7qb76Fx39+ara7LgSkdpXLFVY7fZGZMDu2m1BmaIhlg22WBfXn37xZ/+x2///fNX33933D9b9fGvPvr7v//47fffvXzwXj/0oydPzwJOeCt859nch0WuySwaMcUgKxjKeSyTEDqW9iwGDp7B7aRGPGk+O0vRNNs5HPblzZtX335xffGXR3W6+PoGfJO6DqjaxlGzeEY5WLKXe5hOncGFpMdhB1DXmY3hHg9x6WauFhejI2Z3qxkRpoGraGP6j1HTcyq/JE1XbYZp9Kx5LVR1kC0dINZ4VAan2tRibeslDNHE1VrISh+kBYxYCDGjowFhrbFTbT6VJSqFvs5CYcGz8jBBXY8Dh0cHWGVxMQuyuyMdLK6IKyoHzoFSp5fho8MJu/CgZuQqJIKIvLp/+PMXP/7+G7/GozfIo/c/+uDXP//o/fNbz6HTM6YWANkW0pl19cp2suAmbhp/ZLYrZwfaFBTtWMoGsCGVYTpDdoCrRxU5iUJBH3158+Kr199+df+aVx2X46i7x0+ePDHfvVye8jih0LGZ0UaqVCdtpD4Rc5zGi2qEGK9rUbOdm55krRjuA4m0cp7FYZP6EpmzSDEHSP+kAMcUQbmFu0rv5XMIneNgUMgocAM0J3QEKqpqmFg3bquHWFGM1b6aGlTtetAWOBf+NpBjxv52jkA8Cpy4uXFzI8X0UV2zrI5C8eDEdTeFE8kzfIzk9zjSJKkGOSEtmL8CO8xhmpnJn0aurTf3Z1/WWTk/rrsnH/L7H398eLV+8bP3Pvn1bSkA6AmvHBBnFjEJnsXRuRlrxrsFNMfmT29HXYwZrScrkSDWOF2Now1qOhT3m5cv//zp7z797Pe0JdYdKv34vfd/+etPPv7gncfnGkstE9cY4Cf6YMxTaS1uJ1qF4ewiBY7xkh1pgJo42TEgkYsB1lxnnruvl0mtg1F8W7xhDHTHnZUyNeVwuskjnrDXgUHrtsR1IBKON3GEdjdcIVikhtfYhMkscx/14gUcYwmSBA2VcWgtcDRZO27MYLRYqFDN6Gw0ukfiNZzgIcilkKcIoE1h+IHts9x+c4/ZlYOFKcfCgWauD+dLnjw83H/528+fvIu3P3q3w5Nr4sXKI7ceJ82E+kwCWmdEpjeSjaDj46A0zN9UZVIRTkL3qPqG/R2PFmM3cuT6ww9//vOffvfply97lVbjAeeFX//i7/7lnz9574M7sjXboYuoYhibx2H7aICrQPXYEDBOt8pUUMmHYLN2jCe3nRsPfbCiXjOmYjjQaJJz98Nxj+6+Z9NzZo/NmLkqUcVbdE1gfPXILEkbzbgaGPBgpxRxZalW0RNIgdqhJpGcottzow0Xx71qqYPj2tRswNgRCAn6eiVrDEY/sRWLemDsJd5ywXkMedA1dzUH/SVNo3d40KRW5fr6le/v7x4//v71d7LwFN/93ScfffirJx/8PCq00XFxjvsEA2/dJvYOzSK87e6bY9VJHXtvl5lOSySdFggpbe/lCCOW3QkdD5eHz7745ocvf3hsv7k7Xfvo4O3n+PAjPnviMZdPTUKK1zGk06mDwomLdVvktDnokE1IOJHmid27UxoJxmGQmTR2tOPx/1J7XbI6w2/aajBKgwIXXBKqCJ6QxEd2fgS2b8O91XjwtXXi7RxPspEoOV5YuAZsc74tSmKp+0gWFzSvpdA60S4tBL4eGr0COXYtUDbNjhxq3FDai3Zvq/s0ukHNtvsTm1RGd90/GT3UQjkT5Iv7B3bdPX/37dcvvro7vff09DY+f/XWs+u7j+p0Vme8PrXUgcZuPAGDsKFZcMP9lWTsWUR6iT1rFUe94WP4q1ZzoA2xtnC/M+l+D/3iz3/963/9/Lu/vrzmyJF+uF7IH47T/eV09elArUAOyMXuNtYOgzjt+M2Y3Uaus+zAahdnbUd48xUfxE7TiYqpSZ5GddaeGwEymkAoMyMsIz0UGBJgecttWUykHsGKgS2UyPhko0bj8KYbEYC4BS+ubgMT+V4EhO4eBUqt+V4HjACSw91AdZXIJagMxnADatBltUWVVjhEUIq63BaDTgABdK/1eKA8bL/CukWg2hTaYFchXo8eP3785PHLH599+KsPn719+uijF9cf9PjRuU4LaoFLNflY0QyiDWHcgqZ7NnWP4WrKKY8jPLD3oI/s2cURrkSmSqwck00c7JXpx3dffvN//h+vPv9Dsx9yerhg4ckT4dn53afPfn737Pl6NPyaFscEUtPr1qAWRu99v6sorvkNHplKfODgsfGYrfFkaEiz7csDY22yePZeo0hHaO0dIcGYXSuzZnybEsb37+mcQvYSAHSIIRKsmzoByRSVUFpLFS/rUJLwSkWwz5KuR3OLfZB0eu34laM5f/0xc0HRC6Enqm4sORWsIBTDR8iBAwV1DJlPCBGtulmlg723QVWhOW4glu+enR89P68v33z4nM94994Hz94vvfv+43XCYEIhdBwWtMf21I4lmYQHjh5zUMQ9Nawlw7NTD1sKMMqRMS9OqnBC00Lrer1/8eWf/+v/58+f/o/vX/4Q912RNo974NHzt999951nj0vqsELmyqBh1GzCBck6ae09Z5WWL/A0duwprFVckOdqOEIQVIM4MohLc5aEz4/EQSQ9G9uRSVYiazquJTdnU2FuCxuI4Z/ZghEOtcNQrJp8W3j7Gafc1xIdX0Wk2SAWK5Ib5SLWggvdSHNANpcMuocGnEEaS06iI6mTmTw0DuYErD5Fxes9dCICXutMaSWs9lT1yIc7wGSCdHYE7igGL6+P77568cW3F+Du+Zf9zR+vr1Yf/+V4/I4eTYo4Q83CTo0wfpIgE3VwomcSmbZkIr0JwwKuLQCl0fHZxQbFKiA90fm8XP3w6vXn//7f/r//9umXL3L/pq73PzaursdaT+rurWfPHq/nJ93ttODYA4ie2nb3ZrsPgYoO+Nq+RXINPmEqjhZpLMfQbOp0xN77daddHl0I2OTsdOuAqRDS5L7O2lCaJ+2R3KFdHWsWDcaT5gIV12T+m33TYW4l2CJRzkLzSlFZ9F3IkQGHY7S6YPSmmBHMzahONbYpkdAoSdb0UHN9tZWcCMZHyFxGsQgXcs5sozlO1xG1CyMtA1Fw0MdtixLg4/6HLz//62efv7j6ePnjH777+o/fPVrr6d2zTz78xVXnu4lVoLIgcJQIufFlO42ZvGWiayoqPGn2YW7xOSZTpbiSpYbkRSI4rpeHF9//5Q+/+4/fv/z+B785yOL5GXCpVWfVu/Vwzo/ruO9LX714WqzTeSowkrUkAjjcbNdOWq+atKj5GWFslKZ3ZOaRYHZRyxAO7KykHe6AOAfiqtn5ypowmkkMt2NeU0KNpgQDoGrya5wdOiChEAEH7Nnzh4AtjlwIgFeyCXTD6AHuEBqN5EC0R6ueOGOVc51lQqOkujlIIBb62nANfG8Vw+VJkDd3sLLbOjz+d6Xk8VbMxBKIOo9arH1cLi+/+/rrr7/6ofvN/etv8/DD85c/HI+fvfrmmzevXp+fPhdq9pMTmDUt+2KeFU3V8A7SxL5UsVPLstOBh99zspeJge1OG3T3y/vv/vL1b//jd/+/Tz//6q/H1bhcfH04cMrpySqfzuIZOZ70cU6ddXc+iYUD8RFsqa3hKuk0feRp4vtGCTQN0giwFs1VQ5occJaBwOjUTDeDHjam+ZRwJwCVJNoKlB3K4OLhEN09KNIkWG1nO3Y6DHNMWvKVg2x1EvZI9DqBk3W94lBXZ4dHTtMqlHEt+EgrqhTFZJwB5Hlt8foA6zFA+0gzyXXwJDhYcMR01oSHFkEyYutonpLj6lR23AduPKnCtu0Xb/Li9ZH7H/rNy/vDzJOXTRz6/tXr1/dv3oHXqHOO2xvN0e3XgF3eBP0Ao+POCoH8lPapHRXBW64POKNJXx5efP3F7z797//Hl//991991T+8ufRxvRr357ssPJLv1t1aTy+nsz76u8fvvvP4rs7sOJeegGOtU3XIYAG1AoQtG6OVZB89BX6COr3BJYZcA0WlOTtdN1YFuBjuBcvBdVb7jhib1Jx5SpPFls0kZRNuJDmDCBnwOhGQmNV5nBp1A60wzPCKqurgFWChZhtb1wwN5E8iwVG+LaWNygO43dccVcBkreS8ztaBvnrys1ueO7SvjoCqHT8lksphSGOspDs7cxRuoNNJ5/nrevs7rONyENfzydajPj26Pz051plE4iNV5FrazS/noyEOGY92fRyjmc8LkqjsXOyMCsyjoDfi9vX++68//92//9t/+91//+z1D33ph/uLX+XJ+YMPTk9OfPNd3f+oyin3Z9Q7dVRyXHscmlLtsCNEymyL6ku2L5gE0RGL3sl14wBFI8fsZNxwxGyxOmEh142OBlYumcFnS0C3L4qBYg0ZlHh2qhMYMm2ExBsAIjbhz031F2JNeGEG2CdgrDXxw6UslcjGjsXmDFCTnQG0j7RmQ1T2PpshA6mezM8TI/dOWvCYsUGzuVPZ0KFbkmbuoY9JFPNOg+9hC8OB/5/d1bvPnz568vyH714kZ+s+5+v52fvvfPT+03ee4TTcyBLDCXKbe3U6i1EETgy99ubMfaHB7YzqL8NnDaeNhh/efPPZV3/89z/+5g9f/Pm7fvHAA42np7d//vHP//Htf/4or7/48Tf/9vDqx+JxsVHrggfYaaa0qnb0sWZmT2gf7mN2CVgr7KoArK2zSJCjcQvPFTALf5Bbwr8xwXugfavk3kKN28L3gcIuMQh14mk06Nh9gAHGzgCTNRb4zdXuL5ylkalPChHDrJOcPpkmzGujmZJUsLPAg/sJL6NxMXlE0rrpfgDRkkl1qGMvT9TE+KWYozliA51qCUQaufoQdrjtLU4DE/8zKFAJzkl+csbj0+nVkuN763L4I+IZcTria3hC4QDggcO4802wIvFk7jXQs8N69ES3Zec9sNfOErJzPV5///Kvn/3uv/+ff/zNH1788OP18IE7PP3g5x//T7/4p3/+5FfvF/u3/9e3P17QPoGabSh++AHHS/o56wzISSF9aK+JGED6NKp3HHF6VnxADjm+j9pAmGK6tvYXblow9lliIA00MQKunpFnYN+MQo+pBDtHYfthswi6WCDkMVnNBvPpFfETmCUH6UR2sbzaEboCH0engUJOYlzm4TraWjvfV2LEu64wXTNFLkFMuxty+wSdTgXSR7udg2jmdLqtXs1e9V23ULRBUUagPEHuTmG8AOHiwunUd+w6nZq1rscJD1c9vFzHg7ZUBsEE53oeduZ7u+koAfQwLMno9cauYqTR6XZfj8uL199+/sWf/vjFf3z6xy++/O7lw5uD9nr07J2P/uW//PP/+l/+/qO3Hp3r+vrNV08en896g9fq1UaO+v5lXlz0Vq2TND28OxgafDrPoUqaJI8dYDeklGdHyqzMmDIz4/2mGUTViICi2Qo1x5zcbbY8O4wHuFfVjo+EMMtVq8DxDJw467Q0+9IaxHSBgQvZuYcCPA6vgFlHm4g4+55JAHZ3rksTLYJpeqU0ltuLOLAWaq12fLjBZpUiI2k+3E/QQuZJn07bWD9RoAIhH8TBqiaqVVlWsk0WjWuPSFDAunv7vfMnv7xcXt5dH56++f4RDjwcL98cb7ofOWiXoJOQk1cc/0Tgjaph7jROpggSYFZki7BzOe6PV9+8/uov3/zlT19+/tdP/9oPV718vV5cLg969+69X77zz//0T//LP/3Tz95+ehaEeN09O+tcLy+dzumM5/U23v/l+elbq2AlKmICeKCdmOGBsNBIdRWW1sCdxuzTJN3XY9ofkifWHPCgU8ehTJ7UsNezrm6iQplSpj3F3pw98uS5HWpPobNOaKypY+qOteNSkHSHoEoZZngWUIOBlhZvoefS5FAWCJzIqNy+pZkCPHRCrRrCJ4iEnDAGnt0aH7ivR7v9X2G5+zipBPSZttpNhlW7eKY5IbCT/AShRBM+GNyd6t0P3/3o1//w1+/e5Ju/gL3qPte+fPXi+vUPefauzucQcU44ArmmE5qxZBIIs9yagi1kIpNi99HXlz9+/Ycvf/fbz3772ZdfvHjThwRjtXh68uEHn/zT3//P/+Uf//GTnz09PV6c+Mz768P1h3u/OtaoZa4nFX5+fv22rsUKT1IVs0aqzknsp7kjSohT2NfrLM9ozlFlzGucxmmV17ouMhPOSM5F0/C1q6RVYaGtcLbg7TM0vctEcXUTE8cIhrCV1s5rbI6XCxsmNzBp4JRna9t2DxcCb/dbAzghlBrppCAcfRzT5oYlU22mw6O5IQ7kCI+kOADFKmZWEC4g2XYJBsfRMC6SKnVOiKNRLaYjb5mRcgQwCxhIilnEW1y/+OD5Vz//4OvXX/P0hPXho8vl9Q+XL3/7+6dPT89+9fc+VVqmxWMGRk/+JW/dMpLeYpjk4PXiy4s3L7747q9f/uWz33/+p6/fvHiA+/5Nv766nr5z/vifP/z4f/rl3//i7z9+/rMn53OJS0GUFg89Cp9KLyZCIOzzlU+vOpFcMhWYR4+DxIdvK5sLXCkf6L2uJTc0yoyzUlqT8Nc5mL0FgWqJgGfvLG8G3x0avXuNEX/crPueHMYcnGxBEjVbxI8d+8/dlqcBJ8JBy40rktEagCDbXEZ6eK5tdSSYUWmYpuqgZl1k1fTIUmYxiLkYqQFHnKZPhWlURY13JbhyUYEabg7mUTyCyxH0ZROgYqqSVfLf9tYGS+v9957/w99/crx6cf3q90+f4tHjd/Dk+esP3375qJ7hOu1cGDPtRjPjwJixWIa7j+4++vLq+uLrN19+9f233379w1+//+zHb3/48dWb6/XoY50envwCH//De5/88lf//Ktff/z2u0/W4+KdqApLafSRoNwnXypX4lQt6aSTRA8sPDIillha4Wk/lVnv1LjOQISjeiHl3Q9mbXSJhmcXlPYRp2Rj1bYrzxu1KW+nNX9+JnJ6bhBWBWMwnQl9UOjABxr2ZIlmgqCnWbdtZCJRxyTigWNXLtdOwjoCoreygdEidOLcCyNF3wkBPRh3Q6WZf4w67JpN9z3uygk/QWhVd0cpaQXAaOR0pAmsAjl6k0JPMZDE0/SWXczbT9Y//PI9H//535tvHv66Hl6/LT/50de/6sdLn57c4Y5kDuk6r7ZO4B2PxvW+H368XF5eXr+4vnz98oeX33z99XdffP3Nd2++fXO5ppx18aPj/OzxR7/65F/+l3/8p09++eHz95/qXBrseTYjKY7SZRUen/HknLsKAZ+17nh+fNb5PP5kzoIhgjlYqUEjPM+vDFAn0rbJLmkyhydNbtjQ4oICH9q6V+G6N8NP3spoifZChySziK8Hs7aZ4T0nIWZm94maBzkBYzv22gEsEWvRmlDsTjrlYWmRFdbsysaOnB2Nr7WqR72MIG6Ecx5BT1zbGO0xuHgb0YFjnNREDe5ZWo0Wl4BOXzv+23Y+a5UqOILZtj4QrZngGv/UewWP79YvP/ng2vrDn85ff/bZqx++e/PDt9dvv379/DHvuO6Wil3h6a54oslGP1wvr398/f2X37+6PNzfH6/fvHxz/+2bh4cH3vf5ld6tJx88f/vjt95598nH7/7drz76zz9/+8OnfLwimiTJlDwCunHSdI7juOBN42FiPysHzTvojnVaa0ro6M3MdCOX2S03k/1c6rUZt3EmXtIJmKqmSGmB4U31N0heEVojTFdC9sZnbrEtEjmuLOD/hgBqC4GIecsTlyj30AniRAeJUaESm6mJ/B3PBLHOS7Q292V43MwuqR5xdgVlECTcolelvYKZ7EQxItYsyNhJznA3O7jOVowIhg1iJ1GTJE9bRsck9E5cDTKT8YRyQxRzgt59a53/6f3Hz+/++OS9L7740zfffvX46x8er88aF+BYbOey6rR0HurzzXG8us/rh2unDj5q3l3Ws+PJ+e6jt548+flbH3/84Xvv/OrtZ+8+e/T42en509PzdcNEACKKBa4laB1Hjm7kcu3rj6/fvHltHkXZLpzYd6co8s3cu116qIG7l3beXhjcogNmSUB6x2BlYvSjiYcaQiQ37weG10hiTzYfFsW5lrizRgZa4gTBuufo46cmRbPP0bgchHs6Voo3yPC2c0q3AEIK4eqMNG1+YbaFCwJz8EivwViLxCDnxFZ+gIo7NroEasVJTQwaWrIJj6QyPG6x2dgaz8G2sxjt4SlwazAJhGtoVIIbhS6neP7nj5+/+/zR59999PWXP7z47rsfLz+8fvP69Xc/3L94ON5c68zzoxNPJ99xPUG9dTJUxt3d00fP3797/tb5vcfPP3r087u79x+dnp3ryd06LZW0VJgu+xaQkqvZV5yuoJTa+zLEtep0F57vgcCPrnUiBB/uy6jrInoSUm/AFteSyM4wrZSx5qsY9TZgXiP0UOfctOGkDQVqz8Q4cM6gNVSEG5sHjvdmoNLRbMA7LxoE5xUFuokqL82PuPuOmr3uIOQJLZEnsWpdWbO4QBS3k9QpTiQCjtkikzaPHv/HQZ1qVK0SR0Y7jTPLGjRH114kVVEVJ/9HxIzrq4AxxHZnXE+b3Rj1rOnZIzNADm7SpLX4WPXzpfeenS4fP3t9/PxF9+s3x48/XH58cT2O5LTqXFrE0qPy4wW4+6GfPHr87vO7Z491OpVKK64cp1AlrCmqO2f15kygixcah5We5na8nD5wtO+N9hL59P44Xl0f7nN+XFWlSWIUeRYmODTGUEgc9yIOk+JpqGQMqIlQ3Xt32Vw0E/s76VCTHw2At70Pt7zpwcymyDe2ap8QxjBPCohjekKFwRNF2ON2kSkS2jOuC87IFgPHa00cyLzwGe35JPVgcBIHQ9+dTmIpUjc5XOHcNULSFYer0fJulFWrIyTdBz1q35F/RyWeyinHFWCWlmKWOybi4YXb/HkzCu+kQq46M4vXx4X3cfLT+N3H15EVF3kjYh0fPQFwvdb5fK7TIlgdstZap5JkTzfVnPAlSZQmIYcThTBkl520L/abK7urqK46cu7X0ZtXS9dTTRBaSLK382KeekSza/go11LtePTZFE2DpLEkrluWfmZldaCgdpkbB06QjE62B/efCIFjL1Qb7UMF/NubMeHRB0D16MF2f0csOHb3LA3iiI/ZGNXcQh8ONDtlmGhp5Nc70WRHzAmY7Q51GKhDK4QEaSwORNOdoDI7IoxhA7tRBz2Juk4tEEgfPI4pu///pt612ZLkOA50j8g6t3sGEEBQokTJpJWt2f7//7NmpMwoChTF1wIEZvqeynDfD57VIGnGB4DpvvecqswIf8YpoaKOyEScWp2+lhzQOVEA1HJM/bjXCi1zQXqrBCNJEmSfxO5xotFR4CKr0cuFKlQ7Zbbniq2EHFAYDMvomCHTnpu4U5gv1xcVxjdUl3+49MvfrNeffSUvTdYLi99DmILXbG5I2Koi1zK14+M//n4oT14IEydt4yiTIvutiLgP4e5Elvg+s+/x6IV8zPMQxVPF3Asjhs8MfYPsgUj9Z0bT2NcTOv4cKigurAYS79NVtTohqJU2oHb0DRhvEpRnsR2rG4zoz13LS3XjWeSy3M8tgFioPoQkS2awUDOJyUJoNhRvkmKL2L4h+7AQeOTjOlP2SRZKfYPb15KA9PDmGEYIuKBMaUhy5sBGDB08V3K5Vga50G+mA7jn1FfCSDACiv1aHy+y9s/y23vphx/68+drX41Fz8mzgZHoYZT23ahV5NU+VpJDtQfMl2CjyAWU6Iqc/EwLUZnjSNtysJMgqRINVgRd6UAIyY/oMli7olE5fr/U06XH+rSPp1oyj5/6EDZnOXEFriNPowuVmA7wpJFyilnUo09HqTy32ztM3jB/3+0LmwVs+H2mIHHlK8MLBNsDz1aiHvIzgFfDAJWAXeBiD6Uh5riKKozC6WSGETkikea4wI9uKr2xsI+0J6bYCIyQFxQCK5tqVFQYURN7X8Wr0CAqbQ5IjI3sQl01Hx9+fdH1pdbr1bVer+uXX/HDD36dIN4HyCYaFFvHn5EYnYMwGTxt0nDYgiOwSr8eysixXj4FCY6WPFtxFxZLTVhQQl8rVT1yfsHqmBWLwMo9VVbK1wpwZwtIdsz3ySeaJz+B7VYuHdZEi5w3iqdC05gTXhs/KmizRi8DtrBxGvgabO7kKl4njE1RvscoEiWIL0BPon0EkX+qSW/w4rAFYLow34uNnRGtQCdqn47R69npT7ssjRlL82+m9A67cLDSrP3H8Bg3GR6VVc5XphUw+j1DxBAu0cAmhN7+cfwDu7GglTaBzVGNUv2WSI4mV/zSlb9Zjtbdp84bPP26UXQEDE3abGKbiin7KqS/NLdmaKFSBg+pTFa7C40a0ScE57z6Rgl/OnXt4WmwPs9onRclS3HUHMITTLssFaSh02ybWUWZJjLChyJ2aM6zgxf5CoyPkqgqNmvBlpkNv442AJQuSXUc6w5J9JjTJtG1MjV4p4GsWM0+5Bmd6yLfVsKmjkomfOP9ZK+cAziQI05Vq84/UQ3AtowKOmzzSNUD8H3vdfDzP0awWZXIAXfhFx/4YW3vz7cvLuH+1E+/N4XjlchdC7ZxSiMwQ3EZbqbQLxeislLM2cUwAIt1TjTS4GzYCqp5DBeQsjmQtarPdSOocZBxKWqE7/zJnwyiSf7yGC5G0+HvF2qZICMHC+uPtYEFuo8rHQeuCbTPpilpSkOUpI1nmybQTENqhISivBqz0h0ZybdgGr2x8bRZn2ODLZnGK7kUxGYfkEEsyqdbw2CMn9YjUyj4YGt5ykJMHnnq2X4VcaDPWVh56K0UUNrxfOPMASG38/rovMmZ37MS2DY2bEeiHrvi4CfVH9ZrGlUnVhepFxgWicWUmtWRMqGIGVskwQ4zYcDkRDd3bk5ENehUvrJYrWb4l+RX9ZFTPXolgUc2xe+DKiBgvOWq9Fr1uc/9qFLDHE9Gh1QkQpDpxVr90Rlb6NReRdNIwpzYrhLhDblM8ArwC/ukproOvnzb72GOwsdAdmTpYnsMi3RE4kWi81IeR0HOA0SpZGoyUxjKWu/zYuYSPXfDeSa+D2oPLmjYp7iOouH78Ph5+w4OyTN4KgagbHPhsA9gR9sQXBwlEvbzXvLFy3d34f3z/qf/7/Nf//j55ceOY9ix1fN0osebExbqrAJmP26DDKfG5DCNQjrHI84KEtGldxoC2kShqhN0Tp91RflwH83ygqP9JuqIIxJLURl6mJQ+CZgO8F95AA6JX9XFtY4bPckpOTkAe8pxJudntYtYbUP3Dc6j8vaMZ3LcIdQNRy0HsHtu2AVyYVjbSFNgWYTGZRzlvD3BaauY+/AsGeeCRtHbBEpOs5CA7rwvATfPrxBNHQPCZtsIVpOvLX+gx5O9HjlxfPYG4pweR2MGgO6W9PO3+f3vvv38x9HdGzd5z88/f/7+8/7JRtWV6f7kAWqgLbkCmMDWqqp0W0rG7YO0+3AdsZ+dr/scLHl2TLl1auGAhHHlXc+qrZI9uRudrYIocKkbXZTyPqY/1jx0IpAQuD7j8nMn5DidhTcAs4RSLQKtelYyVIQxkKHAy3ODKK/sB7n0a6nrKkGSMEcuEoxAw+Icein6zgsollZZ8oRNyIfHM6LpmNfiIEgy94ZhLadkZo5RO16w8NaPDK4CzWRAUsayc7IjU0kfD/85eSJZZMGhunF2vcwwREQi5nJfCa1w96euwfqBr7XmVXdrqFUlBudMu+uqAjkPlLj3aO+QJcVqVippQr92hJSHycrX7ug8oXjyfJa1qsjb86kAwW46OOk+eY0wuD2OAL8gFydST4GnAc2i5DkBJUS4vyC0WERVOwjyEZ2fI6MVqX7jXEQ7HbkEQO19VNtmVy/uTcYjGeRDQwLIn5KZ5t+o1mqnkENd1hNWtvLV1WStt7F1PurgM1VAVZnshT9RUk3E+3juChx+F4geKoB4jDawiwrrxLA2PrOpWdBQc3rncaRSzsYD4sdf/Pib//Qff/XbP//DP/8Tvr2bNOcP97ef5vNXdBl7q9rNMwavU+mtuCslWhvYwRHGFWCQaHSmpKmxB0phbIG8K27fFL8DDyhFIqmEBxEpuk5rYrmeXwB9UsYPqGKakSkzHyeX1ZKSX9ZPK92YIyxn5DjTWNkI+mtvUo3EJyTficYVLebtpcchvjZ4g+ZU6QMUezCOjMFh/Ep2ZUmobfs+8se85Iw1VIkyVVXHAiwdpCaPNFQ47/HAFcrIsHwQx/Wc0Wd2OaTkYVvNQvKjofzV5rHjz7lGkHU030KUmAx9UCb0uvDj168fr3/Heo3/UNpz72+f3376/Hnu90d/gB1PVGt6FdKqxhIvJIcN3K69rXvWe/fqvlBlj70nGvOkZQQkn+kMzZZd5CoS3IDQxVXKJpA0xJGriGKvfFvnNTkKZDomdyPQqOm8O1jg2EJtA4ksIwtcI5c89EnIysBe5vbsijiHR3KHKqDpYQKSJri/jQpP2DXHKgN42TamcZA3h/Sv7vKSMSM0xQQTZK4gPanegYn6Lgcl4mRQ2guwKlVHBZdHFSkZn4kzK/t5MM7NHY0xQUwqwzF8juXzfJ6LGsgV6PO/E5hgw/ebn7//uH+/5v25OaKa31D3XBtrVpFYBtdCXdZpXaBTYQW7SF5AlXeeCIq2pwUSpXhHM7wmQ7RrgewTp4FMLw2coJ5T3xaeTPbeYoA8P+qJg2IEtzJmkASPR6XMSp651xFmR32gBa8Z5QLmIKOlkfamiEhOzQAcNFKcvKhVVQUrVjUWkz9A4pxvHFBIvFnW5HzyKh75qc8UYr85u0j3a77bnc/CAH4HqUCW0Seh0pyJc2ZFJ5FCkAN4RHfbBfJ42/B9ugsPI9RRXpwoMVRYhQBBhaSFBTCKNsHXj/Wbv1x/8Y/X3/19zx+ADQH70/cfoE/ia/XVfTSax3MZNCZfuS34KOiWPdyaz/ECu8MLP6iUga0CWOrGGaeTSxzlQzjRwA5ncEKegNyQxAPw+eHI7DmwgJF70sFATAeVQguFqSpXSbVATpNWbTlSH1Lfe9GRF9vP5+ZBuRidV57zflgMnI638BNHIZK5koe/yjkTi1GjYXtvwOiOCTxvbcXs9aTuO4cn6a5kmZ30Htve/r6NGDhhG+dfONWYOqPdOUVyZobSyzJ5/gqcN/KxFBAo8eEHq17kn319/ebr+p/2/nn6xdXA3u/Pe78HW+W78zhNBrJAUo2zgTmrak7BYZWqNHUQyepiNb5jKzIgbMTrjifPzUVTFA9SnX82/35nqZsDc4S59cPjppPBT0Tvw9gk9S2mbnYhEEqT61pJBGXyvhAW2dGRFs64FgSaZxaqHFzhBALkOgXnxwzocwbVZInAYUHO3UijK0SU/adJymdhLWWrCujjnMvMtyntQ3scOCwGuwcKPq959oGDiOZSrLOk8wxYOmdhlC4KBx4M8sCAsXdnrYtMxaPuq77+4I+P20t+VffPP8+3383+2folb/u+xfDD3TkIVsD3gEl5uXEkfUGhU4HQZMoh899xAVn0xPSYX83nGPEzgpy+i2AWzk1jJgC6jjUYyBlRmbFSc1Rncvf5cfNMZlBUaSQu0jVlwg30859np3BEhIAZ4Fh2j+x5K2+o7IBsjPDMekr/mH0p/ooc9B7TrF7VPIx0VYslu57CBe8Ns04GOv8tXJUfLSf9c+XwHOM5AxxCciV9LMHVhwA6mFY+ODPnDQUm27gOOBLk+8yDB2yMO0AlQauvH37xqy9//pvrn/6h3uLY7435JJM21cjJTXX+iIZICSm5qXMnBDwpI+Y2h/QjzyV6RiZkzONRUGRAPmh/MIqggra//2bVxoogzTyUdFDOlTk3/kyQR5HQFLuU4Xno7cFRci5M5RuOiihbEVRIoVuZCilIEkmhPbmufr4md3ZvCxs4OOPzI+E6R0yHIzrf2S0mIDQhdTk5aJemOMgkE9AZibDNTRrJajIteH7Y8synLeKFit4nn3Ly73SC7zNqP3xRZlY+5Bvq+DUw9J8KdjN2+DyURF2FD8w1KhUoed56/6Rv93xSu7vZRcaiCM8JDqhiMgEVcLfy6uTnp1A5T07SKzkgjesgw0oSYnWeFJ+h7Ci8ODjPPoHolyM/bnzHtOoBj5VPx6EqWZEnlVWaVLOG6ZMQIbwiaD+rXYehwNizyX1CUKseienFqJQkROvQq/uJuW0lSzysv0mshSI9HAicWNIGncF8HblIhCgsGnGHc+WH6jNXPxEG+AbA9cXrCgwke+ffP2l8BfhoY+wjzSrkdvM+p0hKdHlumXAtEy0Eo9V7XuQ8QMrqAqBrrfXlWteL+/IXFu6fP//4z5/f/rBnag23dMIO1lF2pQCJJcZuCMC1XMRz4p41IM0IK0c+q8ADAZxQTOuEsh9A0ye4+08oeoZLHXYFD0GZuI1oNg5yk/MQQVp1vELIRlEsc3LWVD2sQ6D/ZNOx1+s55fLXi7D2nTJ6VxfXBaQyYo+JQveGKZWD1st4z4I0HgPdbrCDf+bm19MnCdPkXTa82N2rMx7o6GewB+MuohuVwSLpTSBeGYNhpxpd5+d+dntGrUkgDBSDG2dyIZKrpnNl5/1UZtXoohgofWmwrtf6eJV2/fO3qUvXD9/8qzd/4VoojqPUdGWLDuNHEG55jHgvtONEYtlV5epYNQEk+R3eY6QnqWaXDDAdGT73UjQG54Y9hCJM6ZwZTvjq2Q8Ad5IowrUkHuSI4ZvIYgGYWHTzspfm8cIecDYUAxaJVQeOkzGnkamBCiEtNzciRgHGxvaJOwMJebyHn6Nd6tcLJmfwvied0s2uLvp7Gqxdg94VIafpnc81nwctr7a/Igmy6Skmkm0PtPjggAdnyQmcRSDM7Ll3nyGdxqlyc+qN4cTL4XD4UI4m6RG/sqT5eb79br59cqhb9y/xh1/Uv37hT+CYHyftrazoFpJwyOyb7DwykZEPjp5Ow1J1Sx0wMgwuonaTpSHTEMZ88YrTijvQDgO/FlFQYZwnPwffIzDcg4NnAUByrmwVaz1JzskFMJ0cxgXsLLnxVHgIoEtq4G5YWyFRxYbcFNu7WFkhztcncpWAU4o08gyMxcJ1odCgG1NL8hNRbBnietMqXe0Xq90208xne0gge7RU1VULFkPfpGPpGbkOSx3QB2fXCGd1bnYeudUJBcm7hmcu9lmliBEFdNyqD9Zx83RWqTnNEyHhqzFv8o97fd6N8eU7uJBNEfeQCKU39tSoi+hlJTxFGs9gdOOPWt390X01KsIqJN2f7V3X2T7thCV0yf630RL5/vPUkY8z5ox+OieCqsq5O8MqdbLTVGmPRnSf2AEgsDZJzcm2rYcLjQhGk78puK/kgnmSrwVuH34s8CQ6pg9a7Xj2aZTHrmQVL1JLEwVODritq+FquEYootrkYIjnMHSdj4Bz8tLWMoj40SyiC52ngudzReBYI0f18aJEsGm4iSCleIhjeYcOIyIKyudaOIEV2qFdbL/+3Zcf/vJXX377uv/pX+uD14VXT1EC3+ourBM7EmhDtsbYGaY0rd1QodR0V60ivszLM/J2aaomNpRo+KwKzYJnR88x6zpJKs8HFbBJJYVRMGB+lyQC0ZaAWEGg3REmj2dF3MqEgIQartEK72FVlC8pTMgHqjSTBajzIaOJrsgxR5DYOoic8xiRSatClJNMKxOGxs06wgxRItw4xVjPIkno0dzqDFiZKkFWAcPoPvoEfT2fgHLUPg/BcafSZBgNG8QQO9JjmenmYySqmSB5hEI6b8P3cznXU3RL1nD/8fX+x9f8y8/6eX6+9s0//PM///y7f5j3X9SXC8IWEqeOONnRIBvSaPbyVV7kPAdjRSyKufoM2JH0jYvoiAwrMJ6erHtMo9pdBeUxRFoODQreBfOJGzhLZU6zioWs6tEYIWmyoW6/A4W0Z6zVcBKIvlsknm/lSPszjTZEUM6lVlhU1/f7GUKNikgHQPoLHlSCVVdAtSCdQTer+gSIMCFVgjzbmhSxq4jqCqlEZ1Koosl52geflC8M5tlVD63ChI648qVnfUJbj+THOGmPz0ySxfYoCPK3ZZ6rw5uX6NLgj9/uf/nX9x9+1nui+Nu//5d/+sd//D///g//7csPv6xaBoG+TvbtpAsBqPXxqisjrq0kFz88n3xlWGyO6UkwhzcLHj/9y+XA7AfydT7uMbaCeEWpGHmzm5jod6KXgjwyiDjzUsp5OG2f8TbqOZVh10rleF8R2QBOgSMi0Dewg9QdPTY32KWuo1+10WcNZ9KasghpvJ94aAyB4rrY9GFcXQZmFkxQG7vM9lytujy5GPVQ8LF0RSAypkZpWg1+rFyUfJYqPHAfjoYnI614FGA4h1QOlMxhFblHDBupuzr1hiy7tA0Oe7xm1x//gN/963r7RywVuPi7b9/+/h9++5/+6W9//atf/vCLX3OhSvLauyCw2fU8oCXOThhl7nvMgV7Eslfec57Z6Rig/fyu+ZZzUETI5KK7McUJW26Lq88IfniUbCVRtdunlTtlUc3u+DTrvGhhFUiTa10+qMVUGJFDXFA4SFrjAEJHMLdt3Y+f02AWtVVHLYDD6DQBYMwBirXIkCvFcjUFU7KKCI45QwwvsJquDpNW8QLaLR1gOC/OwYohJ9vATmRxwLHA7XlDffas83cDKUSlV2IM4clz+BwXdsSY43jPE46BgQfvWz/98aef//X3e3/j1at6gP358//667/58euf/fjL//SXHz+svcw0y3KiIdLmhEjVkCdrE8OZMcTC4pVNWhWwx4s2XpC7zNo48bpFLmNIScbmkcge4i0vxwEgfQYJVtPJZzQfed3hiG2N5mgB9ZDah1pf8g6dfiBd5pyANgg3sZiqPgCm6IKZ4tqjhRHjYFDqwIrFTv+nq4odU7QcKXq4oXZdARApcEfvQdWJU4ZdpxX4RFwgYvA/uRVyHeQSiHY99E8SBX3EE9Zh17JJAmlDrTS6HpL2PD2H1Tj/dXIeCcCbkAoD8fONP/yEn77NWwK6hcYs4P15/fT+eM+l6dhU4i8jPK5bx3JVZgboGIfnDd/GCwC3VdirSpU/FYTe5CswNjmdVsCAr0XzfHFzSKF0G9eVeYCRBR09rCPTUmnOApY3GzND85CrTAwyxKqG163I4Sv7QI4py62qrPd4IJsDr518DvOg7Q10du3h2BqfDH6WN0DPDIAMHha3GUVJm+jrLF2mplJZhoapZtaEh3IgiUkRg5xKOxx7+GyGomdC8WRbGzo2QbBYJwY7YL0hPv7F74/FQ2Y0H05Tch+wFGdvr4+P/vrrev0H4F/zF65iwR//4T//+F//++vPf82vy2mmVB1bCkmTM4e7rIRUmVX99cKLtHYJWogyO+5WlMuAR7jDToWIFVxGq7nyCh1YwvTRwrIiDxAJ9hm3uJJeGJckIvA8wdFQVMVIhdM5gzSrrysbM543tJBu9YV4gs4sJFl7hI0udpMrieuAqJHsdUnCBtPVVlYPktkj+37LQHdVYRuadbUaG2QDibqb0thlc0ejnqTDAMgwMWhxwOmjATzPq9NDQAD0UQPmFMvXcbLzDtmWUxdIT86TCgIcgbKOzFdYD5Rm1KgFfP3KP/uLL7/4j1//4fcfvbX6Cvv1F//+F//tL37xZz98vfi6DmB/+5aCmDZCQsA8l2BA/lI1atDwLFr9KZoTaUyzyq7E1+YsysFJ2y7dq8C8wuf0zs2oQrVP1q1DrsReUXRaUiF0jJaFQnsURbncoSwJl1cfqEjR44WCK07Zj9WHoCPeP8Y7bam86RkjvwmE5TNmtasGuoc4DirIheqr0SUBHV+e6j3IP3WyH0h2i+yVw+7QCUctkxnaINL9TQ94+o6tENEuLDbOC6CJVsA0c30EWCqe3CQYjm0jNj8ylhhWszsVJ4Cw3Dpv7JevX3/x73749z++3j9/A4e4u7/++Itf/+LHX/5QeuknSDfKWtH7uOnDiNYisQR4tjj27smRQLQMq9ioq05TQPDCc+SxlmLabUcpmfioSC0jh829cFhzPiQ9gJQcmE2783tXcBxSGroTNVfn9IVtLOfCSoIDvtPrPCH6fvS+pNkGucWRsePONtbJrYzxp2vRy2PRWL6IijGT3gN71FW1iqpsY2F2QxCxgeP0dgPlgluPbYeZoGgcvWlhpYzS8PloDiaBZEwwAJCebd9/sg6LWbppSx5POq0iYabQmmQkZA7DVDDGBb2qFj7mjdmcD2r318ZH7Zd1z5pq21X98SKqkql2CBbJp4uVXjG0BrqsVEuAdZk49pGT8uPDC4Jw+3zX7ZSZ1uTuPHnxYTs0OkvpYRif+AEcY9KZWgnbM4edzoJayJBv2145vHNAKA4yF0yPvWsiParUtFQq6OJjLbuLVx/3sCqCzJEWojipjSofYTmTZxbWKOe4YqyJCaqymxLioVOE7Ky2AVZiu6sMC67+LgwYAjNINXs9kWMgmUA2nFU8rLYMzLD6nPOiifHyaV7NAYmRdIfL/DfbD7jt+XnW5z335+f9bU11cdeX9zft97uwX9WutVJyXSiNx3N7dMap2eeOK87p/QKudWQfoaizHkR7wXLcyhHuh/vI4iGlr+/MBK7KyNihkc9SF9IpGFk952h4hQwAgRL7eHE9rFObvGKxquCIJ9eqSHINuioMDk2qEnafsTlAwsDjRWEBhPSRQ/QsxBMNYK1Mi6trLVdtUCfiKAv1403N1+pMkkFpCl3fZ4Ewz2qnczCZqVMQ1qlMPY9RWBDiKHjPk/KdfzW6DOrsVri4eJ6L2kHdoZ6UwSfN0wDT8CwS3IPP0T0jueEfX16vxfWyW0GF94jgbPIRcJh+rNo5oUfyDR+BBRtqQMji5i5KrSKlJApmRsD3NTXQYOePC/bB3KL2nN3z7KGs71oEwjyOvCBAZQ9XwwTngNvnuUo2BUlgwCkQvPJgdvPoYzLuSDwq4rOskAXMIaeq62szGNpRDtqRj31uW3NtrWvzarKVEfhEfAcfj7QgrKiIoRqrqytVL3mlR/mGaUnzvOflrriXjsIgdtWDzQfQOXpAd1eUFHh0M52E/DjASo1yUWhPejc+kRWpAqRMf3zx1z//9C9/+tyVbviPv6g/+2/XL39TV9eqrvJgRt7YFGII4zL9nQI6syFBbJSNuu3RCWRyQSS8p1TjjfD5R83HbGonUiOSi67DgEq3BLqqi0WEuYSU3CJh+JhiA5aCwfJguwuV1AdA9LK1UQVXR9gZoUMO/EzxooKHnvO1ddjBIGTRPfHzLqavJAJ1BOpJ7IXqehODqfcNbxzLYonYAYCP7gCxmkewVDQ9FabEBaDzk5hQ+/EBC4OtCksYgjVwqSCjqDJyJuTGOWdRQdUWoPOgKTWdB1ATo72pVcAI+2ETrh+//vq//N8//uf1+S9/1PLHL374r//PX/6X/+svf/n1S4nYo7rpIkuu7QICrRThDRGs2hSKjaLA27lrIqtxyGCGKFEgmTqu4CPiGsAy+5g9XWfCNM2BqwvfMw1sm66YgRDQ1KaOsEVFcMYdOOF4Ao7u8G//6u94WPw6jmlsndzKhcdhDkZiQEClZ6rCo5aC7204VpMDqZFgjWoqLQLnjBl6QKIWV4OIrixXmbMv7bgFEQVXVlSZcrXApnGUsOFMVaFBgv2dmAiOcrqccBQqpIpgNjEwk/9y9DMBVDljYxPPhxR1NM+aYNt4a3730/uf/+X+9mnAry/rN7+6/uxrfV1JJUyRCxs+wWq9UJWslBN0hkmpWsDikEOFRFKFmIRLJ44HfGgy5OFQC1XYxMyxUzAzWz5+HgXjoY9AWipQnJO+dpRxtIGOmYyPB0WN5Axai/GAnD9OJ9oDJRhTrHSkHPyfR036fGcMxmX5IMJE3IYkjdGkr3jBeXtET3m3hQYae6rI5SFKbNuFXeNoV3yIkXpk24SWs4ubSZbPyQkG7AoWPufk1YFPw1wejga0uhD4p0xPHSpskFDUc7gcj0EMMhV6cNG+ufHnP16//uGyRW2DtXp1Wxi5qbVYXAMC67s35+TPX7wgm/vmtgT1DMG0EyBOikYO0LO975C7fAanMlL9J1U7WTQUisLx5nEwR889q1DF/H+LrBBixr7zr0H1XR9VbFS85gBd64AG2wc46xJLhQ64bR8VPEDNHBVqflKQQGpRLhg7xbBA0tU4AevSxvSYYqc5VZzxrY02WL17GfK8AXZ3sdqi0lpIE7FUDDtEQx7RjBj2CGkblB0pAXCM4zzJDSFZnyPKPRJY20clImcGEZxczIowmwRaKGFqcytPI7m4xDX3CMIKPdp+pYJrJGW6wov20iTcrMoLxO0x3F1dH11iIVv7ot+p/7YwpEoN98DCTqAGDGtoLzN9SlU1mU0jBQd8f89Ya59AVHJOEMlE/pDEVy9ixf3xXEEFoDLwmarm//rrvy/RzBh+0jtifg9NoyObgBONEuzFrFPbIFT87L7TWy5VsimbIEaclLuxNQV5pRCTqrtJCjrnqAlWLV5NWbehGexNAzw5b1ik60QB+awfqCizaXRaziXHpsFVPmVagQOVFhTticuHJ0LLThyJWdkZjjuKzPfFazeYxA9qS/dwm/WuWnw1mmYhwp6q6pQ4J9QdVEgkuUCWqrpB1BKj9Z40C3RLTNRRLbCZyHoO60TCFU8qEYnqBs4crSwB5NgwPtg4Of0HGdnyrdOHkEOf7MUiVeEb+uwQNOgSZfK3f/W3xdMP4VO8AsL1DAg6LymOG+5ROme4M41xbZtGCw7Trf7OuFUPM46/2+ZqNz1iMsRg5Y43C90LKOPWxODGI25ooKpEhUw481H0uNGucjI3nfLv6FaYW/Wc6IdFg63OMZLTM0aH6vQ505A00FEb4XQrxQ8cx285NWmRsgglgEa7qmqoweYYuf3cLPISSjUjEXepSXViiI4IRe91UtvKXNnr+xEwsboOlw4AU6xCo2Nogyc2gOp07aDnQD44vyRkT9UH4ZZFqygDheJiHOzIpItjIRucpqYIGc4xmm/f4Mk/EA8aP4YxH1mqTp1CDwHPgugnlMZ0YewUK0CvkMddQS8hsi4seHYkXh3WUJt7xEQItcmuwwl/12tEnBDMk3Z1gRQ1sjERiYrlZviULdL74W7N49hwE1m0JtIG2zK9c8jmBDmgT5ZBc6s7evWCMXxjmtfZ9h2a7m0hXvllLhdTCqvanyXE/nkHxOkra5KBnDn8qfCKTdVefExZhVarCs+LITGB5UliO2YmVBabyuN/5vVTDwi4uFbUzMPDKdrgWP5ktXE6ClGGSS2SXEKXtlFWsJHiQZv8XZNSTeQTf1a00wIGVgpwDKKjxmIyDuOoONcfPMamYbYuK6TQ0cVyLnikt6DIZalCUUOAnT2+CqYwRwMIwTPqScBBXp/2d5KN7ihFu5JZGJ1l2jeJSc/5CVZ73J0b9HT+9IiiiWLEevRSHAslPUmq4kBV8qJTOZ0FiKgLZKNObdS7E18XGw4qoGVE2zYKjRcfTJvIGxxOyrzAmm3TfQxeGX1QrnR+Zo9ZKBYT8NOHYy4VMUNs7+2B438/kqdjdDJqfQ9RQwjuqP3rujgpAaKPbI7u6ghoIqvMNplY0cCaIbEPphCjio2KGSMEVrzOWzc3lvOKt7TelrihdOIVVkaHYrOT7LQnu6nAGRSmzupyrsQqtDGpPTaFCEGKSCv3mZhBN6ywLBnHn6/Cwj6JqwxvXHA7Fyrg08CY0Kyk4ERDgdwWRdepzBuQKpZXDmCWRLzv+u617OqFPNnjqsL3IvVTw2PYe12Md4ZHCIfIpROAzMJT+xiMlcUsmCevlbB2fk/TbJesk1lx8u3KvfNVnvnMpucMk3jQ1o7XlxiuqwEuOM2EGT0TbAdEV8/SuV3gcKgFQgPP2AzxFWcSq1l+qg7HMkYNzaqp0ymQmsTCdYEzCXQQ2lh0l3G1ut4q87hIgqMbQLmLk7U1WkoxaklXh47izHPg0UN4s3GY2UaMeXPIRRukvDzZwgfYmMSQG954FvsT55ZGgRP7I/p4wOBnVESqXgRvtBaY/LVE3JdT8eM2VBpxv/PkjGqIKSzZ22NyXdUCfNSyWVWQRypNxpwx88WcpB5R1kZeNhkDPFQ1yFTrMIC3h8eXb2Aqd2EWtLCUpF1Y2u9/45mkzWHD3puo6XI+ByTUD8Bsx8bnEmqfP9BHFphyQKTlD8Vam/N6OSYni3R3FdtTBd0hhlhsbvK2awaBqA6kklvurkj2aDwcJY+Gh9UMrKkBegVrQRNn6T10H8AILc+bdqzzJ+/qgQ1z2qEqRaSkMoap4gaWq0UoIQsky+b3WUsMCfVRdbtHpCevaXYhcGO8Avqs64a3oHZ3cm9QLzGGV1lyW0kMBTmBZ4wz6SaVNSdd3ocFbK5wHX6CckAgIX1uspqcg71kfe0PeNuF4MIFbXG7uLT2NjBV1YlDtBswgG456bXPQe2aMs7tuapTB+NxkX7RnpFuq6JTYZcx3WoIKNVJRgsFK84eFaie4iT5dwPvgnYTm3axyJawU5d3FBhmYcEsYyG4DhShZ7MPoaD8H0RKYoRhvs88WcMuHngxKVxAbbHHtUC6mpXoJyVYVXFku2cYJEqshikH/wyjEYTSrZa4wOq8PoyMiTSkNuh2G+TSq5TfPUqTOKSN8qoNfGgidBIWuJquvRV6YR3RccYp0b1OOwgZxOIoOojiLblK22iWkhAuu2m+vDeAfA6spj0UVxfhDn7MRkLj5XbXRXnOOSQYaUvpNfYFVgWaZtv39rdbBbqu6m6CkO5bBQnbBbr7tKgUIwUCw8uLBZGpKj/hIQNjZyRFEYuLheEGUCwVbgNj3uNGTcRkRSc2KPggJYJqHuWzcj+F6FUdp1YMcLnlx3OzGryS0cFCCVTyYGpYTUVs7+VZ9KZSzhcYNOtCg7tqoaC3tjMzkKsu8425SAmzG28bM8SydCXtSztqHLrZTWwYHI0TUcDt4XZFuvLklh456VlwCXJXnBmjGdUJn6U2jrALqDFLOaZxwV6KbS29A93hXqrqROpp08mISsFZAWyPObPsWIlCsU8sYrQOaM6+epG0PPdjK6gaj3dJ1cf7O/IdFASoRYBj7oPbgTt9DK/qxiVqohiosmezFpRYT6Obr0WDpXJepQaMiZYD1olwpz7RTa5I+nMEdfv4wpJLUstde7lnHcgxhJLyphTtT9drvDhJDvHUECpwRqYQNtd2bVaVUdu+BkXNGg3qvVn2tb29HIBKvVVb99Vvinujqti7GqzO2udUfMNaGJvaWa/Z5S5rEVWcVKETm6yJ8LMwJQk11S8VuWz3Mi0wz0nR01UFzN3VVUsjzw5Sxb/567+vSLXSHxNK1ibp6kSwB1EDOaRuHPn++EHq4FWXzdHupWEYsba9eb9ilzY6rpCMKKqkGnqGbXZQvrGXfbFR5fLswILIUVsUEJdcjCwx8xUwVn5DQ+m1ZOrQUhzKU3obJZEgFVsns0GFql6ZUctE4TZDzwUDqbEWOAXv8sjYcVoUcRVn0ukywmwt59Gv4US6KjVR1ZIhNa1IILDcLEZoa2zdGErmdbxusXKHgKxcFRkvZEBci9Wnvbow0P5M3OYJZs1SRBVZO5JeL7ZhjRKumAVVang23BZtmWMr9lUEOXCHpyt7TsSaVCh0NAouCmNdtquzDNt5VcV+c5lYmvUCQhdt+sv1wzUQhxyotDkJw+SUjK6+MvPqSBhQa0XuVDq1dUAOrUVNH9cZtlKPFRcYq/PDZEwyVc617Fxe1D1soNqG65Tmiq5qVMu0VFzZIQkxnTIsYB3hKuVK1CraZVdvuoG5bKZTrXqRNvXtho0qiqsuNqChWfgg1c0h1xhWzi2gZqG4eY/nKGolVY+ky95kdYpbNydjotToEBlhCeZM2lMOTZOllaBWog2xvQ/u1ufNiBmozCUZGLaLNV6EVnT6eaniIa1qHo4vSojGYQ1YaV87+XxzksCGNfvibS52+PNyLxZt73Hrk0SLG95V3NUiUvQSHCW+ajiFQhWOFPBqIrFf2clYCwNqBiR7qbCOlCyka4vZcs+jdWRTOMpstIQaXeUnAVXHeJikUTGyQ2/UjnCQ4GoXy0rzeGB6B+0YFnhxvpMxEtW6gDdI1FUqxgrC5ffaIzZRL9NVWqLlrb0nsTVNlikut0HDjSaL7bK3RhqOqbr6lhKbzeGdOHQeDZ5u7EHRXVNIALXlfc7uTOE0yPFJpU/gCkvYKFyk71rO8tWGszipQ9Sih/BJUzsaTJVxVwScgx7KVNkCte9Vs2FBhS6Wa1DAYKPFIzT5aLJsa6qry8ORjviAqJqc4kfap/GUnRdeViGdOgSBTig3gu+iOpmy5REpFukmx33BKhCF8ZRRUyjrWemlgPXwVi8cO1Vi3ArFKUSREpXdidkR0DWRvU0+LAzpNfXtCDZMjaE/guj62rwHP6na6vZVb79HOwDUkukuf/giV8JV871f9L7vbWvUHF61emXUuzVrolgrIW0OKo55qJazrsdgDHbtkAIYWF1mlQdyVzU4Jy7LraNa6MVAAseiJJm+QVlLxwgpeAyoVpm9LkIqylcN216ADXl7b3nSiTsNTdOcI667TaGDR5lY7CbHtkb2dhF9VZWgW8Ou9sr6rmM0KPf2PgRaIUmE+QTdXkmdeE6CIo3S0UEU6S3DvAKIxgFOR5sPHq/j+ihY2jluCHMAamtXA6gkcx69lr1vgb7TOxLSh7yqytrdlbgbJvbKpVGjeWmP7/nGli7ILL8+1othvZrxAQpGcngavI26XQW+6uSr0Eq7IIxGVRMdE0ekLGnHWsVmsyyVrVqOCJ+dSbGaBGZyiwXLq2iDZBRjTZjM2UePVYH+1BMOvtAHb5qtEcq8AawgCN0sX6V+DYSZx7Kl1BVP1sdhr3TexYXQfjN/1nXBfVmA935TLDGPJM8XF3PhrUID7TJdSHBd0CS5IE24eQKtqCpj5M6LEOb3Khac8GXTnXY9Arm4sIeqmaqISmA7ENmbbIQpiD4DHFEL1cKQu7qASg1b45q1vkxouh5jj7xQvJpozlyt6g+qteVloPSeYeZqgknhdnPgrx8fO4Z/dPoligBbvIAZV6fHskzirXqBSHvY+cUStumdJ4SBdjXmiAW2DgLIFMORJoTbWq6OJpEkkbIz6Axm3wWVJj0OVS3SxTVVoEqjve0m8XoR4L5reoGqjGQ13l1f4s0M3k8ctWiec18FNMfUXpVihBmnIY2DPTDGNXY8aAtg25SGJHYF24xGEE4FolQjk2wXCl8qvnDAWJGmWMxKArlobKkbbF+4sS9NnrTiujBtiiNsm5iyMShos1tFn1ICQDNr6vKeSAsMsGaR8gLcXfK6gD3gGPViLcznSEOXXpi4bLuLdbGrVwl94sgxTqxSDojpXmHgEb8oukl1He8IYe+yG+X2TWSYPo7plYXTKi9XOVJGoaUi2bU65QMROzTQoMDLL532Tm5HClT04tyg0Gy/uEVvUEN83lWoRS5fqy9lcYC3vqHXq4sYT3L6UNEnq1zvXXr7KlwfYnsVIErYRg20cBNMeJLXBltoVgLyjXYN/F7o6RVx8MBVWEWPB+Gnuc6ob4TTzdlDhx2NKtDNTo22mxCv6uvkxTRxVQofsRtWKPYqLTbFrekqg6MwHzUb0rcu3lWuq/uy5X2vVIPcyVAZScf8ReqqNW/qbQ3AmWtwsY3XNyvaYbVKrGkACxp76IWThoTvWeqICTy55cTAO4Pu0fWMCmLTncQykqlCoNS+PRReWEX+7f/721qA3bZR2w3Y11wsTu4aUywWrkolAI9hQRLGUcG7iRt2dbCSo0KsYq0htY0IbIDrxJexroXeNXVic6hFNGajhKYxBY24VZjqlquXSXkKEY1E5SZM9+Vss81itWTfO+sD+vQbuqmpLpRZpaG70CyjNY0e7cm2RFAF8+glOHuXOV0GuGlxyhb7ZepNv3AsulzkXOxDYxb29KgWdbWHQ9JdEFhajB0G0IA1ahHHbEMUSpRUrG6jnjY4GhpZRicaquELLkFDmUMsGsA+8qCH0V9VZUR1F011/sAC1tQuJUAaT0Qqxb/5q//Dhq2aCD3kwptdO0c40ZUQUxU4RHu2NCVBl7HQwysvvFnwPRpzNRe9B72K1/S84CUMS1WYVqt51429SUZAg2Q4wC+Uu3tI3GiZ1763d3sdZuXoPiC4WZ6j8zfjYoHrVqx9LsmgxtK4ZF5XVxOyN8HD9+ZalYvUY1xnng3awHsXOXXkW+1FFDyebdZdAhl/BerFfRfG1WAitTycscqvq0DMmOxXt8A9A3hRXz76c3R9li5iHT0OzG2u1hFb4BFGWqk227DZC1y24SFmAHbJolehbJ2ID5Ta9+lNzT+7cwhi/MntVehXu5kWOkzx7/7mf0sNK9mm6lIkj+81iyyVyeRfv3aPa7y1DwnIRh+7nFD7FnuEBCCPNUVo4YNZExouoYTOM5Zq4BHtozRJa5DLnRb0mFeCV4wIaCf/4UTatjm4bquBSpwrAc3tmao1VDkzTjacE0/TxtiV0eRon0x2pRNMiVVPMIgc4pVkugs2DaDZEYm+kvGSKYbyYNA1976WL2NQb5bZFy8QNfd0scjwVfF/lmE3Wy8t18JYmimjpLLfkCaBft2VFOGYB96yySYWw0Ylku3GdsQFx9WEAt8EpXHIIjLvPjRoeWMHD8JxP9iFXnuqzCTlxzJWgoInWRUxJ6rcc689c8twV/Wrq5eA4R2FFL+QExzgktR6X/TgosYavYDWAIPeC/K0JV+vpjODA4NGFbV9WxVexyOy2FV2eXWyccrJPJeKaqvrOBwpb0Phl7PxciqJLmU0btQ5IKI15FFEme5O7VubSSsRkk8vsqsLo56q5rSQfe+aXVfm/Jvi7Rrxg6u/vsb7dnCwuGDuS8XLV88ksRAR6Tp+Mty73HrfP49Q7tpGi2vI1kLRPeAcU8pYZdWKPYC34ymqoZfFhcFYvUViisZ2bs7Uzyo0RPQPheVkamG3XK5p3GCtq0+9r5xgF6fuR9BsFMpNlttTkoG+us1qNoxbe3xS+ImB+K4y1lIvrxeqOB5U3V379h1r0RsLtWRcBWO1Cd5TgyqbaBQKM7IGVXJxuzy6lC9ZALEHx6n5SVz0AJ2LIdrAo/N7dI9MLsr+DmyktsHI2xuxkFUx/cUsaNoNhHi2ySRbWdQMkfv21g2A9youehU2ipu9OL0Izp5R8N0t89ZIwKwudkdI7xuzp8uzN0SjaVEb2ihUi12FjiltRz1pDbquitAf2GXDPWMJaxERECpWp5q+xJ67HdFP+WgCa2iKbcc6zXaJBbXJpX0/LG6ri1ctFLFvoFYfAzCOtqqpj8LnTR5FZ5nN1aABdYprgX0Lci34k8SNKt9kE3FbdnEwFwtdgiJ6RBFrAy6RC4XKuZ/2GBHduqWZahQpcQPAquol3O8BvQKSkuvorjt/dJx00fqVC9QGj3pAFb3KIocsu9vJODXjWS0CHGqmYyJ12R2t7tTGQERtc1S9V9kqfZulmoFaYnk3Gr0ytn+knoAj2lxEFTb2lNsvNKuE2YKNCyN5i/VUZANIw2XDnDtB3U5Ko0kiSJFPBuUReUK80MGwErCPgYZTpJRl56T5CW1WeRPrc7DSdxxrj2aMlEBX4nsMzKTGGBSxF9rbWozVndA2h6v6RmF2Ocj2gdwuNDm6CFXPibehm9g+2S12KznLbbhbEfpUl2tZfs3cVxuv0g1OydWoOL3NWnNzJcIS9xTv16sAy4UuY0zOzEDVyekfOMbPcblUAKctNTifOmZthBknPBE9DqrXxb4KsYWot2ve0pcB7aEn34vdxMKdVMckLpjaHOEqwb6Vp2yKcHUv627I8B21JnnaKsvRmydrjcwtvAjgPlmXA9SBYldAKyhtPTkWNZEnpAtAZqCRMcKfxhi882Km+5c+zy1dCQWfe/a+E5yF61oWbitWtZBTaSxdlqOocfLhFicDchWqt25ahZf6wyXu+D8laprFBdKDwaVW3ROYQbnBKM0NVqHG7JMWWbisWjXWnB1MNWqCpAu1riGUpLSTdtcoO0aOothGFbtA0+3dpymgRJIWYqlObLNXGMBUuJsorup8tgkSHorSQvFHVPNGu7uBBY/oukcKXjjVvriqOJzoCUMrssc997DVZTa3KloKNQqb5p5+V69G+M5KKSqqYaEi6LZidU2+NbhgCq5SYuHNMzCD6NBYPGR9MRkSBm28MaCLTuGquNqdFEhMiNHF2yxV2VPwjI6LyFVaL27o3mqSjRIk7D2QV9WG4sS9yEJ5iSr7gt/cG9W5Cm8qvcGetce+3HCnpW2XSp/0F9Pg3KUkb3Z9zIyO5wwHzgLR5Xl/WxDZNtxUzFWRSGEihr8qM77huROOUKkiMyG/It9DEc7M06QLU4TAdt2FVdTMnhGS1xWLOkD5VRB3pOCvhUnal1V7t4eKLoBw5IpgmlNBb+Pe0yZWEbz69DVHJ5+A7FDd5gjlqZKrgPvqJmqqjs8siU6l8YBKe/Mhpk/+Sy4mptMaR/ByOkDcKzZFFAUBxd/+1f9JnNOkJxZYuk/OlEZXyU2zygjfmSYjfMYodrSqxVFXZgelywYEdnTsPoa40xxUjbGlrauWGd1SHWH3Lb6MJ/4SsGusrI7R22fIV2xXLmK2+dGLbnYc8VGbp5/x4WfqdLgxt3dJwjpDO/vkFtXljWrXmKAuuAx0b5vem1ETykRVFaRe8OANA3eYDrsur8aih9fchdnG+UiJhUI166qQWCNorGJrLtLriPlqpct9PIsnZAOj8UyBWqzqmCFO/ibhZrG0lbOEC2AhLrEc7LQ7HK3BgJm5lJ4QADK4oeyG+Xf/43+PrpDqHKKR2IbP0bHUuQDJk4ibvtb+pp1s6ipXY0O32sJLq6qCLKO3CWz/LH/pZbExRbqvabFmTXTfJz+wi1iXMTN+JS9Aj0kKHmPWXLuZr5iRYWPOu6vqVXFdHwW/AGsKVzwmeaaiGe4S3dy6D9BgUVWOm7Md5wHGJKtKdO0bvY6lLvRsU+17vICt/WEyYOfEMGI1fS1dA3lt9tCEr111WTVxbhLImynAd1Zz4UaJdZX6ZATUZCj3yUsbs9UnvSx6rwT82wcDitXI5klGpr1lNuvqY//Nc2kQfBFz4o2BY2Rx2fyff/U/wbUSsfBMFqyaRo2kk1R539btavDiKAuKNQ6D6MEGsWLnwioVLJWrVawl3H4L1/K1CLF033iVgSnD00Po2ijWXF147/fIEpeq2Gigbr1pcrGjVKBO3hyxBkMXPaYF2RsGuwtrxeTARKOWa9zJcAAETpZ237PnEsRyo9IOuNhobKozzQ2S4QWcrq84Eairulzzhlj9lRzuPX35PdC4ulaxfTdGbHLtrb1l5+lIsE+DEEcpMwSPSglM4VOGhJCEE+pqXEm+SORAhe5mCarEVjy+ARP2TI6geCqjgCwjwfOWbNfYFRlmFPP/469/S/kCuQo4CR1n3ZlJ5qHMUXvQhbHblSt1aA9a5R6uYnoWJtkJLkZfW2qzgMaM92cB6/UDV9v7npyGj6g3XkIlQnGGW4DVCIXqQXg0wAHXMQ1IFLhmpbLcMrCb1GqqzyfKKZmqaQlY7NjFou1Kqm3Cp/BuNo89eFEwtpznq9gJLGl4xw5vGlrFdj9CW7nNSRMgVJsei6PCsGfDkpdO5pNIo4EF7L64n2q76OOsW/ReXatbT9Ji9hVZUKtwjDcIB1xXeTNDPF30iSA9xLWEY1dDvu1CF1cGk4Yf+g4seK2qVUkKE1jiKg1z/xSRqGPWuqCLM+rMLC5Z3mWVyvSSzLvFieAs3eFa2rfvgd7ZCrmIVeNPfRslDYP3jUV/MG4WbKILqu5mSTtwvchkrfmB+nUGU9Mn5xCW0ej8k8mdgB8Tf5boEisYh2WVimJSmVaA+juF5Z2UkylYDYhYfZI9TdzCbGzro6U30RbvJgmO7EVyx4lraS+KpEQsJW96uZOQV6xqkW2tpBMlo77y3KBXza737XtUeXhPhKsNd4lsKVCaUVH/mJpMnRbnCBoTUHOZw5XIJNOuzVXlkmSuKVNGisIBLdrllIdV6mmcxQj2FCYc6wZZVxtGfa/1ZDUxMqUip5Z7A8IN7MKGNFroXr7QQO1W4kGFXXU1VpMTcFLWiOu2h7yw6n2CjbuRx2G6KK6GkJRbQVp1rtpRGqmSUxmXACELg0pWcEgTkmrjXZyulAUULxKIvBaX7J2EdJTLrmp0EnMBn5EGpK8yu/vFbJPvHfbFI3ZPHlqtxa7VBUAb9pU3HbDPXoASSvOObSRRKbEPgCD7ujYFp1+KBI++BgvllcGiQhwh9jYIRzkaUjbKuQY16XLK/ECTlLzxzbJ9pzyRQRKruGRtnXAoAFQiOESVXImRkm2qwartm7ePka4CYBEatQa9ieaQ8pDDC4sX2euGsbUOLA2z4y8fk73oaVhdwxX4qW6At4JPVskFdRybiTGdzGEyu+g3Z6lQy6A9wvAETyZuJvBhuMbOxLBjBTuTe3lE7UE31vRIh9TxucrJHtJJQSz61HDVSDbW0WbZl0FeQ2JtVEEvJ40XQqHFVZArUDLjuLjLVCV9WhHjHc4cHPgq84T5Gnj8yjrvr7jpRhmFsi28dU7GA5o+gkgX6BuPXBenlFL7VNogVejBcrarqdUsN0aoQZ/+ZyZdozkEXcivsj1yJyi35EpC+4qPoqe4UV2vWq+momkzJmhgKxC8I2nV6Zby3NFkoMBSg+aL+60hTySM2FhsGgXfmFjuDYFV1Y2x6CErLV2uGFZKCEJ3ZB5KtqS31ekSX5SLQjCXqcyySJxsQq2V+mzUIqQtFzt9JfXIMtrJkEEcaclLLhQ+TF/rlr3JjeYU5CSFni6hSWIYYiESaZO5NBiNFusEj+Px+AIJMj2crrDCOCbNlya8TntsSH+jYtnIwZJcSASmAqI/hpOAloPHwjb2YHUtsNSRkERDU+hqyjulhAWURomw1BQXa0DP3qdtCsBaxeU1f4Q7IZps7wT/m9VNzVhvlNE9u+7tKrtd4o5whJZmurQ4t5Mfh2K17Z5NblYUcidWBrgt4OWlYrJRIjIiUGhPNRO+56T2mC4dznz51AAT8GFWDuXMEyzbR4VcZVcDZzEYaOCyee5/LkfUjUaEl4bli6iFyTcjwZgd7l04zjqEz11bVHsk2WWkOlm2satRafgS/xSzXy6vSljtwPheDXBlQiibPCe1QNUCJnmRSMQsfQLmAFI6dYhGaCCUtMJwXba65eZoycK+bd7mBcL0Dtx+Yjrn9DTlNGCd3/Oe+nYfvImyyF77mu4ayO+NMRuqmiGEyw0PtEnUALwz69wJW9cEVJPfW9Mu0stkvZxrdUuGS2WoHXkvK+TSkQPqqLXJSMPRRHct0Ls4MIRS5npN6L0+yAlrUE0sa7Q1rEOBbpWG60g88nWNsGxSd3sLmA0Kd3UVbI0Akw1fZNeIKf18IHq8WSvzdUidyY8dqjQhFxznGIlPy6WjC6Oy0hZLkdHXOQNiooVPHktaTbuSrJ24JRDUKWg/mW/PNEIszBaGeT6L9mztsWfW9McL5r7lFBowEpzmWwSqOyofz5D7Bo+jBacuSZo/Fs37IkdJKjCwhwBXu7dFnxpEnpF7q2VcRi+aGEFkt5cJWk0MRuWEqruELu7Rrmf6jxKXCZJUIbLo/O01GGvr2+xYz52MCpdrSPaMAzLHamfOUEK3cXvSm93HY1Fly6fSgu9xG/XmZXZdU5ZHN2gXmRbAVe4CU14eJYFIVRWqZnzuQBNeJbASjZB+lnUBq6RIYSsC2VrBpwn5pC8Cw6mkT8XiH6FDygRScZESqnQ8chLKqYCLLLiKrML/D05qyGDOtzIGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=180x180 at 0x161A72AB788>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "data_dir = 'C:/Users/Mayeesha/Desktop/sc/NumtaDB/training-a'\n",
    "name = os.listdir(data_dir)[10]\n",
    "Image.open(data_dir+\"/\"+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRawTrainingSamples(csv_filename):\n",
    "  df = pd.read_csv(PATH + csv_filename)\n",
    "  print(csv_filename)\n",
    "  print(df.columns)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training-a.csv\n",
      "Index(['filename', 'original filename', 'scanid', 'digit',\n",
      "       'database name original', 'contributing team', 'database name'],\n",
      "      dtype='object')\n",
      "training-c.csv\n",
      "Index(['filename', 'original filename', 'scanid', 'digit',\n",
      "       'database name original', 'contributing team', 'database name'],\n",
      "      dtype='object')\n",
      "training-d.csv\n",
      "Index(['original filename', 'scanid', 'digit', 'num', 'database name original',\n",
      "       'database name', 'filename'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "a_csv = showRawTrainingSamples('training-a.csv')\n",
    "c_csv = showRawTrainingSamples('training-c.csv')\n",
    "d_csv = showRawTrainingSamples('training-d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropColumns(csv_file):\n",
    "  csv_file = csv_file[['filename', 'digit']]\n",
    "  print(csv_file)\n",
    "  print(csv_file.iloc[:5, :])   #First 5 Rows of the CSV File\n",
    "  print(\"=============================\")\n",
    "  return csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         filename  digit\n",
      "0      a00000.png      5\n",
      "1      a00001.png      3\n",
      "2      a00002.png      1\n",
      "3      a00003.png      7\n",
      "4      a00004.png      0\n",
      "...           ...    ...\n",
      "19697  a19697.png      4\n",
      "19698  a19698.png      3\n",
      "19699  a19699.png      8\n",
      "19700  a19700.png      3\n",
      "19701  a19701.png      8\n",
      "\n",
      "[19702 rows x 2 columns]\n",
      "     filename  digit\n",
      "0  a00000.png      5\n",
      "1  a00001.png      3\n",
      "2  a00002.png      1\n",
      "3  a00003.png      7\n",
      "4  a00004.png      0\n",
      "=============================\n",
      "         filename  digit\n",
      "0      c00000.png      6\n",
      "1      c00001.png      1\n",
      "2      c00002.png      3\n",
      "3      c00003.png      2\n",
      "4      c00004.png      7\n",
      "...           ...    ...\n",
      "24293  c24293.png      3\n",
      "24294  c24294.png      2\n",
      "24295  c24295.png      7\n",
      "24296  c24296.png      2\n",
      "24297  c24297.png      7\n",
      "\n",
      "[24298 rows x 2 columns]\n",
      "     filename  digit\n",
      "0  c00000.png      6\n",
      "1  c00001.png      1\n",
      "2  c00002.png      3\n",
      "3  c00003.png      2\n",
      "4  c00004.png      7\n",
      "=============================\n",
      "         filename  digit\n",
      "0      d00000.png      1\n",
      "1      d00001.png      1\n",
      "2      d00002.png      5\n",
      "3      d00003.png      7\n",
      "4      d00004.png      0\n",
      "...           ...    ...\n",
      "10903  d10903.png      8\n",
      "10904  d10904.png      6\n",
      "10905  d10905.png      1\n",
      "10906  d10906.png      6\n",
      "10907  d10907.png      1\n",
      "\n",
      "[10908 rows x 2 columns]\n",
      "     filename  digit\n",
      "0  d00000.png      1\n",
      "1  d00001.png      1\n",
      "2  d00002.png      5\n",
      "3  d00003.png      7\n",
      "4  d00004.png      0\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "a_csv = dropColumns(a_csv)\n",
    "c_csv = dropColumns(c_csv)\n",
    "d_csv = dropColumns(d_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'original filename', 'scanid', 'digit',\n",
       "       'database name original', 'contributing team', 'database name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_csv = pd.read_csv('C:/Users/Mayeesha/Desktop/sc/NumtaDB/training-a.csv')\n",
    "a_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a00000.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a00001.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a00002.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a00003.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a00004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a00005.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a00006.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a00007.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a00008.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a00009.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a00010.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  digit\n",
       "0   a00000.png      5\n",
       "1   a00001.png      3\n",
       "2   a00002.png      1\n",
       "3   a00003.png      7\n",
       "4   a00004.png      0\n",
       "5   a00005.png      4\n",
       "6   a00006.png      3\n",
       "7   a00007.png      0\n",
       "8   a00008.png      4\n",
       "9   a00009.png      9\n",
       "10  a00010.png      7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_csv = a_csv.drop(columns=['original filename', 'scanid',\n",
    "       'database name original', 'contributing team', 'database name'])\n",
    "a_csv.iloc[:11, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'original filename', 'scanid', 'digit',\n",
       "       'database name original', 'contributing team', 'database name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_csv = pd.read_csv('C:/Users/Mayeesha/Desktop/sc/NumtaDB/training-c.csv')\n",
    "c_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c00000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c00001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c00002.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c00003.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c00004.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c00005.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c00006.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c00007.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c00008.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c00009.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  digit\n",
       "0  c00000.png      6\n",
       "1  c00001.png      1\n",
       "2  c00002.png      3\n",
       "3  c00003.png      2\n",
       "4  c00004.png      7\n",
       "5  c00005.png      3\n",
       "6  c00006.png      4\n",
       "7  c00007.png      7\n",
       "8  c00008.png      5\n",
       "9  c00009.png      3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_csv = c_csv.drop(columns=['original filename', 'scanid',\n",
    "       'database name original', 'contributing team', 'database name'])\n",
    "c_csv.iloc[:10, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'original filename', 'scanid', 'digit',\n",
       "       'database name original', 'contributing team', 'database name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_csv = pd.read_csv('C:/Users/Mayeesha/Desktop/sc/NumtaDB/training-c.csv')\n",
    "d_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c00000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c00001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c00002.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c00003.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c00004.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c00005.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c00006.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c00007.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c00008.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c00009.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  digit\n",
       "0  c00000.png      6\n",
       "1  c00001.png      1\n",
       "2  c00002.png      3\n",
       "3  c00003.png      2\n",
       "4  c00004.png      7\n",
       "5  c00005.png      3\n",
       "6  c00006.png      4\n",
       "7  c00007.png      7\n",
       "8  c00008.png      5\n",
       "9  c00009.png      3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_csv = d_csv.drop(columns=['original filename', 'scanid',\n",
    "       'database name original', 'contributing team', 'database name'])\n",
    "d_csv.iloc[:10, 0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68298\n"
     ]
    }
   ],
   "source": [
    "#Concating 3 csv\n",
    "total_csv = [a_csv, c_csv, d_csv]\n",
    "merged_csv = pd.concat(total_csv)\n",
    "print(len(merged_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'C:/Users/Mayeesha/Desktop/sc/NumtaDB/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making folder train\n",
    "os.mkdir(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(folder_name):\n",
    "    src = PATH + folder_name + '/'\n",
    "    dir_folders = os.listdir(src)\n",
    "    for dir_name in dir_folders:\n",
    "        file_name = os.path.join(src, dir_name)\n",
    "        if os.path.isfile(file_name):\n",
    "            shutil.copy(file_name, TRAIN_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Done\n",
      "C Done\n",
      "D Done\n"
     ]
    }
   ],
   "source": [
    "#copying images of three folder to train folder\n",
    "processImages('training-a')\n",
    "print('A Done')\n",
    "processImages('training-c')\n",
    "print('C Done')\n",
    "processImages('training-d')\n",
    "print('D Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None):\n",
    "        self.data = df\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        \n",
    "        path = self.root + \"/\" + item[0]\n",
    "        image = Image.open(path).convert('L')\n",
    "        label = item[1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Samples:  68298\n"
     ]
    }
   ],
   "source": [
    "# Normalizing data\n",
    "mean = [0.5,]\n",
    "std = [0.5, ]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data  = Dataset(merged_csv, TRAIN_PATH, train_transform)\n",
    "test_data = Dataset(merged_csv, TRAIN_PATH, test_transform)\n",
    "\n",
    "print(\"Trainig Samples: \",len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-1:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 100, Layer=2, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 100\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        ###self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        ###self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        ###out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        ###out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 2.002051591873169. Accuracy: 25.46492897935276\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.8084993362426758. Accuracy: 38.40972323912725\n",
      "4\n",
      "Iteration: 1500. Loss: 1.7670708894729614. Accuracy: 40.899106750622344\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.6696139574050903. Accuracy: 45.07248499048177\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.5830371379852295. Accuracy: 48.36725728510763\n",
      "9\n",
      "Iteration: 3000. Loss: 1.5428467988967896. Accuracy: 51.295943769219505\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.368764042854309. Accuracy: 52.97993849758383\n",
      "12\n",
      "Iteration: 4000. Loss: 1.3579825162887573. Accuracy: 54.356421145116414\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination1.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-2:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 100, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 100\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 2.07180118560791. Accuracy: 27.31000146434324\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 2.016425371170044. Accuracy: 29.49187289500659\n",
      "4\n",
      "Iteration: 1500. Loss: 1.741481900215149. Accuracy: 34.90994289061356\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.6602952480316162. Accuracy: 41.63127837165032\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.6188243627548218. Accuracy: 43.06633474886513\n",
      "9\n",
      "Iteration: 3000. Loss: 1.599918007850647. Accuracy: 42.75882266803339\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.5430854558944702. Accuracy: 44.12066188314541\n",
      "12\n",
      "Iteration: 4000. Loss: 1.5207512378692627. Accuracy: 44.677112315126664\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination2.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-3:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 150, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 150\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=150, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=150, out_features=150, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=150, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.9341932535171509. Accuracy: 25.596719871137793\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.7797245979309082. Accuracy: 34.92458632303412\n",
      "4\n",
      "Iteration: 1500. Loss: 1.6845479011535645. Accuracy: 44.01815785620149\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.4783931970596313. Accuracy: 47.18113925904232\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.5502046346664429. Accuracy: 50.988431688387756\n",
      "9\n",
      "Iteration: 3000. Loss: 1.3536765575408936. Accuracy: 51.67667301215405\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.3255234956741333. Accuracy: 56.77258749450871\n",
      "12\n",
      "Iteration: 4000. Loss: 1.248772144317627. Accuracy: 55.732903792649\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination3.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-4:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=ReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.ReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.ReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.8502153158187866. Accuracy: 27.83716503148338\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.7094354629516602. Accuracy: 34.03133694538\n",
      "4\n",
      "Iteration: 1500. Loss: 1.6925479173660278. Accuracy: 42.62703177624835\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.3626867532730103. Accuracy: 49.74373993264021\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.2556071281433105. Accuracy: 53.74139698345292\n",
      "9\n",
      "Iteration: 3000. Loss: 1.358113408088684. Accuracy: 55.45467857665837\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.0717111825942993. Accuracy: 60.14057695123737\n",
      "12\n",
      "Iteration: 4000. Loss: 0.9812244176864624. Accuracy: 60.726314248059744\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination4.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-5:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=SELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.SELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.SELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.SELU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): SELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): SELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): SELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.851885199546814. Accuracy: 39.99121394054767\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.7450916767120361. Accuracy: 44.618538585444426\n",
      "4\n",
      "Iteration: 1500. Loss: 1.1469746828079224. Accuracy: 55.00073217162103\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.0556366443634033. Accuracy: 60.82881827500366\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.0223535299301147. Accuracy: 67.75516180992825\n",
      "9\n",
      "Iteration: 3000. Loss: 0.876280665397644. Accuracy: 65.74901156831162\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 0.7865107655525208. Accuracy: 73.27573583247913\n",
      "12\n",
      "Iteration: 4000. Loss: 0.83172607421875. Accuracy: 74.95973056084347\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination5.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-6:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=RReLU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.RReLU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.RReLU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.RReLU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.8899548053741455. Accuracy: 34.119197539903354\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.5722349882125854. Accuracy: 43.490994289061355\n",
      "4\n",
      "Iteration: 1500. Loss: 1.4353547096252441. Accuracy: 50.812710499341044\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.1632227897644043. Accuracy: 53.82925757797628\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 0.9357652068138123. Accuracy: 65.80758529799385\n",
      "9\n",
      "Iteration: 3000. Loss: 0.9531119465827942. Accuracy: 66.21760140576951\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 0.9818577766418457. Accuracy: 70.78635232098404\n",
      "12\n",
      "Iteration: 4000. Loss: 0.8183508515357971. Accuracy: 73.15858837311465\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination6.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-7:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=Sigmoid, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.Sigmoid()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.Sigmoid()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.Sigmoid()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): Sigmoid()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): Sigmoid()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): Sigmoid()\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 2.0954980850219727. Accuracy: 24.99633914189486\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.9632785320281982. Accuracy: 33.577390540342655\n",
      "4\n",
      "Iteration: 1500. Loss: 1.6662564277648926. Accuracy: 36.4475032947723\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.808862566947937. Accuracy: 38.49758383365061\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.5443555116653442. Accuracy: 42.94918728950066\n",
      "9\n",
      "Iteration: 3000. Loss: 1.5129013061523438. Accuracy: 46.156098989603166\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.5200963020324707. Accuracy: 46.6100453946405\n",
      "12\n",
      "Iteration: 4000. Loss: 1.384485125541687. Accuracy: 48.95299458193001\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination7.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-8:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=3, activations=GELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.GELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.GELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.GELU()\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): GELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): GELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): GELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.933354139328003. Accuracy: 34.4267096207351\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.6043626070022583. Accuracy: 40.26943915653829\n",
      "4\n",
      "Iteration: 1500. Loss: 1.7052502632141113. Accuracy: 47.25435642114512\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.613397240638733. Accuracy: 45.58500512520135\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.2375528812408447. Accuracy: 54.81036755015376\n",
      "9\n",
      "Iteration: 3000. Loss: 1.2464101314544678. Accuracy: 57.85620149363011\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 1.1881598234176636. Accuracy: 54.66393322594816\n",
      "12\n",
      "Iteration: 4000. Loss: 0.8782936334609985. Accuracy: 64.29931175867624\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination8.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-9:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 200, Layer=4, activations=SELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 200\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.SELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.SELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.SELU()\n",
    "        \n",
    "        ### 4th hidden layer: 100 --> 100\n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        self.relu_4 = nn.SELU()\n",
    "\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "         ### 4th hidden layer\n",
    "        out  = self.linear_4(out)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        out = self.relu_4(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (relu_1): SELU()\n",
       "  (linear_2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_2): SELU()\n",
       "  (linear_3): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_3): SELU()\n",
       "  (linear_4): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (relu_4): SELU()\n",
       "  (linear_out): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.8995469808578491. Accuracy: 37.399326402108656\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.5171699523925781. Accuracy: 45.33606677405184\n",
      "4\n",
      "Iteration: 1500. Loss: 1.398962140083313. Accuracy: 56.0550593059013\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 1.1415431499481201. Accuracy: 63.46463611070435\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.0157082080841064. Accuracy: 66.77405183775078\n",
      "9\n",
      "Iteration: 3000. Loss: 0.8932211399078369. Accuracy: 72.4557036169278\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 0.6233296394348145. Accuracy: 72.95358031922683\n",
      "12\n",
      "Iteration: 4000. Loss: 0.7115881443023682. Accuracy: 80.07028847561868\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination9.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination-10:\n",
    "iteration=5000, epoch=14, lr=0.001, batch size=200, optimizer=Adam, num_hidden = 250, Layer=4, activations=SELU, Loss function=CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 200\n",
    "num_iters = 5000\n",
    "num_hidden = 250\n",
    "input_dim = 28*28 # num_features = 784\n",
    "output_dim = 10\n",
    "save_model = True\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:308\n",
      "Test dataloader:35\n"
     ]
    }
   ],
   "source": [
    "#batch size\n",
    "#batch_size = 32\n",
    "\n",
    "# split data 20% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "\n",
    "# mix data\n",
    "# index of num of train\n",
    "indices = list(range(num_train))\n",
    "# random the index\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "# divied into two part\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define the sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# prepare loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "        ### 1st hidden layer: 784 --> 100\n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        self.relu_1 = nn.SELU()\n",
    "\n",
    "        ### 2nd hidden layer: 100 --> 100\n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        self.relu_2 = nn.SELU()\n",
    "\n",
    "        ### 3rd hidden layer: 100 --> 100\n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        self.relu_3 = nn.SELU()\n",
    "        \n",
    "        ### 4th hidden layer: 100 --> 100\n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        self.relu_4 = nn.SELU()\n",
    "\n",
    "\n",
    "        ### Output layer: 100 --> 10\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### 1st hidden layer\n",
    "        out  = self.linear_1(x)\n",
    "        ### Non-linearity in 1st hidden layer\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        ### 2nd hidden layer\n",
    "        out  = self.linear_2(out)\n",
    "        ### Non-linearity in 2nd hidden layer\n",
    "        out = self.relu_2(out)\n",
    "\n",
    "        ### 3rd hidden layer\n",
    "        out  = self.linear_3(out)\n",
    "        ### Non-linearity in 3rd hidden layer\n",
    "        out = self.relu_3(out)\n",
    "        \n",
    "         ### 4th hidden layer\n",
    "        out  = self.linear_4(out)\n",
    "        ### Non-linearity in 4th hidden layer\n",
    "        out = self.relu_4(out)\n",
    "        \n",
    "        # Linear layer (output)\n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=250, bias=True)\n",
       "  (relu_1): SELU()\n",
       "  (linear_2): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_2): SELU()\n",
       "  (linear_3): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_3): SELU()\n",
       "  (linear_4): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_4): SELU()\n",
       "  (linear_out): Linear(in_features=250, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INSTANTIATE MODEL CLASS\n",
    "\n",
    "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
    "                               num_classes = output_dim,\n",
    "                               num_hidden = num_hidden)\n",
    "# To enable GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Iteration: 500. Loss: 1.8908472061157227. Accuracy: 33.43095621613706\n",
      "2\n",
      "3\n",
      "Iteration: 1000. Loss: 1.6988894939422607. Accuracy: 44.237809342509884\n",
      "4\n",
      "Iteration: 1500. Loss: 1.4279316663742065. Accuracy: 47.444721042612386\n",
      "5\n",
      "6\n",
      "Iteration: 2000. Loss: 0.982621967792511. Accuracy: 56.37721481915361\n",
      "7\n",
      "8\n",
      "Iteration: 2500. Loss: 1.0405484437942505. Accuracy: 66.80333870259189\n",
      "9\n",
      "Iteration: 3000. Loss: 0.6938892602920532. Accuracy: 71.18172499633914\n",
      "10\n",
      "11\n",
      "Iteration: 3500. Loss: 0.6407827138900757. Accuracy: 74.03719431834823\n",
      "12\n",
      "Iteration: 4000. Loss: 0.6389110684394836. Accuracy: 76.14584858690877\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images) \n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # wights & biases\n",
    "    torch.save(model.state_dict(), 'E:/CSE/softConputing/NumtaDB/assignment2/model/combination10.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Best Model\n",
    "Best Model: Combination-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model Loaded\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('E:/CSE/softConputing/NumtaDB/assignment2/model/combination9.pkl'))\n",
    "    print('Trained Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in test_loader:\n",
    "    break\n",
    "    \n",
    "fig, ax = plt.subplots(1, 5)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(images[i].view(28, 28), cmap=matplotlib.cm.binary)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels [6 3 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.forward(images[:5].view(-1, 28*28).to(device))\n",
    "predictions = torch.argmax(predictions, dim=1)\n",
    "print('Predicted labels', predictions.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies obtained for different Hyperparameters\n",
    "\n",
    "- for all combinations iteration=5000, learning rate=0.001, Optimizer=Adam, batch size=200, epoch=14 and Loss function=CrossEntropyLoss    \n",
    "Other hyperpatameters are shown in the table below along with Accuracy and Loss \n",
    "\n",
    "Combination|hidden layer| num_hidden | Activations  | Accuracy | Loss |\n",
    "-----------|------------|------------|--------------|----------|------|\n",
    "    1      |      2     |     100    |     ReLU     |54.356    |1.357 |\n",
    "    2      |      3     |     100    |     ReLU     |44.677    |1.520 |\n",
    "    3      |      3     |     150    |     ReLU     |55.732    |1.248 |\n",
    "    4      |      3     |     200    |     ReLU     |60.726    |0.981 |\n",
    "    5      |      3     |     200    |     SELU     |74.959    |0.831 |\n",
    "    6      |      3     |     200    |     RReLU    |73.158    |0.818 |\n",
    "    7      |      3     |     200    |    Sigmoid   |48.952    |1.384 |\n",
    "    8      |      3     |     200    |     GELU     |64.299    |0.878 |\n",
    "    9      |      4     |     200    |     SELU     |***80.070***    |0.711 |\n",
    "    10     |      4     |     250    |     SELU     |76.145    |0.638 |\n",
    "   \n",
    "\n",
    "   \n",
    "\n",
    "- **How hyperparameters were chosen**\n",
    "    - Firstly, layer size 2 and 3 were take along with 3 different num_hidden 100, 150 and 200. It was seen that 3 layered model with 200 num_ hidden performed best.\n",
    "    - Secondly, for the three layerd model and 200 num_hidden 4 diffenent activations SELU, RReLU, Sigmoid, GELU were tested. It could be seen that SELU performed better than others.\n",
    "    - Thirdly, hidden layer size was increased from 3 to 4 for model with activation SELU and num_hidden 200 and it could be seen that this model gave highest accuracy.\n",
    "    - Finally, for the model in combination 9 num_hidden were incresed to 250 but the accuracy of this model was less than that of model 9.\n",
    "\n",
    "### *** Combination-9 performed the best ***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
